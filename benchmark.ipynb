{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "#import torch.utils.benchmark as benchmark\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WARM_UP = 10\n",
    "BATCH_SIZE = 4\n",
    "NUM_TEST = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  8 09:21:38 2022       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:09:00.0 Off |                  Off |\r\n",
      "| 30%   52C    P8    20W / 300W |     38MiB / 48682MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1118      G   /usr/lib/xorg/Xorg                 28MiB |\r\n",
      "|    0   N/A  N/A      1505      G   /usr/bin/gnome-shell                7MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>top1</th>\n",
       "      <th>top1_err</th>\n",
       "      <th>top5</th>\n",
       "      <th>top5_err</th>\n",
       "      <th>param_count</th>\n",
       "      <th>img_size</th>\n",
       "      <th>cropt_pct</th>\n",
       "      <th>interpolation</th>\n",
       "      <th>top1_diff</th>\n",
       "      <th>top5_diff</th>\n",
       "      <th>rank_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beit_large_patch16_512</td>\n",
       "      <td>90.689</td>\n",
       "      <td>9.311</td>\n",
       "      <td>98.751</td>\n",
       "      <td>1.249</td>\n",
       "      <td>305.67</td>\n",
       "      <td>512</td>\n",
       "      <td>1.00</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>2.089</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beit_large_patch16_384</td>\n",
       "      <td>90.610</td>\n",
       "      <td>9.390</td>\n",
       "      <td>98.766</td>\n",
       "      <td>1.234</td>\n",
       "      <td>305.00</td>\n",
       "      <td>384</td>\n",
       "      <td>1.00</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>2.206</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>volo_d5_512</td>\n",
       "      <td>90.608</td>\n",
       "      <td>9.392</td>\n",
       "      <td>98.698</td>\n",
       "      <td>1.302</td>\n",
       "      <td>296.09</td>\n",
       "      <td>512</td>\n",
       "      <td>1.15</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>3.566</td>\n",
       "      <td>0.730</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>volo_d5_448</td>\n",
       "      <td>90.582</td>\n",
       "      <td>9.418</td>\n",
       "      <td>98.685</td>\n",
       "      <td>1.315</td>\n",
       "      <td>295.91</td>\n",
       "      <td>448</td>\n",
       "      <td>1.15</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>3.630</td>\n",
       "      <td>0.745</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tf_efficientnet_l2_ns</td>\n",
       "      <td>90.563</td>\n",
       "      <td>9.437</td>\n",
       "      <td>98.779</td>\n",
       "      <td>1.221</td>\n",
       "      <td>480.31</td>\n",
       "      <td>800</td>\n",
       "      <td>0.96</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>2.215</td>\n",
       "      <td>0.131</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model    top1  top1_err    top5  top5_err  param_count  \\\n",
       "0  beit_large_patch16_512  90.689     9.311  98.751     1.249       305.67   \n",
       "1  beit_large_patch16_384  90.610     9.390  98.766     1.234       305.00   \n",
       "2             volo_d5_512  90.608     9.392  98.698     1.302       296.09   \n",
       "3             volo_d5_448  90.582     9.418  98.685     1.315       295.91   \n",
       "4   tf_efficientnet_l2_ns  90.563     9.437  98.779     1.221       480.31   \n",
       "\n",
       "   img_size  cropt_pct interpolation  top1_diff  top5_diff  rank_diff  \n",
       "0       512       1.00       bicubic      2.089      0.095          0  \n",
       "1       384       1.00       bicubic      2.206      0.158          0  \n",
       "2       512       1.15       bicubic      3.566      0.730          7  \n",
       "3       448       1.15       bicubic      3.630      0.745          8  \n",
       "4       800       0.96       bicubic      2.215      0.131         -2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models = pd.read_csv(\"results-imagenet-real.csv\")\n",
    "# use models with img size 224\n",
    "modellist = df_models[df_models[\"img_size\"]==224][\"model\"]\n",
    "df_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "    def __init__(self,  length, imsize):\n",
    "        self.len = length\n",
    "        self.data = torch.randn( 3, imsize, imsize, length)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[:,:,:,index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "rand_loader = DataLoader(dataset=RandomDataset(BATCH_SIZE*(WARM_UP + NUM_TEST), 224),\n",
    "                         batch_size=BATCH_SIZE, shuffle=False,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ryujaehun/pytorch-gpu-benchmark/blob/master/benchmark_models.py\n",
    "def inference(modelname, benchmark, half=False):\n",
    "    with torch.no_grad():\n",
    "        model = timm.create_model(modelname,)\n",
    "        model=model.to('cuda')\n",
    "        model.eval()\n",
    "        precision = \"float\"\n",
    "        durations = []\n",
    "        print(f'Benchmarking Inference {modelname} ')\n",
    "        for step,img in enumerate(rand_loader):\n",
    "            img=getattr(img,precision)()\n",
    "            torch.cuda.synchronize()\n",
    "            start = time.time()\n",
    "            model(img.to('cuda'))\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            if step >= WARM_UP:\n",
    "                durations.append((end - start)*1000)\n",
    "        print(f'{modelname} model average inference time : {sum(durations)/len(durations)}ms')\n",
    "        \n",
    "        if half:\n",
    "            durations_half = []\n",
    "            print(f'Benchmarking Inference half precision type {modelname} ')\n",
    "            model.half()\n",
    "            precision = \"half\"\n",
    "            for step,img in enumerate(rand_loader):\n",
    "                img=getattr(img,precision)()\n",
    "                torch.cuda.synchronize()\n",
    "                start = time.time()\n",
    "                model(img.to('cuda'))\n",
    "                torch.cuda.synchronize()\n",
    "                end = time.time()\n",
    "                if step >= WARM_UP:\n",
    "                    durations_half.append((end - start)*1000)\n",
    "            print(f'{modelname} half model average inference time : {sum(durations_half)/len(durations_half)}ms')\n",
    "            \n",
    "        if half:\n",
    "            benchmark[modelname] = {\"fp32\": np.mean(durations), \"fp16\": np.mean(durations_half), \"top1\": df_models[df_models[\"model\"]==modelname][\"top1\"]}\n",
    "        else:\n",
    "            benchmark[modelname] = {\"fp32\": np.mean(durations), \"top1\": float(df_models[df_models[\"model\"]==modelname][\"top1\"])}\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1cfeb06ff484fa987af34c9e5208a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference beit_large_patch16_224 \n",
      "beit_large_patch16_224 model average inference time : 21.330020427703857ms\n",
      "Benchmarking Inference convnext_xlarge_in22ft1k \n",
      "convnext_xlarge_in22ft1k model average inference time : 21.824769973754883ms\n",
      "pass volo_d5_224\n",
      "pass volo_d4_224\n",
      "Benchmarking Inference convnext_large_in22ft1k \n",
      "convnext_large_in22ft1k model average inference time : 15.023713111877441ms\n",
      "Benchmarking Inference swin_large_patch4_window7_224 \n",
      "swin_large_patch4_window7_224 model average inference time : 17.223894596099854ms\n",
      "Benchmarking Inference convnext_base_in22ft1k \n",
      "convnext_base_in22ft1k model average inference time : 10.011317729949951ms\n",
      "pass volo_d3_224\n",
      "Benchmarking Inference xcit_large_24_p8_224_dist \n",
      "xcit_large_24_p8_224_dist model average inference time : 67.19565153121948ms\n",
      "Benchmarking Inference vit_base_patch8_224 \n",
      "vit_base_patch8_224 model average inference time : 37.55551815032959ms\n",
      "Benchmarking Inference beit_base_patch16_224 \n",
      "beit_base_patch16_224 model average inference time : 7.529146671295166ms\n",
      "pass volo_d2_224\n",
      "Benchmarking Inference vit_large_patch16_224 \n",
      "vit_large_patch16_224 model average inference time : 20.30693531036377ms\n",
      "Benchmarking Inference xcit_medium_24_p8_224_dist \n",
      "xcit_medium_24_p8_224_dist model average inference time : 41.19997262954712ms\n",
      "Benchmarking Inference xcit_small_24_p8_224_dist \n",
      "xcit_small_24_p8_224_dist model average inference time : 29.569995403289795ms\n",
      "Benchmarking Inference swin_base_patch4_window7_224 \n",
      "swin_base_patch4_window7_224 model average inference time : 13.018548488616943ms\n",
      "Benchmarking Inference ig_resnext101_32x48d \n",
      "ig_resnext101_32x48d model average inference time : 209.78129625320435ms\n",
      "Benchmarking Inference ig_resnext101_32x32d \n",
      "ig_resnext101_32x32d model average inference time : 132.99628257751465ms\n",
      "Benchmarking Inference xcit_large_24_p16_224_dist \n",
      "xcit_large_24_p16_224_dist model average inference time : 19.60197687149048ms\n",
      "Benchmarking Inference resmlp_big_24_224_in22ft1k \n",
      "resmlp_big_24_224_in22ft1k model average inference time : 34.17351245880127ms\n",
      "Benchmarking Inference xcit_small_12_p8_224_dist \n",
      "xcit_small_12_p8_224_dist model average inference time : 16.266090869903564ms\n",
      "pass volo_d1_224\n",
      "Benchmarking Inference vit_base_patch16_224 \n",
      "vit_base_patch16_224 model average inference time : 7.095944881439209ms\n",
      "Benchmarking Inference ig_resnext101_32x16d \n",
      "ig_resnext101_32x16d model average inference time : 35.64509630203247ms\n",
      "Benchmarking Inference xcit_medium_24_p16_224_dist \n",
      "xcit_medium_24_p16_224_dist model average inference time : 19.10825490951538ms\n",
      "Benchmarking Inference swsl_resnext101_32x8d \n",
      "swsl_resnext101_32x8d model average inference time : 19.363136291503906ms\n",
      "Benchmarking Inference vit_base_patch16_224_miil \n",
      "vit_base_patch16_224_miil model average inference time : 6.888918876647949ms\n",
      "Benchmarking Inference pit_b_distilled_224 \n",
      "pit_b_distilled_224 model average inference time : 8.160560131072998ms\n",
      "Benchmarking Inference convnext_large \n",
      "convnext_large model average inference time : 15.413098335266113ms\n",
      "Benchmarking Inference xcit_small_24_p16_224_dist \n",
      "xcit_small_24_p16_224_dist model average inference time : 19.14161205291748ms\n",
      "Benchmarking Inference cait_s24_224 \n",
      "cait_s24_224 model average inference time : 14.487385749816895ms\n",
      "Benchmarking Inference resmlp_big_24_distilled_224 \n",
      "resmlp_big_24_distilled_224 model average inference time : 34.13303852081299ms\n",
      "Benchmarking Inference vit_large_r50_s32_224 \n",
      "vit_large_r50_s32_224 model average inference time : 17.136824131011963ms\n",
      "Benchmarking Inference convnext_base \n",
      "convnext_base model average inference time : 10.280053615570068ms\n",
      "Benchmarking Inference xcit_small_12_p16_224_dist \n",
      "xcit_small_12_p16_224_dist model average inference time : 10.65110445022583ms\n",
      "Benchmarking Inference deit_base_distilled_patch16_224 \n",
      "deit_base_distilled_patch16_224 model average inference time : 7.141168117523193ms\n",
      "Benchmarking Inference xcit_large_24_p8_224 \n",
      "xcit_large_24_p8_224 model average inference time : 68.47956657409668ms\n",
      "Benchmarking Inference ig_resnext101_32x8d \n",
      "ig_resnext101_32x8d model average inference time : 19.347553253173828ms\n",
      "Benchmarking Inference swsl_resnext101_32x4d \n",
      "swsl_resnext101_32x4d model average inference time : 12.494845390319824ms\n",
      "Benchmarking Inference convnext_small \n",
      "convnext_small model average inference time : 8.828063011169434ms\n",
      "pass swin_s3_base_224\n",
      "Benchmarking Inference xcit_tiny_24_p8_224_dist \n",
      "xcit_tiny_24_p8_224_dist model average inference time : 18.574306964874268ms\n",
      "Benchmarking Inference xcit_small_24_p8_224 \n",
      "xcit_small_24_p8_224 model average inference time : 29.81912851333618ms\n",
      "Benchmarking Inference twins_svt_large \n",
      "twins_svt_large model average inference time : 14.563868045806885ms\n",
      "Benchmarking Inference twins_pcpvt_large \n",
      "twins_pcpvt_large model average inference time : 24.161112308502197ms\n",
      "pass swin_s3_small_224\n",
      "Benchmarking Inference xcit_small_12_p8_224 \n",
      "xcit_small_12_p8_224 model average inference time : 16.130428314208984ms\n",
      "Benchmarking Inference resnetv2_50x1_bit_distilled \n",
      "resnetv2_50x1_bit_distilled model average inference time : 7.660644054412842ms\n",
      "Benchmarking Inference tresnet_m \n",
      "pass tresnet_m\n",
      "Benchmarking Inference twins_pcpvt_base \n",
      "twins_pcpvt_base model average inference time : 17.1039080619812ms\n",
      "Benchmarking Inference swin_small_patch4_window7_224 \n",
      "swin_small_patch4_window7_224 model average inference time : 13.149974346160889ms\n",
      "Benchmarking Inference twins_svt_base \n",
      "twins_svt_base model average inference time : 13.463866710662842ms\n",
      "Benchmarking Inference jx_nest_base \n",
      "jx_nest_base model average inference time : 13.895213603973389ms\n",
      "Benchmarking Inference swsl_resnext101_32x16d \n",
      "swsl_resnext101_32x16d model average inference time : 35.57924032211304ms\n",
      "Benchmarking Inference xcit_medium_24_p8_224 \n",
      "xcit_medium_24_p8_224 model average inference time : 41.584742069244385ms\n",
      "Benchmarking Inference swsl_resnext50_32x4d \n",
      "swsl_resnext50_32x4d model average inference time : 7.035844326019287ms\n",
      "Benchmarking Inference levit_384 \n",
      "levit_384 model average inference time : 8.390529155731201ms\n",
      "Benchmarking Inference jx_nest_small \n",
      "jx_nest_small model average inference time : 10.838394165039062ms\n",
      "Benchmarking Inference resnetv2_152x2_bit_teacher \n",
      "resnetv2_152x2_bit_teacher model average inference time : 46.67759895324707ms\n",
      "Benchmarking Inference resnet152 \n",
      "resnet152 model average inference time : 14.783093929290771ms\n",
      "Benchmarking Inference coat_lite_small \n",
      "coat_lite_small model average inference time : 13.37568998336792ms\n",
      "Benchmarking Inference xcit_tiny_24_p8_224 \n",
      "xcit_tiny_24_p8_224 model average inference time : 18.555846214294434ms\n",
      "Benchmarking Inference resnetv2_101 \n",
      "resnetv2_101 model average inference time : 10.43726921081543ms\n",
      "Benchmarking Inference convnext_tiny \n",
      "convnext_tiny model average inference time : 5.076277256011963ms\n",
      "Benchmarking Inference ecaresnet101d \n",
      "ecaresnet101d model average inference time : 13.19871187210083ms\n",
      "Benchmarking Inference pit_s_distilled_224 \n",
      "pit_s_distilled_224 model average inference time : 5.891351699829102ms\n",
      "pass poolformer_m48\n",
      "Benchmarking Inference tresnet_xl \n",
      "pass tresnet_xl\n",
      "Benchmarking Inference mixer_b16_224_miil \n",
      "mixer_b16_224_miil model average inference time : 5.02307653427124ms\n",
      "Benchmarking Inference xcit_tiny_12_p8_224_dist \n",
      "xcit_tiny_12_p8_224_dist model average inference time : 10.722513198852539ms\n",
      "Benchmarking Inference convit_base \n",
      "convit_base model average inference time : 10.301809310913086ms\n",
      "Benchmarking Inference visformer_small \n",
      "visformer_small model average inference time : 12.261354923248291ms\n",
      "Benchmarking Inference xcit_small_24_p16_224 \n",
      "xcit_small_24_p16_224 model average inference time : 18.74488592147827ms\n",
      "pass swin_s3_tiny_224\n",
      "Benchmarking Inference resnet101 \n",
      "resnet101 model average inference time : 10.390040874481201ms\n",
      "Benchmarking Inference convit_small \n",
      "convit_small model average inference time : 7.084593772888184ms\n",
      "Benchmarking Inference xcit_small_12_p16_224 \n",
      "xcit_small_12_p16_224 model average inference time : 10.7073974609375ms\n",
      "Benchmarking Inference jx_nest_tiny \n",
      "jx_nest_tiny model average inference time : 7.253236770629883ms\n",
      "Benchmarking Inference deit_small_distilled_patch16_224 \n",
      "deit_small_distilled_patch16_224 model average inference time : 5.374166965484619ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference resmlp_36_distilled_224 \n",
      "resmlp_36_distilled_224 model average inference time : 8.577532768249512ms\n",
      "Benchmarking Inference xcit_large_24_p16_224 \n",
      "xcit_large_24_p16_224 model average inference time : 20.206291675567627ms\n",
      "pass poolformer_m36\n",
      "Benchmarking Inference xcit_medium_24_p16_224 \n",
      "xcit_medium_24_p16_224 model average inference time : 18.9121413230896ms\n",
      "Benchmarking Inference convnext_tiny_hnf \n",
      "convnext_tiny_hnf model average inference time : 5.20892858505249ms\n",
      "Benchmarking Inference tnt_s_patch16_224 \n",
      "tnt_s_patch16_224 model average inference time : 11.865389347076416ms\n",
      "Benchmarking Inference ssl_resnext101_32x16d \n",
      "ssl_resnext101_32x16d model average inference time : 35.50900459289551ms\n",
      "Benchmarking Inference vit_small_patch16_224 \n",
      "vit_small_patch16_224 model average inference time : 5.314064025878906ms\n",
      "Benchmarking Inference vit_small_r26_s32_224 \n",
      "vit_small_r26_s32_224 model average inference time : 9.324173927307129ms\n",
      "Benchmarking Inference convmixer_1536_20 \n",
      "pass convmixer_1536_20\n",
      "Benchmarking Inference rexnet_200 \n",
      "rexnet_200 model average inference time : 8.676526546478271ms\n",
      "Benchmarking Inference deit_base_patch16_224 \n",
      "deit_base_patch16_224 model average inference time : 7.112069129943848ms\n",
      "Benchmarking Inference swsl_resnet50 \n",
      "swsl_resnet50 model average inference time : 5.69875955581665ms\n",
      "Benchmarking Inference ssl_resnext101_32x8d \n",
      "ssl_resnext101_32x8d model average inference time : 19.221656322479248ms\n",
      "Benchmarking Inference coat_mini \n",
      "coat_mini model average inference time : 22.50577211380005ms\n",
      "Benchmarking Inference tresnet_l \n",
      "pass tresnet_l\n",
      "Benchmarking Inference twins_svt_small \n",
      "twins_svt_small model average inference time : 9.938509464263916ms\n",
      "Benchmarking Inference levit_256 \n",
      "levit_256 model average inference time : 7.915101051330566ms\n",
      "Benchmarking Inference seresnext50_32x4d \n",
      "seresnext50_32x4d model average inference time : 10.353505611419678ms\n",
      "Benchmarking Inference pit_b_224 \n",
      "pit_b_224 model average inference time : 8.090710639953613ms\n",
      "Benchmarking Inference swin_tiny_patch4_window7_224 \n",
      "swin_tiny_patch4_window7_224 model average inference time : 7.008519172668457ms\n",
      "Benchmarking Inference wide_resnet50_2 \n",
      "wide_resnet50_2 model average inference time : 11.220738887786865ms\n",
      "pass poolformer_s36\n",
      "Benchmarking Inference twins_pcpvt_small \n",
      "twins_pcpvt_small model average inference time : 10.364930629730225ms\n",
      "Benchmarking Inference resmlp_24_distilled_224 \n",
      "resmlp_24_distilled_224 model average inference time : 6.013643741607666ms\n",
      "Benchmarking Inference resnest50d_4s2x40d \n",
      "resnest50d_4s2x40d model average inference time : 22.737603187561035ms\n",
      "Benchmarking Inference repvgg_b3 \n",
      "repvgg_b3 model average inference time : 19.03630495071411ms\n",
      "Benchmarking Inference xcit_tiny_24_p16_224_dist \n",
      "xcit_tiny_24_p16_224_dist model average inference time : 19.14799451828003ms\n",
      "Benchmarking Inference ssl_resnext101_32x4d \n",
      "ssl_resnext101_32x4d model average inference time : 12.40248441696167ms\n",
      "Benchmarking Inference ecaresnet50d \n",
      "ecaresnet50d model average inference time : 7.260231971740723ms\n",
      "Benchmarking Inference gluon_resnet152_v1s \n",
      "gluon_resnet152_v1s model average inference time : 14.737098217010498ms\n",
      "Benchmarking Inference haloregnetz_b \n",
      "haloregnetz_b model average inference time : 13.67612361907959ms\n",
      "Benchmarking Inference resnest50d_1s4x24d \n",
      "resnest50d_1s4x24d model average inference time : 14.005622863769531ms\n",
      "Benchmarking Inference repvgg_b3g4 \n",
      "repvgg_b3g4 model average inference time : 21.469557285308838ms\n",
      "Benchmarking Inference legacy_senet154 \n",
      "legacy_senet154 model average inference time : 34.78443145751953ms\n",
      "Benchmarking Inference cait_xxs36_224 \n",
      "cait_xxs36_224 model average inference time : 20.45429229736328ms\n",
      "Benchmarking Inference resnext50_32x4d \n",
      "resnext50_32x4d model average inference time : 6.816830635070801ms\n",
      "Benchmarking Inference gernet_m \n",
      "gernet_m model average inference time : 5.102229118347168ms\n",
      "Benchmarking Inference pit_s_224 \n",
      "pit_s_224 model average inference time : 5.802435874938965ms\n",
      "Benchmarking Inference gluon_senet154 \n",
      "gluon_senet154 model average inference time : 34.912269115448ms\n",
      "Benchmarking Inference resnest50d \n",
      "resnest50d model average inference time : 13.726053237915039ms\n",
      "Benchmarking Inference convmixer_768_32 \n",
      "pass convmixer_768_32\n",
      "Benchmarking Inference ecaresnet101d_pruned \n",
      "ecaresnet101d_pruned model average inference time : 12.104275226593018ms\n",
      "Benchmarking Inference rexnet_150 \n",
      "rexnet_150 model average inference time : 8.617901802062988ms\n",
      "Benchmarking Inference xcit_tiny_12_p8_224 \n",
      "xcit_tiny_12_p8_224 model average inference time : 10.457496643066406ms\n",
      "Benchmarking Inference ssl_resnext50_32x4d \n",
      "ssl_resnext50_32x4d model average inference time : 7.0175957679748535ms\n",
      "Benchmarking Inference gluon_resnet101_v1s \n",
      "gluon_resnet101_v1s model average inference time : 10.573070049285889ms\n",
      "Benchmarking Inference ecaresnetlight \n",
      "ecaresnetlight model average inference time : 6.995887756347656ms\n",
      "pass poolformer_s24\n",
      "Benchmarking Inference gluon_seresnext101_32x4d \n",
      "gluon_seresnext101_32x4d model average inference time : 20.58621644973755ms\n",
      "Benchmarking Inference resnetv2_50 \n",
      "resnetv2_50 model average inference time : 5.7357048988342285ms\n",
      "Benchmarking Inference resnet50d \n",
      "resnet50d model average inference time : 6.155939102172852ms\n",
      "Benchmarking Inference gluon_seresnext101_64x4d \n",
      "gluon_seresnext101_64x4d model average inference time : 23.90171766281128ms\n",
      "Benchmarking Inference vit_base_patch32_224 \n",
      "vit_base_patch32_224 model average inference time : 5.4349684715271ms\n",
      "Benchmarking Inference gluon_resnet152_v1d \n",
      "gluon_resnet152_v1d model average inference time : 14.936988353729248ms\n",
      "Benchmarking Inference resnet50_gn \n",
      "resnet50_gn model average inference time : 6.199815273284912ms\n",
      "pass vit_base_patch16_224_sam\n",
      "Benchmarking Inference seresnet50 \n",
      "seresnet50 model average inference time : 8.887426853179932ms\n",
      "Benchmarking Inference gluon_resnet101_v1d \n",
      "gluon_resnet101_v1d model average inference time : 10.5153489112854ms\n",
      "Benchmarking Inference repvgg_b2g4 \n",
      "repvgg_b2g4 model average inference time : 19.929993152618408ms\n",
      "Benchmarking Inference mixnet_xl \n",
      "mixnet_xl model average inference time : 15.671555995941162ms\n",
      "Benchmarking Inference cspresnext50 \n",
      "cspresnext50 model average inference time : 6.937711238861084ms\n",
      "Benchmarking Inference ese_vovnet39b \n",
      "ese_vovnet39b model average inference time : 6.915445327758789ms\n",
      "Benchmarking Inference gluon_resnext101_32x4d \n",
      "gluon_resnext101_32x4d model average inference time : 12.917296886444092ms\n",
      "Benchmarking Inference legacy_seresnext101_32x4d \n",
      "legacy_seresnext101_32x4d model average inference time : 20.41252374649048ms\n",
      "Benchmarking Inference xcit_tiny_24_p16_224 \n",
      "xcit_tiny_24_p16_224 model average inference time : 19.209411144256592ms\n",
      "Benchmarking Inference regnety_320 \n",
      "regnety_320 model average inference time : 36.98447227478027ms\n",
      "Benchmarking Inference resnet50 \n",
      "resnet50 model average inference time : 5.773820877075195ms\n",
      "Benchmarking Inference resmlp_big_24_224 \n",
      "resmlp_big_24_224 model average inference time : 34.094531536102295ms\n",
      "Benchmarking Inference gluon_resnext101_64x4d \n",
      "gluon_resnext101_64x4d model average inference time : 19.746713638305664ms\n",
      "Benchmarking Inference deit_small_patch16_224 \n",
      "deit_small_patch16_224 model average inference time : 5.586421489715576ms\n",
      "Benchmarking Inference pit_xs_distilled_224 \n",
      "pit_xs_distilled_224 model average inference time : 5.78035831451416ms\n",
      "Benchmarking Inference dpn107 \n",
      "dpn107 model average inference time : 25.14744758605957ms\n",
      "Benchmarking Inference resmlp_36_224 \n",
      "resmlp_36_224 model average inference time : 8.780181407928467ms\n",
      "Benchmarking Inference ecaresnet50d_pruned \n",
      "ecaresnet50d_pruned model average inference time : 7.013001441955566ms\n",
      "Benchmarking Inference gluon_resnet152_v1c \n",
      "gluon_resnet152_v1c model average inference time : 14.960885047912598ms\n",
      "Benchmarking Inference levit_192 \n",
      "levit_192 model average inference time : 7.703721523284912ms\n",
      "Benchmarking Inference resnext50d_32x4d \n",
      "resnext50d_32x4d model average inference time : 7.077133655548096ms\n",
      "Benchmarking Inference regnety_120 \n",
      "regnety_120 model average inference time : 23.424253463745117ms\n",
      "Benchmarking Inference regnetx_320 \n",
      "regnetx_320 model average inference time : 36.52901649475098ms\n",
      "Benchmarking Inference dpn92 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dpn92 model average inference time : 12.669572830200195ms\n",
      "Benchmarking Inference rexnet_130 \n",
      "rexnet_130 model average inference time : 8.681139945983887ms\n",
      "Benchmarking Inference gluon_resnet152_v1b \n",
      "gluon_resnet152_v1b model average inference time : 14.61836576461792ms\n",
      "Benchmarking Inference resnetrs50 \n",
      "resnetrs50 model average inference time : 9.30058479309082ms\n",
      "Benchmarking Inference dpn131 \n",
      "dpn131 model average inference time : 23.13347816467285ms\n",
      "Benchmarking Inference regnetx_160 \n",
      "regnetx_160 model average inference time : 26.61684513092041ms\n",
      "Benchmarking Inference dla102x2 \n",
      "dla102x2 model average inference time : 16.012027263641357ms\n",
      "Benchmarking Inference gmlp_s16_224 \n",
      "gmlp_s16_224 model average inference time : 7.957139015197754ms\n",
      "Benchmarking Inference gluon_seresnext50_32x4d \n",
      "gluon_seresnext50_32x4d model average inference time : 10.371260643005371ms\n",
      "Benchmarking Inference skresnext50_32x4d \n",
      "skresnext50_32x4d model average inference time : 13.965444564819336ms\n",
      "Benchmarking Inference dpn98 \n",
      "dpn98 model average inference time : 16.97061538696289ms\n",
      "Benchmarking Inference gluon_resnet101_v1c \n",
      "gluon_resnet101_v1c model average inference time : 10.414409637451172ms\n",
      "Benchmarking Inference dpn68b \n",
      "dpn68b model average inference time : 10.688762664794922ms\n",
      "Benchmarking Inference resnetblur50 \n",
      "resnetblur50 model average inference time : 5.85850715637207ms\n",
      "Benchmarking Inference resmlp_24_224 \n",
      "resmlp_24_224 model average inference time : 6.24377965927124ms\n",
      "Benchmarking Inference coat_lite_mini \n",
      "coat_lite_mini model average inference time : 7.415227890014648ms\n",
      "Benchmarking Inference cait_xxs24_224 \n",
      "cait_xxs24_224 model average inference time : 14.695963859558105ms\n",
      "Benchmarking Inference xcit_tiny_12_p16_224_dist \n",
      "xcit_tiny_12_p16_224_dist model average inference time : 11.01663589477539ms\n",
      "Benchmarking Inference resnext101_32x8d \n",
      "resnext101_32x8d model average inference time : 19.250683784484863ms\n",
      "Benchmarking Inference hrnet_w48 \n",
      "hrnet_w48 model average inference time : 35.442304611206055ms\n",
      "Benchmarking Inference gluon_resnet101_v1b \n",
      "gluon_resnet101_v1b model average inference time : 10.232810974121094ms\n",
      "Benchmarking Inference regnetx_120 \n",
      "regnetx_120 model average inference time : 21.471972465515137ms\n",
      "Benchmarking Inference hrnet_w64 \n",
      "hrnet_w64 model average inference time : 32.543818950653076ms\n",
      "Benchmarking Inference ssl_resnet50 \n",
      "ssl_resnet50 model average inference time : 5.5466628074646ms\n",
      "Benchmarking Inference res2net101_26w_4s \n",
      "res2net101_26w_4s model average inference time : 18.502306938171387ms\n",
      "Benchmarking Inference gluon_resnext50_32x4d \n",
      "gluon_resnext50_32x4d model average inference time : 6.836404800415039ms\n",
      "Benchmarking Inference resnest26d \n",
      "resnest26d model average inference time : 9.149255752563477ms\n",
      "Benchmarking Inference tf_efficientnet_b0_ns \n",
      "tf_efficientnet_b0_ns model average inference time : 7.553682327270508ms\n",
      "Benchmarking Inference coat_tiny \n",
      "coat_tiny model average inference time : 21.694064140319824ms\n",
      "Benchmarking Inference dla169 \n",
      "dla169 model average inference time : 16.40092372894287ms\n",
      "Benchmarking Inference legacy_seresnext50_32x4d \n",
      "legacy_seresnext50_32x4d model average inference time : 10.21946907043457ms\n",
      "Benchmarking Inference hrnet_w44 \n",
      "hrnet_w44 model average inference time : 35.05104064941406ms\n",
      "Benchmarking Inference regnetx_080 \n",
      "regnetx_080 model average inference time : 16.2624454498291ms\n",
      "Benchmarking Inference gluon_resnet50_v1s \n",
      "gluon_resnet50_v1s model average inference time : 6.048216819763184ms\n",
      "Benchmarking Inference res2net50_26w_8s \n",
      "res2net50_26w_8s model average inference time : 16.55200719833374ms\n",
      "Benchmarking Inference levit_128 \n",
      "levit_128 model average inference time : 7.457218170166016ms\n",
      "Benchmarking Inference gluon_resnet50_v1d \n",
      "gluon_resnet50_v1d model average inference time : 5.979855060577393ms\n",
      "Benchmarking Inference dla60_res2next \n",
      "dla60_res2next model average inference time : 16.676864624023438ms\n",
      "Benchmarking Inference mixnet_l \n",
      "mixnet_l model average inference time : 12.020494937896729ms\n",
      "Benchmarking Inference tv_resnet152 \n",
      "tv_resnet152 model average inference time : 14.778411388397217ms\n",
      "Benchmarking Inference dla102x \n",
      "dla102x model average inference time : 12.80745267868042ms\n",
      "Benchmarking Inference dla60_res2net \n",
      "dla60_res2net model average inference time : 10.99360704421997ms\n",
      "Benchmarking Inference pit_xs_224 \n",
      "pit_xs_224 model average inference time : 5.574824810028076ms\n",
      "Benchmarking Inference regnetx_064 \n",
      "regnetx_064 model average inference time : 10.881218910217285ms\n",
      "Benchmarking Inference hrnet_w40 \n",
      "hrnet_w40 model average inference time : 32.84000873565674ms\n",
      "Benchmarking Inference res2net50_26w_6s \n",
      "res2net50_26w_6s model average inference time : 13.051064014434814ms\n",
      "Benchmarking Inference repvgg_b2 \n",
      "repvgg_b2 model average inference time : 13.539295196533203ms\n",
      "Benchmarking Inference resmlp_12_distilled_224 \n",
      "resmlp_12_distilled_224 model average inference time : 3.6040902137756348ms\n",
      "Benchmarking Inference legacy_seresnet152 \n",
      "legacy_seresnet152 model average inference time : 26.476173400878906ms\n",
      "Benchmarking Inference selecsls60b \n",
      "selecsls60b model average inference time : 6.78408145904541ms\n",
      "Benchmarking Inference hrnet_w32 \n",
      "hrnet_w32 model average inference time : 32.459938526153564ms\n",
      "Benchmarking Inference tf_efficientnetv2_b0 \n",
      "tf_efficientnetv2_b0 model average inference time : 9.069797992706299ms\n",
      "Benchmarking Inference regnetx_040 \n",
      "regnetx_040 model average inference time : 9.452488422393799ms\n",
      "Benchmarking Inference efficientnet_es \n",
      "efficientnet_es model average inference time : 4.622650146484375ms\n",
      "Benchmarking Inference hrnet_w30 \n",
      "hrnet_w30 model average inference time : 32.88370132446289ms\n",
      "Benchmarking Inference tf_mixnet_l \n",
      "tf_mixnet_l model average inference time : 12.54335880279541ms\n",
      "Benchmarking Inference wide_resnet101_2 \n",
      "wide_resnet101_2 model average inference time : 18.53970766067505ms\n",
      "Benchmarking Inference dla60x \n",
      "dla60x model average inference time : 7.748398780822754ms\n",
      "Benchmarking Inference legacy_seresnet101 \n",
      "legacy_seresnet101 model average inference time : 17.77522087097168ms\n",
      "Benchmarking Inference coat_lite_tiny \n",
      "coat_lite_tiny model average inference time : 7.747297286987305ms\n",
      "Benchmarking Inference repvgg_b1 \n",
      "repvgg_b1 model average inference time : 10.340573787689209ms\n",
      "Benchmarking Inference res2net50_26w_4s \n",
      "res2net50_26w_4s model average inference time : 9.812300205230713ms\n",
      "Benchmarking Inference hardcorenas_f \n",
      "hardcorenas_f model average inference time : 7.513260841369629ms\n",
      "Benchmarking Inference res2net50_14w_8s \n",
      "res2net50_14w_8s model average inference time : 15.492770671844482ms\n",
      "Benchmarking Inference selecsls60 \n",
      "selecsls60 model average inference time : 6.7041850090026855ms\n",
      "Benchmarking Inference regnetx_032 \n",
      "regnetx_032 model average inference time : 9.24436092376709ms\n",
      "Benchmarking Inference res2next50 \n",
      "res2next50 model average inference time : 16.0325288772583ms\n",
      "Benchmarking Inference gluon_resnet50_v1c \n",
      "gluon_resnet50_v1c model average inference time : 6.02961540222168ms\n",
      "Benchmarking Inference dla102 \n",
      "dla102 model average inference time : 11.158323287963867ms\n",
      "Benchmarking Inference rexnet_100 \n",
      "rexnet_100 model average inference time : 8.488998413085938ms\n",
      "Benchmarking Inference res2net50_48w_2s \n",
      "res2net50_48w_2s model average inference time : 6.8399739265441895ms\n",
      "Benchmarking Inference xcit_tiny_12_p16_224 \n",
      "xcit_tiny_12_p16_224 model average inference time : 10.742213726043701ms\n",
      "Benchmarking Inference resnet34d \n",
      "resnet34d model average inference time : 4.444456100463867ms\n",
      "pass poolformer_s12\n",
      "Benchmarking Inference efficientnet_b0 \n",
      "efficientnet_b0 model average inference time : 7.722764015197754ms\n",
      "Benchmarking Inference hardcorenas_e \n",
      "hardcorenas_e model average inference time : 7.862691879272461ms\n",
      "Benchmarking Inference gmixer_24_224 \n",
      "gmixer_24_224 model average inference time : 8.633630275726318ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b0_8e \n",
      "tf_efficientnet_cc_b0_8e model average inference time : 9.532198905944824ms\n",
      "Benchmarking Inference regnety_016 \n",
      "regnety_016 model average inference time : 13.075990676879883ms\n",
      "Benchmarking Inference tv_resnext50_32x4d \n",
      "tv_resnext50_32x4d model average inference time : 6.84128999710083ms\n",
      "Benchmarking Inference gluon_resnet50_v1b \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gluon_resnet50_v1b model average inference time : 5.709357261657715ms\n",
      "Benchmarking Inference densenet161 \n",
      "densenet161 model average inference time : 18.180179595947266ms\n",
      "Benchmarking Inference mobilenetv2_120d \n",
      "mobilenetv2_120d model average inference time : 6.398036479949951ms\n",
      "Benchmarking Inference seresnext26t_32x4d \n",
      "seresnext26t_32x4d model average inference time : 6.067569255828857ms\n",
      "Benchmarking Inference tv_resnet101 \n",
      "tv_resnet101 model average inference time : 10.200674533843994ms\n",
      "Benchmarking Inference hardcorenas_d \n",
      "hardcorenas_d model average inference time : 7.6938605308532715ms\n",
      "Benchmarking Inference seresnext26d_32x4d \n",
      "seresnext26d_32x4d model average inference time : 6.100883483886719ms\n",
      "Benchmarking Inference dla60 \n",
      "dla60 model average inference time : 6.960539817810059ms\n",
      "Benchmarking Inference xcit_nano_12_p8_224_dist \n",
      "xcit_nano_12_p8_224_dist model average inference time : 10.60863733291626ms\n",
      "Benchmarking Inference repvgg_b1g4 \n",
      "repvgg_b1g4 model average inference time : 15.697145462036133ms\n",
      "Benchmarking Inference convmixer_1024_20_ks9_p14 \n",
      "pass convmixer_1024_20_ks9_p14\n",
      "Benchmarking Inference legacy_seresnet50 \n",
      "legacy_seresnet50 model average inference time : 9.095869064331055ms\n",
      "Benchmarking Inference tf_efficientnet_b0_ap \n",
      "tf_efficientnet_b0_ap model average inference time : 7.9328179359436035ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b0_4e \n",
      "tf_efficientnet_cc_b0_4e model average inference time : 9.515957832336426ms\n",
      "Benchmarking Inference skresnet34 \n",
      "skresnet34 model average inference time : 11.576557159423828ms\n",
      "Benchmarking Inference resmlp_12_224 \n",
      "resmlp_12_224 model average inference time : 3.418292999267578ms\n",
      "Benchmarking Inference mobilenetv3_large_100_miil \n",
      "mobilenetv3_large_100_miil model average inference time : 5.8875322341918945ms\n",
      "Benchmarking Inference densenet201 \n",
      "densenet201 model average inference time : 22.708756923675537ms\n",
      "Benchmarking Inference gernet_s \n",
      "gernet_s model average inference time : 4.930844306945801ms\n",
      "Benchmarking Inference legacy_seresnext26_32x4d \n",
      "legacy_seresnext26_32x4d model average inference time : 5.834329128265381ms\n",
      "Benchmarking Inference mixnet_m \n",
      "mixnet_m model average inference time : 11.8780517578125ms\n",
      "Benchmarking Inference tf_efficientnet_b0 \n",
      "tf_efficientnet_b0 model average inference time : 7.822632789611816ms\n",
      "Benchmarking Inference hrnet_w18 \n",
      "hrnet_w18 model average inference time : 30.394515991210938ms\n",
      "Benchmarking Inference densenetblur121d \n",
      "densenetblur121d model average inference time : 13.929440975189209ms\n",
      "Benchmarking Inference selecsls42b \n",
      "selecsls42b model average inference time : 5.317094326019287ms\n",
      "Benchmarking Inference hardcorenas_c \n",
      "hardcorenas_c model average inference time : 5.877339839935303ms\n",
      "Benchmarking Inference regnetx_016 \n",
      "regnetx_016 model average inference time : 6.857666969299316ms\n",
      "Benchmarking Inference dpn68 \n",
      "dpn68 model average inference time : 9.795167446136475ms\n",
      "Benchmarking Inference mobilenetv2_140 \n",
      "mobilenetv2_140 model average inference time : 4.393730163574219ms\n",
      "Benchmarking Inference tf_efficientnet_es \n",
      "tf_efficientnet_es model average inference time : 4.962162971496582ms\n",
      "Benchmarking Inference tf_mixnet_m \n",
      "tf_mixnet_m model average inference time : 12.627298831939697ms\n",
      "Benchmarking Inference ese_vovnet19b_dw \n",
      "ese_vovnet19b_dw model average inference time : 4.190046787261963ms\n",
      "Benchmarking Inference levit_128s \n",
      "levit_128s model average inference time : 6.306872367858887ms\n",
      "Benchmarking Inference resnet26d \n",
      "resnet26d model average inference time : 3.9606857299804688ms\n",
      "Benchmarking Inference repvgg_a2 \n",
      "repvgg_a2 model average inference time : 5.6511616706848145ms\n",
      "Benchmarking Inference tv_resnet50 \n",
      "tv_resnet50 model average inference time : 5.752856731414795ms\n",
      "Benchmarking Inference hardcorenas_b \n",
      "hardcorenas_b model average inference time : 5.313284397125244ms\n",
      "Benchmarking Inference densenet121 \n",
      "densenet121 model average inference time : 13.66246223449707ms\n",
      "Benchmarking Inference densenet169 \n",
      "densenet169 model average inference time : 19.266939163208008ms\n",
      "Benchmarking Inference mixnet_s \n",
      "mixnet_s model average inference time : 9.835643768310547ms\n",
      "Benchmarking Inference vit_small_patch32_224 \n",
      "vit_small_patch32_224 model average inference time : 5.282011032104492ms\n",
      "Benchmarking Inference regnety_008 \n",
      "regnety_008 model average inference time : 7.687127590179443ms\n",
      "Benchmarking Inference efficientnet_lite0 \n",
      "efficientnet_lite0 model average inference time : 4.397320747375488ms\n",
      "Benchmarking Inference resnest14d \n",
      "resnest14d model average inference time : 6.806044578552246ms\n",
      "Benchmarking Inference hardcorenas_a \n",
      "hardcorenas_a model average inference time : 4.8999786376953125ms\n",
      "Benchmarking Inference efficientnet_es_pruned \n",
      "efficientnet_es_pruned model average inference time : 4.652845859527588ms\n",
      "Benchmarking Inference mobilenetv3_rw \n",
      "mobilenetv3_rw model average inference time : 5.950417518615723ms\n",
      "Benchmarking Inference semnasnet_100 \n",
      "semnasnet_100 model average inference time : 5.771811008453369ms\n",
      "Benchmarking Inference mobilenetv3_large_100 \n",
      "mobilenetv3_large_100 model average inference time : 6.3648223876953125ms\n",
      "Benchmarking Inference resnet34 \n",
      "resnet34 model average inference time : 4.3703293800354ms\n",
      "Benchmarking Inference vit_tiny_patch16_224 \n",
      "vit_tiny_patch16_224 model average inference time : 5.5307722091674805ms\n",
      "Benchmarking Inference mobilenetv2_110d \n",
      "mobilenetv2_110d model average inference time : 5.535926818847656ms\n",
      "Benchmarking Inference tf_mixnet_s \n",
      "tf_mixnet_s model average inference time : 10.418744087219238ms\n",
      "Benchmarking Inference repvgg_b0 \n",
      "repvgg_b0 model average inference time : 6.795341968536377ms\n",
      "Benchmarking Inference deit_tiny_distilled_patch16_224 \n",
      "deit_tiny_distilled_patch16_224 model average inference time : 5.380315780639648ms\n",
      "Benchmarking Inference mixer_b16_224 \n",
      "mixer_b16_224 model average inference time : 4.956786632537842ms\n",
      "Benchmarking Inference pit_ti_distilled_224 \n",
      "pit_ti_distilled_224 model average inference time : 5.767495632171631ms\n",
      "Benchmarking Inference hrnet_w18_small_v2 \n",
      "hrnet_w18_small_v2 model average inference time : 16.956512928009033ms\n",
      "Benchmarking Inference resnet26 \n",
      "resnet26 model average inference time : 3.737163543701172ms\n",
      "Benchmarking Inference tf_efficientnet_lite0 \n",
      "tf_efficientnet_lite0 model average inference time : 4.358277320861816ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_100 \n",
      "tf_mobilenetv3_large_100 model average inference time : 6.118559837341309ms\n",
      "Benchmarking Inference tv_densenet121 \n",
      "tv_densenet121 model average inference time : 13.866865634918213ms\n",
      "Benchmarking Inference regnety_006 \n",
      "regnety_006 model average inference time : 8.436896800994873ms\n",
      "Benchmarking Inference dla34 \n",
      "dla34 model average inference time : 4.560897350311279ms\n",
      "Benchmarking Inference xcit_nano_12_p8_224 \n",
      "xcit_nano_12_p8_224 model average inference time : 10.833866596221924ms\n",
      "Benchmarking Inference fbnetc_100 \n",
      "fbnetc_100 model average inference time : 5.327892303466797ms\n",
      "Benchmarking Inference legacy_seresnet34 \n",
      "legacy_seresnet34 model average inference time : 6.90471887588501ms\n",
      "Benchmarking Inference gluon_resnet34_v1b \n",
      "gluon_resnet34_v1b model average inference time : 4.467740058898926ms\n",
      "Benchmarking Inference regnetx_008 \n",
      "regnetx_008 model average inference time : 5.900390148162842ms\n",
      "Benchmarking Inference mnasnet_100 \n",
      "mnasnet_100 model average inference time : 4.553892612457275ms\n",
      "Benchmarking Inference vgg19_bn \n",
      "vgg19_bn model average inference time : 12.30588674545288ms\n",
      "Benchmarking Inference convit_tiny \n",
      "convit_tiny model average inference time : 7.331175804138184ms\n",
      "Benchmarking Inference spnasnet_100 \n",
      "spnasnet_100 model average inference time : 5.1381754875183105ms\n",
      "Benchmarking Inference ghostnet_100 \n",
      "ghostnet_100 model average inference time : 9.09602165222168ms\n",
      "Benchmarking Inference regnety_004 \n",
      "regnety_004 model average inference time : 10.290906429290771ms\n",
      "Benchmarking Inference skresnet18 \n",
      "skresnet18 model average inference time : 6.64794921875ms\n",
      "Benchmarking Inference regnetx_006 \n",
      "regnetx_006 model average inference time : 5.949075222015381ms\n",
      "Benchmarking Inference pit_ti_224 \n",
      "pit_ti_224 model average inference time : 5.768704414367676ms\n",
      "Benchmarking Inference swsl_resnet18 \n",
      "swsl_resnet18 model average inference time : 2.929062843322754ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference vgg16_bn \n",
      "vgg16_bn model average inference time : 10.73566198348999ms\n",
      "Benchmarking Inference semnasnet_075 \n",
      "semnasnet_075 model average inference time : 5.941629409790039ms\n",
      "Benchmarking Inference tv_resnet34 \n",
      "tv_resnet34 model average inference time : 4.107306003570557ms\n",
      "Benchmarking Inference resnet18d \n",
      "resnet18d model average inference time : 3.145148754119873ms\n",
      "Benchmarking Inference mobilenetv2_100 \n",
      "mobilenetv2_100 model average inference time : 4.582910537719727ms\n",
      "Benchmarking Inference xcit_nano_12_p16_224_dist \n",
      "xcit_nano_12_p16_224_dist model average inference time : 10.572693347930908ms\n",
      "pass vit_base_patch32_224_sam\n",
      "Benchmarking Inference ssl_resnet18 \n",
      "ssl_resnet18 model average inference time : 2.853367328643799ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_075 \n",
      "tf_mobilenetv3_large_075 model average inference time : 6.057429313659668ms\n",
      "Benchmarking Inference deit_tiny_patch16_224 \n",
      "deit_tiny_patch16_224 model average inference time : 5.405433177947998ms\n",
      "Benchmarking Inference hrnet_w18_small \n",
      "hrnet_w18_small model average inference time : 9.77731466293335ms\n",
      "Benchmarking Inference vgg19 \n",
      "vgg19 model average inference time : 11.525249481201172ms\n",
      "Benchmarking Inference regnetx_004 \n",
      "regnetx_004 model average inference time : 8.871192932128906ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_minimal_100 \n",
      "tf_mobilenetv3_large_minimal_100 model average inference time : 4.2511749267578125ms\n",
      "Benchmarking Inference legacy_seresnet18 \n",
      "legacy_seresnet18 model average inference time : 4.143624305725098ms\n",
      "Benchmarking Inference vgg16 \n",
      "vgg16 model average inference time : 10.0022554397583ms\n",
      "Benchmarking Inference vgg13_bn \n",
      "vgg13_bn model average inference time : 9.130573272705078ms\n",
      "Benchmarking Inference vit_tiny_r_s16_p8_224 \n",
      "vit_tiny_r_s16_p8_224 model average inference time : 5.409998893737793ms\n",
      "Benchmarking Inference lcnet_100 \n",
      "lcnet_100 model average inference time : 3.202395439147949ms\n",
      "Benchmarking Inference gluon_resnet18_v1b \n",
      "gluon_resnet18_v1b model average inference time : 2.834024429321289ms\n",
      "Benchmarking Inference vgg11_bn \n",
      "vgg11_bn model average inference time : 7.411701679229736ms\n",
      "Benchmarking Inference xcit_nano_12_p16_224 \n",
      "xcit_nano_12_p16_224 model average inference time : 10.727806091308594ms\n",
      "Benchmarking Inference regnety_002 \n",
      "regnety_002 model average inference time : 8.449339866638184ms\n",
      "Benchmarking Inference mixer_l16_224 \n",
      "mixer_l16_224 model average inference time : 15.56145191192627ms\n",
      "Benchmarking Inference resnet18 \n",
      "resnet18 model average inference time : 2.7750158309936523ms\n",
      "Benchmarking Inference vgg13 \n",
      "vgg13 model average inference time : 8.489997386932373ms\n",
      "Benchmarking Inference vgg11 \n",
      "vgg11 model average inference time : 6.989898681640625ms\n",
      "Benchmarking Inference regnetx_002 \n",
      "regnetx_002 model average inference time : 5.940618515014648ms\n",
      "Benchmarking Inference lcnet_075 \n",
      "lcnet_075 model average inference time : 3.65983247756958ms\n",
      "Benchmarking Inference dla60x_c \n",
      "dla60x_c model average inference time : 6.474413871765137ms\n",
      "Benchmarking Inference mobilenetv3_small_100 \n",
      "mobilenetv3_small_100 model average inference time : 4.966714382171631ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_100 \n",
      "tf_mobilenetv3_small_100 model average inference time : 4.927332401275635ms\n",
      "Benchmarking Inference mnasnet_small \n",
      "mnasnet_small model average inference time : 6.198482513427734ms\n",
      "Benchmarking Inference dla46x_c \n",
      "dla46x_c model average inference time : 5.030632019042969ms\n",
      "Benchmarking Inference mobilenetv2_050 \n",
      "mobilenetv2_050 model average inference time : 4.8744964599609375ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_075 \n",
      "tf_mobilenetv3_small_075 model average inference time : 5.385587215423584ms\n",
      "Benchmarking Inference dla46_c \n",
      "dla46_c model average inference time : 5.167293548583984ms\n",
      "Benchmarking Inference mobilenetv3_small_075 \n",
      "mobilenetv3_small_075 model average inference time : 5.276763439178467ms\n",
      "Benchmarking Inference lcnet_050 \n",
      "lcnet_050 model average inference time : 3.289806842803955ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_minimal_100 \n",
      "tf_mobilenetv3_small_minimal_100 model average inference time : 3.4982943534851074ms\n",
      "Benchmarking Inference mobilenetv3_small_050 \n",
      "mobilenetv3_small_050 model average inference time : 4.885776042938232ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beit_large_patch16_224': {'fp32': 21.330020427703857, 'top1': 90.151},\n",
       " 'convnext_xlarge_in22ft1k': {'fp32': 21.824769973754883, 'top1': 89.933},\n",
       " 'convnext_large_in22ft1k': {'fp32': 15.023713111877441, 'top1': 89.811},\n",
       " 'swin_large_patch4_window7_224': {'fp32': 17.223894596099854, 'top1': 89.792},\n",
       " 'convnext_base_in22ft1k': {'fp32': 10.011317729949951, 'top1': 89.628},\n",
       " 'xcit_large_24_p8_224_dist': {'fp32': 67.19565153121948, 'top1': 89.517},\n",
       " 'vit_base_patch8_224': {'fp32': 37.55551815032959, 'top1': 89.427},\n",
       " 'beit_base_patch16_224': {'fp32': 7.529146671295166, 'top1': 89.41},\n",
       " 'vit_large_patch16_224': {'fp32': 20.30693531036377, 'top1': 89.312},\n",
       " 'xcit_medium_24_p8_224_dist': {'fp32': 41.19997262954712, 'top1': 89.293},\n",
       " 'xcit_small_24_p8_224_dist': {'fp32': 29.569995403289795, 'top1': 89.203},\n",
       " 'swin_base_patch4_window7_224': {'fp32': 13.018548488616943, 'top1': 89.145},\n",
       " 'ig_resnext101_32x48d': {'fp32': 209.78129625320435, 'top1': 89.118},\n",
       " 'ig_resnext101_32x32d': {'fp32': 132.99628257751465, 'top1': 89.109},\n",
       " 'xcit_large_24_p16_224_dist': {'fp32': 19.60197687149048, 'top1': 89.041},\n",
       " 'resmlp_big_24_224_in22ft1k': {'fp32': 34.17351245880127, 'top1': 89.011},\n",
       " 'xcit_small_12_p8_224_dist': {'fp32': 16.266090869903564, 'top1': 89.002},\n",
       " 'vit_base_patch16_224': {'fp32': 7.095944881439209, 'top1': 88.864},\n",
       " 'ig_resnext101_32x16d': {'fp32': 35.64509630203247, 'top1': 88.825},\n",
       " 'xcit_medium_24_p16_224_dist': {'fp32': 19.10825490951538, 'top1': 88.799},\n",
       " 'swsl_resnext101_32x8d': {'fp32': 19.363136291503906, 'top1': 88.778},\n",
       " 'vit_base_patch16_224_miil': {'fp32': 6.888918876647949, 'top1': 88.742},\n",
       " 'pit_b_distilled_224': {'fp32': 8.160560131072998, 'top1': 88.674},\n",
       " 'convnext_large': {'fp32': 15.413098335266113, 'top1': 88.573},\n",
       " 'xcit_small_24_p16_224_dist': {'fp32': 19.14161205291748, 'top1': 88.541},\n",
       " 'cait_s24_224': {'fp32': 14.487385749816895, 'top1': 88.451},\n",
       " 'resmlp_big_24_distilled_224': {'fp32': 34.13303852081299, 'top1': 88.443},\n",
       " 'vit_large_r50_s32_224': {'fp32': 17.136824131011963, 'top1': 88.417},\n",
       " 'convnext_base': {'fp32': 10.280053615570068, 'top1': 88.345},\n",
       " 'xcit_small_12_p16_224_dist': {'fp32': 10.65110445022583, 'top1': 88.251},\n",
       " 'deit_base_distilled_patch16_224': {'fp32': 7.141168117523193,\n",
       "  'top1': 88.214},\n",
       " 'xcit_large_24_p8_224': {'fp32': 68.47956657409668, 'top1': 88.159},\n",
       " 'ig_resnext101_32x8d': {'fp32': 19.347553253173828, 'top1': 88.155},\n",
       " 'swsl_resnext101_32x4d': {'fp32': 12.494845390319824, 'top1': 88.095},\n",
       " 'convnext_small': {'fp32': 8.828063011169434, 'top1': 88.052},\n",
       " 'xcit_tiny_24_p8_224_dist': {'fp32': 18.574306964874268, 'top1': 88.044},\n",
       " 'xcit_small_24_p8_224': {'fp32': 29.81912851333618, 'top1': 87.967},\n",
       " 'twins_svt_large': {'fp32': 14.563868045806885, 'top1': 87.901},\n",
       " 'twins_pcpvt_large': {'fp32': 24.161112308502197, 'top1': 87.877},\n",
       " 'xcit_small_12_p8_224': {'fp32': 16.130428314208984, 'top1': 87.826},\n",
       " 'resnetv2_50x1_bit_distilled': {'fp32': 7.660644054412842, 'top1': 87.792},\n",
       " 'twins_pcpvt_base': {'fp32': 17.1039080619812, 'top1': 87.734},\n",
       " 'swin_small_patch4_window7_224': {'fp32': 13.149974346160889, 'top1': 87.668},\n",
       " 'twins_svt_base': {'fp32': 13.463866710662842, 'top1': 87.642},\n",
       " 'jx_nest_base': {'fp32': 13.895213603973389, 'top1': 87.608},\n",
       " 'swsl_resnext101_32x16d': {'fp32': 35.57924032211304, 'top1': 87.608},\n",
       " 'xcit_medium_24_p8_224': {'fp32': 41.584742069244385, 'top1': 87.604},\n",
       " 'swsl_resnext50_32x4d': {'fp32': 7.035844326019287, 'top1': 87.595},\n",
       " 'levit_384': {'fp32': 8.390529155731201, 'top1': 87.557},\n",
       " 'jx_nest_small': {'fp32': 10.838394165039062, 'top1': 87.493},\n",
       " 'resnetv2_152x2_bit_teacher': {'fp32': 46.67759895324707, 'top1': 87.493},\n",
       " 'resnet152': {'fp32': 14.783093929290771, 'top1': 87.454},\n",
       " 'coat_lite_small': {'fp32': 13.37568998336792, 'top1': 87.38},\n",
       " 'xcit_tiny_24_p8_224': {'fp32': 18.555846214294434, 'top1': 87.377},\n",
       " 'resnetv2_101': {'fp32': 10.43726921081543, 'top1': 87.318},\n",
       " 'convnext_tiny': {'fp32': 5.076277256011963, 'top1': 87.313},\n",
       " 'ecaresnet101d': {'fp32': 13.19871187210083, 'top1': 87.29},\n",
       " 'pit_s_distilled_224': {'fp32': 5.891351699829102, 'top1': 87.273},\n",
       " 'mixer_b16_224_miil': {'fp32': 5.02307653427124, 'top1': 87.228},\n",
       " 'xcit_tiny_12_p8_224_dist': {'fp32': 10.722513198852539, 'top1': 87.222},\n",
       " 'convit_base': {'fp32': 10.301809310913086, 'top1': 87.2},\n",
       " 'visformer_small': {'fp32': 12.261354923248291, 'top1': 87.185},\n",
       " 'xcit_small_24_p16_224': {'fp32': 18.74488592147827, 'top1': 87.132},\n",
       " 'resnet101': {'fp32': 10.390040874481201, 'top1': 87.083},\n",
       " 'convit_small': {'fp32': 7.084593772888184, 'top1': 87.049},\n",
       " 'xcit_small_12_p16_224': {'fp32': 10.7073974609375, 'top1': 87.012},\n",
       " 'jx_nest_tiny': {'fp32': 7.253236770629883, 'top1': 87.008},\n",
       " 'deit_small_distilled_patch16_224': {'fp32': 5.374166965484619,\n",
       "  'top1': 87.002},\n",
       " 'resmlp_36_distilled_224': {'fp32': 8.577532768249512, 'top1': 86.989},\n",
       " 'xcit_large_24_p16_224': {'fp32': 20.206291675567627, 'top1': 86.957},\n",
       " 'xcit_medium_24_p16_224': {'fp32': 18.9121413230896, 'top1': 86.938},\n",
       " 'convnext_tiny_hnf': {'fp32': 5.20892858505249, 'top1': 86.921},\n",
       " 'tnt_s_patch16_224': {'fp32': 11.865389347076416, 'top1': 86.906},\n",
       " 'ssl_resnext101_32x16d': {'fp32': 35.50900459289551, 'top1': 86.867},\n",
       " 'vit_small_patch16_224': {'fp32': 5.314064025878906, 'top1': 86.865},\n",
       " 'vit_small_r26_s32_224': {'fp32': 9.324173927307129, 'top1': 86.854},\n",
       " 'rexnet_200': {'fp32': 8.676526546478271, 'top1': 86.844},\n",
       " 'deit_base_patch16_224': {'fp32': 7.112069129943848, 'top1': 86.829},\n",
       " 'swsl_resnet50': {'fp32': 5.69875955581665, 'top1': 86.825},\n",
       " 'ssl_resnext101_32x8d': {'fp32': 19.221656322479248, 'top1': 86.801},\n",
       " 'coat_mini': {'fp32': 22.50577211380005, 'top1': 86.79},\n",
       " 'twins_svt_small': {'fp32': 9.938509464263916, 'top1': 86.758},\n",
       " 'levit_256': {'fp32': 7.915101051330566, 'top1': 86.728},\n",
       " 'seresnext50_32x4d': {'fp32': 10.353505611419678, 'top1': 86.696},\n",
       " 'pit_b_224': {'fp32': 8.090710639953613, 'top1': 86.688},\n",
       " 'swin_tiny_patch4_window7_224': {'fp32': 7.008519172668457, 'top1': 86.662},\n",
       " 'wide_resnet50_2': {'fp32': 11.220738887786865, 'top1': 86.645},\n",
       " 'twins_pcpvt_small': {'fp32': 10.364930629730225, 'top1': 86.624},\n",
       " 'resmlp_24_distilled_224': {'fp32': 6.013643741607666, 'top1': 86.62},\n",
       " 'resnest50d_4s2x40d': {'fp32': 22.737603187561035, 'top1': 86.588},\n",
       " 'repvgg_b3': {'fp32': 19.03630495071411, 'top1': 86.562},\n",
       " 'xcit_tiny_24_p16_224_dist': {'fp32': 19.14799451828003, 'top1': 86.534},\n",
       " 'ssl_resnext101_32x4d': {'fp32': 12.40248441696167, 'top1': 86.479},\n",
       " 'ecaresnet50d': {'fp32': 7.260231971740723, 'top1': 86.47},\n",
       " 'gluon_resnet152_v1s': {'fp32': 14.737098217010498, 'top1': 86.47},\n",
       " 'haloregnetz_b': {'fp32': 13.67612361907959, 'top1': 86.464},\n",
       " 'resnest50d_1s4x24d': {'fp32': 14.005622863769531, 'top1': 86.445},\n",
       " 'repvgg_b3g4': {'fp32': 21.469557285308838, 'top1': 86.361},\n",
       " 'legacy_senet154': {'fp32': 34.78443145751953, 'top1': 86.34},\n",
       " 'cait_xxs36_224': {'fp32': 20.45429229736328, 'top1': 86.338},\n",
       " 'resnext50_32x4d': {'fp32': 6.816830635070801, 'top1': 86.334},\n",
       " 'gernet_m': {'fp32': 5.102229118347168, 'top1': 86.331},\n",
       " 'pit_s_224': {'fp32': 5.802435874938965, 'top1': 86.325},\n",
       " 'gluon_senet154': {'fp32': 34.912269115448, 'top1': 86.272},\n",
       " 'resnest50d': {'fp32': 13.726053237915039, 'top1': 86.24},\n",
       " 'ecaresnet101d_pruned': {'fp32': 12.104275226593018, 'top1': 86.21},\n",
       " 'rexnet_150': {'fp32': 8.617901802062988, 'top1': 86.156},\n",
       " 'xcit_tiny_12_p8_224': {'fp32': 10.457496643066406, 'top1': 86.105},\n",
       " 'ssl_resnext50_32x4d': {'fp32': 7.0175957679748535, 'top1': 86.088},\n",
       " 'gluon_resnet101_v1s': {'fp32': 10.573070049285889, 'top1': 86.056},\n",
       " 'ecaresnetlight': {'fp32': 6.995887756347656, 'top1': 86.047},\n",
       " 'gluon_seresnext101_32x4d': {'fp32': 20.58621644973755, 'top1': 86.032},\n",
       " 'resnetv2_50': {'fp32': 5.7357048988342285, 'top1': 86.022},\n",
       " 'resnet50d': {'fp32': 6.155939102172852, 'top1': 85.998},\n",
       " 'gluon_seresnext101_64x4d': {'fp32': 23.90171766281128, 'top1': 85.958},\n",
       " 'vit_base_patch32_224': {'fp32': 5.4349684715271, 'top1': 85.958},\n",
       " 'gluon_resnet152_v1d': {'fp32': 14.936988353729248, 'top1': 85.913},\n",
       " 'resnet50_gn': {'fp32': 6.199815273284912, 'top1': 85.885},\n",
       " 'seresnet50': {'fp32': 8.887426853179932, 'top1': 85.853},\n",
       " 'gluon_resnet101_v1d': {'fp32': 10.5153489112854, 'top1': 85.849},\n",
       " 'repvgg_b2g4': {'fp32': 19.929993152618408, 'top1': 85.847},\n",
       " 'mixnet_xl': {'fp32': 15.671555995941162, 'top1': 85.795},\n",
       " 'cspresnext50': {'fp32': 6.937711238861084, 'top1': 85.748},\n",
       " 'ese_vovnet39b': {'fp32': 6.915445327758789, 'top1': 85.744},\n",
       " 'gluon_resnext101_32x4d': {'fp32': 12.917296886444092, 'top1': 85.744},\n",
       " 'legacy_seresnext101_32x4d': {'fp32': 20.41252374649048, 'top1': 85.744},\n",
       " 'xcit_tiny_24_p16_224': {'fp32': 19.209411144256592, 'top1': 85.736},\n",
       " 'regnety_320': {'fp32': 36.98447227478027, 'top1': 85.723},\n",
       " 'resnet50': {'fp32': 5.773820877075195, 'top1': 85.719},\n",
       " 'resmlp_big_24_224': {'fp32': 34.094531536102295, 'top1': 85.697},\n",
       " 'gluon_resnext101_64x4d': {'fp32': 19.746713638305664, 'top1': 85.693},\n",
       " 'deit_small_patch16_224': {'fp32': 5.586421489715576, 'top1': 85.678},\n",
       " 'pit_xs_distilled_224': {'fp32': 5.78035831451416, 'top1': 85.652},\n",
       " 'dpn107': {'fp32': 25.14744758605957, 'top1': 85.65},\n",
       " 'resmlp_36_224': {'fp32': 8.780181407928467, 'top1': 85.618},\n",
       " 'ecaresnet50d_pruned': {'fp32': 7.013001441955566, 'top1': 85.58},\n",
       " 'gluon_resnet152_v1c': {'fp32': 14.960885047912598, 'top1': 85.576},\n",
       " 'levit_192': {'fp32': 7.703721523284912, 'top1': 85.569},\n",
       " 'resnext50d_32x4d': {'fp32': 7.077133655548096, 'top1': 85.561},\n",
       " 'regnety_120': {'fp32': 23.424253463745117, 'top1': 85.546},\n",
       " 'regnetx_320': {'fp32': 36.52901649475098, 'top1': 85.516},\n",
       " 'dpn92': {'fp32': 12.669572830200195, 'top1': 85.503},\n",
       " 'rexnet_130': {'fp32': 8.681139945983887, 'top1': 85.473},\n",
       " 'gluon_resnet152_v1b': {'fp32': 14.61836576461792, 'top1': 85.467},\n",
       " 'resnetrs50': {'fp32': 9.30058479309082, 'top1': 85.46},\n",
       " 'dpn131': {'fp32': 23.13347816467285, 'top1': 85.394},\n",
       " 'regnetx_160': {'fp32': 26.61684513092041, 'top1': 85.388},\n",
       " 'dla102x2': {'fp32': 16.012027263641357, 'top1': 85.375},\n",
       " 'gmlp_s16_224': {'fp32': 7.957139015197754, 'top1': 85.349},\n",
       " 'gluon_seresnext50_32x4d': {'fp32': 10.371260643005371, 'top1': 85.336},\n",
       " 'skresnext50_32x4d': {'fp32': 13.965444564819336, 'top1': 85.317},\n",
       " 'dpn98': {'fp32': 16.97061538696289, 'top1': 85.309},\n",
       " 'gluon_resnet101_v1c': {'fp32': 10.414409637451172, 'top1': 85.302},\n",
       " 'dpn68b': {'fp32': 10.688762664794922, 'top1': 85.291},\n",
       " 'resnetblur50': {'fp32': 5.85850715637207, 'top1': 85.289},\n",
       " 'resmlp_24_224': {'fp32': 6.24377965927124, 'top1': 85.268},\n",
       " 'coat_lite_mini': {'fp32': 7.415227890014648, 'top1': 85.253},\n",
       " 'cait_xxs24_224': {'fp32': 14.695963859558105, 'top1': 85.228},\n",
       " 'xcit_tiny_12_p16_224_dist': {'fp32': 11.01663589477539, 'top1': 85.206},\n",
       " 'resnext101_32x8d': {'fp32': 19.250683784484863, 'top1': 85.195},\n",
       " 'hrnet_w48': {'fp32': 35.442304611206055, 'top1': 85.153},\n",
       " 'gluon_resnet101_v1b': {'fp32': 10.232810974121094, 'top1': 85.144},\n",
       " 'regnetx_120': {'fp32': 21.471972465515137, 'top1': 85.127},\n",
       " 'hrnet_w64': {'fp32': 32.543818950653076, 'top1': 85.112},\n",
       " 'ssl_resnet50': {'fp32': 5.5466628074646, 'top1': 85.102},\n",
       " 'res2net101_26w_4s': {'fp32': 18.502306938171387, 'top1': 85.093},\n",
       " 'gluon_resnext50_32x4d': {'fp32': 6.836404800415039, 'top1': 85.01},\n",
       " 'resnest26d': {'fp32': 9.149255752563477, 'top1': 85.01},\n",
       " 'tf_efficientnet_b0_ns': {'fp32': 7.553682327270508, 'top1': 84.986},\n",
       " 'coat_tiny': {'fp32': 21.694064140319824, 'top1': 84.978},\n",
       " 'dla169': {'fp32': 16.40092372894287, 'top1': 84.92},\n",
       " 'legacy_seresnext50_32x4d': {'fp32': 10.21946907043457, 'top1': 84.897},\n",
       " 'hrnet_w44': {'fp32': 35.05104064941406, 'top1': 84.884},\n",
       " 'regnetx_080': {'fp32': 16.2624454498291, 'top1': 84.867},\n",
       " 'gluon_resnet50_v1s': {'fp32': 6.048216819763184, 'top1': 84.856},\n",
       " 'res2net50_26w_8s': {'fp32': 16.55200719833374, 'top1': 84.85},\n",
       " 'levit_128': {'fp32': 7.457218170166016, 'top1': 84.843},\n",
       " 'gluon_resnet50_v1d': {'fp32': 5.979855060577393, 'top1': 84.83},\n",
       " 'dla60_res2next': {'fp32': 16.676864624023438, 'top1': 84.83},\n",
       " 'mixnet_l': {'fp32': 12.020494937896729, 'top1': 84.822},\n",
       " 'tv_resnet152': {'fp32': 14.778411388397217, 'top1': 84.818},\n",
       " 'dla102x': {'fp32': 12.80745267868042, 'top1': 84.813},\n",
       " 'dla60_res2net': {'fp32': 10.99360704421997, 'top1': 84.809},\n",
       " 'pit_xs_224': {'fp32': 5.574824810028076, 'top1': 84.79},\n",
       " 'regnetx_064': {'fp32': 10.881218910217285, 'top1': 84.781},\n",
       " 'hrnet_w40': {'fp32': 32.84000873565674, 'top1': 84.736},\n",
       " 'res2net50_26w_6s': {'fp32': 13.051064014434814, 'top1': 84.732},\n",
       " 'repvgg_b2': {'fp32': 13.539295196533203, 'top1': 84.722},\n",
       " 'resmlp_12_distilled_224': {'fp32': 3.6040902137756348, 'top1': 84.713},\n",
       " 'legacy_seresnet152': {'fp32': 26.476173400878906, 'top1': 84.698},\n",
       " 'selecsls60b': {'fp32': 6.78408145904541, 'top1': 84.655},\n",
       " 'hrnet_w32': {'fp32': 32.459938526153564, 'top1': 84.649},\n",
       " 'tf_efficientnetv2_b0': {'fp32': 9.069797992706299, 'top1': 84.63},\n",
       " 'regnetx_040': {'fp32': 9.452488422393799, 'top1': 84.6},\n",
       " 'efficientnet_es': {'fp32': 4.622650146484375, 'top1': 84.581},\n",
       " 'hrnet_w30': {'fp32': 32.88370132446289, 'top1': 84.574},\n",
       " 'tf_mixnet_l': {'fp32': 12.54335880279541, 'top1': 84.564},\n",
       " 'wide_resnet101_2': {'fp32': 18.53970766067505, 'top1': 84.551},\n",
       " 'dla60x': {'fp32': 7.748398780822754, 'top1': 84.523},\n",
       " 'legacy_seresnet101': {'fp32': 17.77522087097168, 'top1': 84.502},\n",
       " 'coat_lite_tiny': {'fp32': 7.747297286987305, 'top1': 84.461},\n",
       " 'repvgg_b1': {'fp32': 10.340573787689209, 'top1': 84.414},\n",
       " 'res2net50_26w_4s': {'fp32': 9.812300205230713, 'top1': 84.363},\n",
       " 'hardcorenas_f': {'fp32': 7.513260841369629, 'top1': 84.322},\n",
       " 'res2net50_14w_8s': {'fp32': 15.492770671844482, 'top1': 84.305},\n",
       " 'selecsls60': {'fp32': 6.7041850090026855, 'top1': 84.284},\n",
       " 'regnetx_032': {'fp32': 9.24436092376709, 'top1': 84.239},\n",
       " 'res2next50': {'fp32': 16.0325288772583, 'top1': 84.237},\n",
       " 'gluon_resnet50_v1c': {'fp32': 6.02961540222168, 'top1': 84.211},\n",
       " 'dla102': {'fp32': 11.158323287963867, 'top1': 84.192},\n",
       " 'rexnet_100': {'fp32': 8.488998413085938, 'top1': 84.164},\n",
       " 'res2net50_48w_2s': {'fp32': 6.8399739265441895, 'top1': 84.126},\n",
       " 'xcit_tiny_12_p16_224': {'fp32': 10.742213726043701, 'top1': 84.094},\n",
       " 'resnet34d': {'fp32': 4.444456100463867, 'top1': 84.094},\n",
       " 'efficientnet_b0': {'fp32': 7.722764015197754, 'top1': 84.025},\n",
       " 'hardcorenas_e': {'fp32': 7.862691879272461, 'top1': 83.968},\n",
       " 'gmixer_24_224': {'fp32': 8.633630275726318, 'top1': 83.966},\n",
       " 'tf_efficientnet_cc_b0_8e': {'fp32': 9.532198905944824, 'top1': 83.963},\n",
       " 'regnety_016': {'fp32': 13.075990676879883, 'top1': 83.957},\n",
       " 'tv_resnext50_32x4d': {'fp32': 6.84128999710083, 'top1': 83.957},\n",
       " 'gluon_resnet50_v1b': {'fp32': 5.709357261657715, 'top1': 83.942},\n",
       " 'densenet161': {'fp32': 18.180179595947266, 'top1': 83.908},\n",
       " 'mobilenetv2_120d': {'fp32': 6.398036479949951, 'top1': 83.891},\n",
       " 'seresnext26t_32x4d': {'fp32': 6.067569255828857, 'top1': 83.874},\n",
       " 'tv_resnet101': {'fp32': 10.200674533843994, 'top1': 83.85},\n",
       " 'hardcorenas_d': {'fp32': 7.6938605308532715, 'top1': 83.759},\n",
       " 'seresnext26d_32x4d': {'fp32': 6.100883483886719, 'top1': 83.754},\n",
       " 'dla60': {'fp32': 6.960539817810059, 'top1': 83.731},\n",
       " 'xcit_nano_12_p8_224_dist': {'fp32': 10.60863733291626, 'top1': 83.729},\n",
       " 'repvgg_b1g4': {'fp32': 15.697145462036133, 'top1': 83.695},\n",
       " 'legacy_seresnet50': {'fp32': 9.095869064331055, 'top1': 83.662},\n",
       " 'tf_efficientnet_b0_ap': {'fp32': 7.9328179359436035, 'top1': 83.652},\n",
       " 'tf_efficientnet_cc_b0_4e': {'fp32': 9.515957832336426, 'top1': 83.635},\n",
       " 'skresnet34': {'fp32': 11.576557159423828, 'top1': 83.635},\n",
       " 'resmlp_12_224': {'fp32': 3.418292999267578, 'top1': 83.569},\n",
       " 'mobilenetv3_large_100_miil': {'fp32': 5.8875322341918945, 'top1': 83.556},\n",
       " 'densenet201': {'fp32': 22.708756923675537, 'top1': 83.554},\n",
       " 'gernet_s': {'fp32': 4.930844306945801, 'top1': 83.519},\n",
       " 'legacy_seresnext26_32x4d': {'fp32': 5.834329128265381, 'top1': 83.519},\n",
       " 'mixnet_m': {'fp32': 11.8780517578125, 'top1': 83.519},\n",
       " 'tf_efficientnet_b0': {'fp32': 7.822632789611816, 'top1': 83.515},\n",
       " 'hrnet_w18': {'fp32': 30.394515991210938, 'top1': 83.498},\n",
       " 'densenetblur121d': {'fp32': 13.929440975189209, 'top1': 83.466},\n",
       " 'selecsls42b': {'fp32': 5.317094326019287, 'top1': 83.455},\n",
       " 'hardcorenas_c': {'fp32': 5.877339839935303, 'top1': 83.34},\n",
       " 'regnetx_016': {'fp32': 6.857666969299316, 'top1': 83.197},\n",
       " 'dpn68': {'fp32': 9.795167446136475, 'top1': 83.18},\n",
       " 'mobilenetv2_140': {'fp32': 4.393730163574219, 'top1': 83.18},\n",
       " 'tf_efficientnet_es': {'fp32': 4.962162971496582, 'top1': 83.178},\n",
       " 'tf_mixnet_m': {'fp32': 12.627298831939697, 'top1': 83.176},\n",
       " 'ese_vovnet19b_dw': {'fp32': 4.190046787261963, 'top1': 83.114},\n",
       " 'levit_128s': {'fp32': 6.306872367858887, 'top1': 83.062},\n",
       " 'resnet26d': {'fp32': 3.9606857299804688, 'top1': 83.062},\n",
       " 'repvgg_a2': {'fp32': 5.6511616706848145, 'top1': 83.001},\n",
       " 'tv_resnet50': {'fp32': 5.752856731414795, 'top1': 82.954},\n",
       " 'hardcorenas_b': {'fp32': 5.313284397125244, 'top1': 82.868},\n",
       " 'densenet121': {'fp32': 13.66246223449707, 'top1': 82.821},\n",
       " 'densenet169': {'fp32': 19.266939163208008, 'top1': 82.678},\n",
       " 'mixnet_s': {'fp32': 9.835643768310547, 'top1': 82.522},\n",
       " 'vit_small_patch32_224': {'fp32': 5.282011032104492, 'top1': 82.507},\n",
       " 'regnety_008': {'fp32': 7.687127590179443, 'top1': 82.488},\n",
       " 'efficientnet_lite0': {'fp32': 4.397320747375488, 'top1': 82.386},\n",
       " 'resnest14d': {'fp32': 6.806044578552246, 'top1': 82.349},\n",
       " 'hardcorenas_a': {'fp32': 4.8999786376953125, 'top1': 82.311},\n",
       " 'efficientnet_es_pruned': {'fp32': 4.652845859527588, 'top1': 82.287},\n",
       " 'mobilenetv3_rw': {'fp32': 5.950417518615723, 'top1': 82.273},\n",
       " 'semnasnet_100': {'fp32': 5.771811008453369, 'top1': 82.251},\n",
       " 'mobilenetv3_large_100': {'fp32': 6.3648223876953125, 'top1': 82.179},\n",
       " 'resnet34': {'fp32': 4.3703293800354, 'top1': 82.144},\n",
       " 'vit_tiny_patch16_224': {'fp32': 5.5307722091674805, 'top1': 82.076},\n",
       " 'mobilenetv2_110d': {'fp32': 5.535926818847656, 'top1': 82.074},\n",
       " 'tf_mixnet_s': {'fp32': 10.418744087219238, 'top1': 82.038},\n",
       " 'repvgg_b0': {'fp32': 6.795341968536377, 'top1': 82.006},\n",
       " 'deit_tiny_distilled_patch16_224': {'fp32': 5.380315780639648,\n",
       "  'top1': 81.997},\n",
       " 'mixer_b16_224': {'fp32': 4.956786632537842, 'top1': 81.987},\n",
       " 'pit_ti_distilled_224': {'fp32': 5.767495632171631, 'top1': 81.972},\n",
       " 'hrnet_w18_small_v2': {'fp32': 16.956512928009033, 'top1': 81.963},\n",
       " 'resnet26': {'fp32': 3.737163543701172, 'top1': 81.954},\n",
       " 'tf_efficientnet_lite0': {'fp32': 4.358277320861816, 'top1': 81.952},\n",
       " 'tf_mobilenetv3_large_100': {'fp32': 6.118559837341309, 'top1': 81.848},\n",
       " 'tv_densenet121': {'fp32': 13.866865634918213, 'top1': 81.724},\n",
       " 'regnety_006': {'fp32': 8.436896800994873, 'top1': 81.698},\n",
       " 'dla34': {'fp32': 4.560897350311279, 'top1': 81.645},\n",
       " 'xcit_nano_12_p8_224': {'fp32': 10.833866596221924, 'top1': 81.638},\n",
       " 'fbnetc_100': {'fp32': 5.327892303466797, 'top1': 81.559},\n",
       " 'legacy_seresnet34': {'fp32': 6.90471887588501, 'top1': 81.536},\n",
       " 'gluon_resnet34_v1b': {'fp32': 4.467740058898926, 'top1': 81.498},\n",
       " 'regnetx_008': {'fp32': 5.900390148162842, 'top1': 81.481},\n",
       " 'mnasnet_100': {'fp32': 4.553892612457275, 'top1': 81.453},\n",
       " 'vgg19_bn': {'fp32': 12.30588674545288, 'top1': 81.446},\n",
       " 'convit_tiny': {'fp32': 7.331175804138184, 'top1': 81.132},\n",
       " 'spnasnet_100': {'fp32': 5.1381754875183105, 'top1': 80.872},\n",
       " 'ghostnet_100': {'fp32': 9.09602165222168, 'top1': 80.701},\n",
       " 'regnety_004': {'fp32': 10.290906429290771, 'top1': 80.65},\n",
       " 'skresnet18': {'fp32': 6.64794921875, 'top1': 80.641},\n",
       " 'regnetx_006': {'fp32': 5.949075222015381, 'top1': 80.635},\n",
       " 'pit_ti_224': {'fp32': 5.768704414367676, 'top1': 80.614},\n",
       " 'swsl_resnet18': {'fp32': 2.929062843322754, 'top1': 80.573},\n",
       " 'vgg16_bn': {'fp32': 10.73566198348999, 'top1': 80.556},\n",
       " 'semnasnet_075': {'fp32': 5.941629409790039, 'top1': 80.473},\n",
       " 'tv_resnet34': {'fp32': 4.107306003570557, 'top1': 80.389},\n",
       " 'resnet18d': {'fp32': 3.145148754119873, 'top1': 80.385},\n",
       " 'mobilenetv2_100': {'fp32': 4.582910537719727, 'top1': 80.255},\n",
       " 'xcit_nano_12_p16_224_dist': {'fp32': 10.572693347930908, 'top1': 80.216},\n",
       " 'ssl_resnet18': {'fp32': 2.853367328643799, 'top1': 80.097},\n",
       " 'tf_mobilenetv3_large_075': {'fp32': 6.057429313659668, 'top1': 80.091},\n",
       " 'deit_tiny_patch16_224': {'fp32': 5.405433177947998, 'top1': 80.016},\n",
       " 'hrnet_w18_small': {'fp32': 9.77731466293335, 'top1': 79.565},\n",
       " 'vgg19': {'fp32': 11.525249481201172, 'top1': 79.478},\n",
       " 'regnetx_004': {'fp32': 8.871192932128906, 'top1': 79.422},\n",
       " 'tf_mobilenetv3_large_minimal_100': {'fp32': 4.2511749267578125,\n",
       "  'top1': 79.224},\n",
       " 'legacy_seresnet18': {'fp32': 4.143624305725098, 'top1': 79.157},\n",
       " 'vgg16': {'fp32': 10.0022554397583, 'top1': 79.034},\n",
       " 'vgg13_bn': {'fp32': 9.130573272705078, 'top1': 79.008},\n",
       " 'vit_tiny_r_s16_p8_224': {'fp32': 5.409998893737793, 'top1': 78.991},\n",
       " 'lcnet_100': {'fp32': 3.202395439147949, 'top1': 78.895},\n",
       " 'gluon_resnet18_v1b': {'fp32': 2.834024429321289, 'top1': 78.374},\n",
       " 'vgg11_bn': {'fp32': 7.411701679229736, 'top1': 77.926},\n",
       " 'xcit_nano_12_p16_224': {'fp32': 10.727806091308594, 'top1': 77.891},\n",
       " 'regnety_002': {'fp32': 8.449339866638184, 'top1': 77.411},\n",
       " 'mixer_l16_224': {'fp32': 15.56145191192627, 'top1': 77.283},\n",
       " 'resnet18': {'fp32': 2.7750158309936523, 'top1': 77.274},\n",
       " 'vgg13': {'fp32': 8.489997386932373, 'top1': 77.227},\n",
       " 'vgg11': {'fp32': 6.989898681640625, 'top1': 76.393},\n",
       " 'regnetx_002': {'fp32': 5.940618515014648, 'top1': 76.117},\n",
       " 'lcnet_075': {'fp32': 3.65983247756958, 'top1': 76.057},\n",
       " 'dla60x_c': {'fp32': 6.474413871765137, 'top1': 75.637},\n",
       " 'mobilenetv3_small_100': {'fp32': 4.966714382171631, 'top1': 74.913},\n",
       " 'tf_mobilenetv3_small_100': {'fp32': 4.927332401275635, 'top1': 74.719},\n",
       " 'mnasnet_small': {'fp32': 6.198482513427734, 'top1': 73.816},\n",
       " 'dla46x_c': {'fp32': 5.030632019042969, 'top1': 73.647},\n",
       " 'mobilenetv2_050': {'fp32': 4.8744964599609375, 'top1': 73.463},\n",
       " 'tf_mobilenetv3_small_075': {'fp32': 5.385587215423584, 'top1': 72.806},\n",
       " 'dla46_c': {'fp32': 5.167293548583984, 'top1': 72.607},\n",
       " 'mobilenetv3_small_075': {'fp32': 5.276763439178467, 'top1': 72.325},\n",
       " 'lcnet_050': {'fp32': 3.289806842803955, 'top1': 70.393},\n",
       " 'tf_mobilenetv3_small_minimal_100': {'fp32': 3.4982943534851074,\n",
       "  'top1': 70.111},\n",
       " 'mobilenetv3_small_050': {'fp32': 4.885776042938232, 'top1': 64.671}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = {}\n",
    "\n",
    "# inference float precision\n",
    "for i,modelname in tqdm(enumerate((modellist))):\n",
    "    try:\n",
    "        benchmark = inference(modelname, benchmark)\n",
    "    except:\n",
    "        print(\"pass {}\".format(modelname))\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp32</th>\n",
       "      <th>top1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beit_large_patch16_224</th>\n",
       "      <td>21.330020</td>\n",
       "      <td>90.151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_xlarge_in22ft1k</th>\n",
       "      <td>21.824770</td>\n",
       "      <td>89.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_large_in22ft1k</th>\n",
       "      <td>15.023713</td>\n",
       "      <td>89.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swin_large_patch4_window7_224</th>\n",
       "      <td>17.223895</td>\n",
       "      <td>89.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base_in22ft1k</th>\n",
       "      <td>10.011318</td>\n",
       "      <td>89.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dla46_c</th>\n",
       "      <td>5.167294</td>\n",
       "      <td>72.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobilenetv3_small_075</th>\n",
       "      <td>5.276763</td>\n",
       "      <td>72.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcnet_050</th>\n",
       "      <td>3.289807</td>\n",
       "      <td>70.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_mobilenetv3_small_minimal_100</th>\n",
       "      <td>3.498294</td>\n",
       "      <td>70.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobilenetv3_small_050</th>\n",
       "      <td>4.885776</td>\n",
       "      <td>64.671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       fp32    top1\n",
       "beit_large_patch16_224            21.330020  90.151\n",
       "convnext_xlarge_in22ft1k          21.824770  89.933\n",
       "convnext_large_in22ft1k           15.023713  89.811\n",
       "swin_large_patch4_window7_224     17.223895  89.792\n",
       "convnext_base_in22ft1k            10.011318  89.628\n",
       "...                                     ...     ...\n",
       "dla46_c                            5.167294  72.607\n",
       "mobilenetv3_small_075              5.276763  72.325\n",
       "lcnet_050                          3.289807  70.393\n",
       "tf_mobilenetv3_small_minimal_100   3.498294  70.111\n",
       "mobilenetv3_small_050              4.885776  64.671\n",
       "\n",
       "[338 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(benchmark).T\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"results_fp32_224.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f79461bf198>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot(y='top1', x='fp32',  \n",
    "           data=df_results, logx=True,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For various image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ryujaehun/pytorch-gpu-benchmark/blob/master/benchmark_models.py\n",
    "def inference_imsize(modelname, benchmark, imsize):\n",
    "    with torch.no_grad():\n",
    "        model = timm.create_model(modelname,)\n",
    "        model=model.to('cuda')\n",
    "        model.eval()\n",
    "        precision = \"float\"\n",
    "        durations = []\n",
    "        rand_loader = DataLoader(dataset=RandomDataset(BATCH_SIZE*(WARM_UP + NUM_TEST), imsize),\n",
    "                         batch_size=BATCH_SIZE, shuffle=False,num_workers=8)\n",
    "        print(f'Benchmarking Inference {modelname} ')\n",
    "        for step,img in enumerate(rand_loader):\n",
    "            img=getattr(img,precision)()\n",
    "            torch.cuda.synchronize()\n",
    "            start = time.time()\n",
    "            model(img.to('cuda'))\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            if step >= WARM_UP:\n",
    "                durations.append((end - start)*1000)\n",
    "        print(f'{modelname} model average inference time : {sum(durations)/len(durations)}ms')\n",
    "        \n",
    "        benchmark[modelname] = {\"fp32\": np.mean(durations), \"top1\": float(df_models[df_models[\"model\"]==modelname][\"top1\"]), \"imsize\": imsize}\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffab9468059f456991b8879c20c8adba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference beit_large_patch16_512 \n",
      "beit_large_patch16_512 model average inference time : 187.91571378707886ms\n",
      "Benchmarking Inference beit_large_patch16_384 \n",
      "beit_large_patch16_384 model average inference time : 79.08053874969482ms\n",
      "pass volo_d5_512\n",
      "pass volo_d5_448\n",
      "Benchmarking Inference tf_efficientnet_l2_ns \n",
      "tf_efficientnet_l2_ns model average inference time : 608.8841009140015ms\n",
      "Benchmarking Inference tf_efficientnet_l2_ns_475 \n",
      "tf_efficientnet_l2_ns_475 model average inference time : 255.66667079925537ms\n",
      "pass volo_d4_448\n",
      "Benchmarking Inference convnext_xlarge_384_in22ft1k \n",
      "convnext_xlarge_384_in22ft1k model average inference time : 56.37524366378784ms\n",
      "Benchmarking Inference beit_base_patch16_384 \n",
      "beit_base_patch16_384 model average inference time : 30.774567127227783ms\n",
      "Benchmarking Inference convnext_large_384_in22ft1k \n",
      "convnext_large_384_in22ft1k model average inference time : 40.837438106536865ms\n",
      "Benchmarking Inference vit_large_patch16_384 \n",
      "vit_large_patch16_384 model average inference time : 67.05897569656372ms\n",
      "Benchmarking Inference cait_m48_448 \n",
      "cait_m48_448 model average inference time : 482.7632546424866ms\n",
      "pass volo_d3_448\n",
      "Benchmarking Inference beit_large_patch16_224 \n",
      "beit_large_patch16_224 model average inference time : 22.212607860565186ms\n",
      "Benchmarking Inference convnext_base_384_in22ft1k \n",
      "convnext_base_384_in22ft1k model average inference time : 24.37373638153076ms\n",
      "Benchmarking Inference tf_efficientnet_b7_ns \n",
      "tf_efficientnet_b7_ns model average inference time : 92.93165683746338ms\n",
      "Benchmarking Inference cait_m36_384 \n",
      "cait_m36_384 model average inference time : 207.56558895111084ms\n",
      "Benchmarking Inference dm_nfnet_f6 \n",
      "dm_nfnet_f6 model average inference time : 672.6956820487976ms\n",
      "Benchmarking Inference swin_large_patch4_window12_384 \n",
      "swin_large_patch4_window12_384 model average inference time : 55.37781476974487ms\n",
      "Benchmarking Inference tf_efficientnetv2_l_in21ft1k \n",
      "tf_efficientnetv2_l_in21ft1k model average inference time : 71.37280941009521ms\n",
      "Benchmarking Inference swin_base_patch4_window12_384 \n",
      "swin_base_patch4_window12_384 model average inference time : 34.73442077636719ms\n",
      "Benchmarking Inference vit_base_patch16_384 \n",
      "vit_base_patch16_384 model average inference time : 26.0374116897583ms\n",
      "Benchmarking Inference convnext_xlarge_in22ft1k \n",
      "convnext_xlarge_in22ft1k model average inference time : 22.533299922943115ms\n",
      "Benchmarking Inference xcit_large_24_p8_384_dist \n",
      "xcit_large_24_p8_384_dist model average inference time : 171.54454708099365ms\n",
      "pass volo_d5_224\n",
      "Benchmarking Inference cait_s36_384 \n",
      "cait_s36_384 model average inference time : 100.09888172149658ms\n",
      "Benchmarking Inference xcit_medium_24_p8_384_dist \n",
      "xcit_medium_24_p8_384_dist model average inference time : 103.07622194290161ms\n",
      "pass volo_d4_224\n",
      "Benchmarking Inference convnext_large_in22ft1k \n",
      "convnext_large_in22ft1k model average inference time : 15.546832084655762ms\n",
      "Benchmarking Inference vit_large_r50_s32_384 \n",
      "vit_large_r50_s32_384 model average inference time : 30.807855129241943ms\n",
      "Benchmarking Inference swin_large_patch4_window7_224 \n",
      "swin_large_patch4_window7_224 model average inference time : 17.675859928131104ms\n",
      "pass volo_d2_384\n",
      "Benchmarking Inference tf_efficientnetv2_m_in21ft1k \n",
      "tf_efficientnetv2_m_in21ft1k model average inference time : 36.42094612121582ms\n",
      "Benchmarking Inference tf_efficientnet_b6_ns \n",
      "tf_efficientnet_b6_ns model average inference time : 53.91404390335083ms\n",
      "Benchmarking Inference xcit_small_24_p8_384_dist \n",
      "xcit_small_24_p8_384_dist model average inference time : 75.50479650497437ms\n",
      "pass volo_d1_384\n",
      "Benchmarking Inference xcit_large_24_p16_384_dist \n",
      "xcit_large_24_p16_384_dist model average inference time : 50.74313163757324ms\n",
      "Benchmarking Inference tf_efficientnet_b5_ns \n",
      "tf_efficientnet_b5_ns model average inference time : 32.290048599243164ms\n",
      "Benchmarking Inference convnext_base_in22ft1k \n",
      "convnext_base_in22ft1k model average inference time : 10.318505764007568ms\n",
      "Benchmarking Inference tf_efficientnetv2_xl_in21ft1k \n",
      "tf_efficientnetv2_xl_in21ft1k model average inference time : 112.3640489578247ms\n",
      "Benchmarking Inference tf_efficientnet_b8_ap \n",
      "tf_efficientnet_b8_ap model average inference time : 137.68148183822632ms\n",
      "Benchmarking Inference dm_nfnet_f4 \n",
      "dm_nfnet_f4 model average inference time : 672.0425343513489ms\n",
      "pass volo_d3_224\n",
      "Benchmarking Inference xcit_large_24_p8_224_dist \n",
      "xcit_large_24_p8_224_dist model average inference time : 69.41962718963623ms\n",
      "Benchmarking Inference xcit_small_12_p8_384_dist \n",
      "xcit_small_12_p8_384_dist model average inference time : 41.09152555465698ms\n",
      "Benchmarking Inference cait_s24_384 \n",
      "cait_s24_384 model average inference time : 67.35388517379761ms\n",
      "Benchmarking Inference dm_nfnet_f3 \n",
      "dm_nfnet_f3 model average inference time : 292.4152183532715ms\n",
      "Benchmarking Inference xcit_medium_24_p16_384_dist \n",
      "xcit_medium_24_p16_384_dist model average inference time : 31.045682430267334ms\n",
      "Benchmarking Inference dm_nfnet_f5 \n",
      "dm_nfnet_f5 model average inference time : 794.8230934143066ms\n",
      "Benchmarking Inference deit_base_distilled_patch16_384 \n",
      "deit_base_distilled_patch16_384 model average inference time : 26.244633197784424ms\n",
      "Benchmarking Inference tf_efficientnet_b7_ap \n",
      "tf_efficientnet_b7_ap model average inference time : 93.15792560577393ms\n",
      "Benchmarking Inference vit_base_patch8_224 \n",
      "vit_base_patch8_224 model average inference time : 38.318350315093994ms\n",
      "Benchmarking Inference beit_base_patch16_224 \n",
      "beit_base_patch16_224 model average inference time : 7.689826488494873ms\n",
      "Benchmarking Inference regnetz_e8 \n",
      "regnetz_e8 model average inference time : 31.81417465209961ms\n",
      "Benchmarking Inference tf_efficientnetv2_l \n",
      "tf_efficientnetv2_l model average inference time : 71.03377103805542ms\n",
      "Benchmarking Inference tf_efficientnet_b8 \n",
      "tf_efficientnet_b8 model average inference time : 137.69964694976807ms\n",
      "Benchmarking Inference tf_efficientnet_b6_ap \n",
      "tf_efficientnet_b6_ap model average inference time : 53.95560264587402ms\n",
      "pass volo_d2_224\n",
      "Benchmarking Inference vit_large_patch16_224 \n",
      "vit_large_patch16_224 model average inference time : 20.655953884124756ms\n",
      "Benchmarking Inference tf_efficientnet_b4_ns \n",
      "tf_efficientnet_b4_ns model average inference time : 17.379508018493652ms\n",
      "Benchmarking Inference xcit_small_24_p16_384_dist \n",
      "xcit_small_24_p16_384_dist model average inference time : 21.77457332611084ms\n",
      "Benchmarking Inference xcit_medium_24_p8_224_dist \n",
      "xcit_medium_24_p8_224_dist model average inference time : 41.69515609741211ms\n",
      "Benchmarking Inference tf_efficientnetv2_m \n",
      "tf_efficientnetv2_m model average inference time : 36.484036445617676ms\n",
      "Benchmarking Inference xcit_small_24_p8_224_dist \n",
      "xcit_small_24_p8_224_dist model average inference time : 29.96450424194336ms\n",
      "Benchmarking Inference xcit_small_12_p16_384_dist \n",
      "xcit_small_12_p16_384_dist model average inference time : 12.865972518920898ms\n",
      "Benchmarking Inference swin_base_patch4_window7_224 \n",
      "swin_base_patch4_window7_224 model average inference time : 13.439774513244629ms\n",
      "Benchmarking Inference cait_xs24_384 \n",
      "cait_xs24_384 model average inference time : 48.526389598846436ms\n",
      "Benchmarking Inference eca_nfnet_l2 \n",
      "eca_nfnet_l2 model average inference time : 72.81731128692627ms\n",
      "Benchmarking Inference ig_resnext101_32x48d \n",
      "ig_resnext101_32x48d model average inference time : 210.53939580917358ms\n",
      "Benchmarking Inference ig_resnext101_32x32d \n",
      "ig_resnext101_32x32d model average inference time : 133.38236331939697ms\n",
      "Benchmarking Inference tf_efficientnet_b7 \n",
      "tf_efficientnet_b7 model average inference time : 92.8994870185852ms\n",
      "Benchmarking Inference ecaresnet269d \n",
      "ecaresnet269d model average inference time : 50.67777633666992ms\n",
      "Benchmarking Inference xcit_large_24_p16_224_dist \n",
      "xcit_large_24_p16_224_dist model average inference time : 20.32648801803589ms\n",
      "Benchmarking Inference resmlp_big_24_224_in22ft1k \n",
      "resmlp_big_24_224_in22ft1k model average inference time : 34.29241418838501ms\n",
      "Benchmarking Inference dm_nfnet_f2 \n",
      "dm_nfnet_f2 model average inference time : 185.6989073753357ms\n",
      "Benchmarking Inference xcit_small_12_p8_224_dist \n",
      "xcit_small_12_p8_224_dist model average inference time : 16.310091018676758ms\n",
      "Benchmarking Inference efficientnetv2_rw_m \n",
      "efficientnetv2_rw_m model average inference time : 31.904401779174805ms\n",
      "pass regnetz_040h\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference tf_efficientnet_b5_ap \n",
      "tf_efficientnet_b5_ap model average inference time : 32.3570990562439ms\n",
      "Benchmarking Inference dm_nfnet_f1 \n",
      "dm_nfnet_f1 model average inference time : 110.08667707443237ms\n",
      "pass volo_d1_224\n",
      "Benchmarking Inference tf_efficientnetv2_s_in21ft1k \n",
      "tf_efficientnetv2_s_in21ft1k model average inference time : 19.096014499664307ms\n",
      "Benchmarking Inference vit_base_patch16_224 \n",
      "vit_base_patch16_224 model average inference time : 7.161188125610352ms\n",
      "Benchmarking Inference regnetz_d8 \n",
      "regnetz_d8 model average inference time : 19.865193367004395ms\n",
      "Benchmarking Inference resnetrs420 \n",
      "resnetrs420 model average inference time : 122.50638008117676ms\n",
      "Benchmarking Inference regnetz_d8_evos \n",
      "regnetz_d8_evos model average inference time : 29.344148635864258ms\n",
      "Benchmarking Inference resnetrs270 \n",
      "resnetrs270 model average inference time : 57.58063554763794ms\n",
      "Benchmarking Inference ig_resnext101_32x16d \n",
      "ig_resnext101_32x16d model average inference time : 35.88122367858887ms\n",
      "Benchmarking Inference vit_small_r26_s32_384 \n",
      "vit_small_r26_s32_384 model average inference time : 12.752251625061035ms\n",
      "Benchmarking Inference vit_base_r50_s16_384 \n",
      "vit_base_r50_s16_384 model average inference time : 39.00730848312378ms\n",
      "Benchmarking Inference xcit_medium_24_p16_224_dist \n",
      "xcit_medium_24_p16_224_dist model average inference time : 19.440722465515137ms\n",
      "Benchmarking Inference seresnet152d \n",
      "seresnet152d model average inference time : 31.543376445770264ms\n",
      "Benchmarking Inference swsl_resnext101_32x8d \n",
      "swsl_resnext101_32x8d model average inference time : 19.418256282806396ms\n",
      "Benchmarking Inference xcit_tiny_24_p8_384_dist \n",
      "xcit_tiny_24_p8_384_dist model average inference time : 38.722381591796875ms\n",
      "Benchmarking Inference resnetrs200 \n",
      "resnetrs200 model average inference time : 38.456058502197266ms\n",
      "Benchmarking Inference tf_efficientnet_b6 \n",
      "tf_efficientnet_b6 model average inference time : 53.8628888130188ms\n",
      "Benchmarking Inference resnetrs350 \n",
      "resnetrs350 model average inference time : 80.18627882003784ms\n",
      "Benchmarking Inference vit_base_patch16_224_miil \n",
      "vit_base_patch16_224_miil model average inference time : 6.964316368103027ms\n",
      "pass regnetz_040\n",
      "Benchmarking Inference resnetv2_152x2_bitm \n",
      "resnetv2_152x2_bitm model average inference time : 127.63757705688477ms\n",
      "Benchmarking Inference regnety_160 \n",
      "regnety_160 model average inference time : 71.84243202209473ms\n",
      "Benchmarking Inference pit_b_distilled_224 \n",
      "pit_b_distilled_224 model average inference time : 8.21521520614624ms\n",
      "Benchmarking Inference vit_small_patch16_384 \n",
      "vit_small_patch16_384 model average inference time : 11.51090383529663ms\n",
      "Benchmarking Inference regnetz_d32 \n",
      "regnetz_d32 model average inference time : 31.382534503936768ms\n",
      "Benchmarking Inference regnety_080 \n",
      "regnety_080 model average inference time : 26.292824745178223ms\n",
      "Benchmarking Inference eca_nfnet_l1 \n",
      "eca_nfnet_l1 model average inference time : 36.145222187042236ms\n",
      "Benchmarking Inference convnext_large \n",
      "convnext_large model average inference time : 15.460774898529053ms\n",
      "Benchmarking Inference resnetv2_152x4_bitm \n",
      "resnetv2_152x4_bitm model average inference time : 443.8380432128906ms\n",
      "Benchmarking Inference resnet200d \n",
      "resnet200d model average inference time : 30.661048889160156ms\n",
      "Benchmarking Inference xcit_small_24_p16_224_dist \n",
      "xcit_small_24_p16_224_dist model average inference time : 18.936047554016113ms\n",
      "Benchmarking Inference resnest269e \n",
      "resnest269e model average inference time : 191.641206741333ms\n",
      "Benchmarking Inference seresnext101_32x8d \n",
      "seresnext101_32x8d model average inference time : 29.890413284301758ms\n",
      "Benchmarking Inference efficientnetv2_rw_s \n",
      "efficientnetv2_rw_s model average inference time : 19.278180599212646ms\n",
      "Benchmarking Inference crossvit_18_dagger_408 \n",
      "crossvit_18_dagger_408 model average inference time : 28.73060703277588ms\n",
      "Benchmarking Inference resnetv2_101x3_bitm \n",
      "resnetv2_101x3_bitm model average inference time : 165.76751947402954ms\n",
      "Benchmarking Inference cait_s24_224 \n",
      "cait_s24_224 model average inference time : 14.428799152374268ms\n",
      "Benchmarking Inference resnetv2_50x3_bitm \n",
      "resnetv2_50x3_bitm model average inference time : 96.11170530319214ms\n",
      "Benchmarking Inference resmlp_big_24_distilled_224 \n",
      "resmlp_big_24_distilled_224 model average inference time : 34.34579133987427ms\n",
      "pass regnetv_064\n",
      "Benchmarking Inference resnest200e \n",
      "resnest200e model average inference time : 88.43701839447021ms\n",
      "Benchmarking Inference tf_efficientnet_b3_ns \n",
      "tf_efficientnet_b3_ns model average inference time : 13.30073356628418ms\n",
      "Benchmarking Inference vit_large_r50_s32_224 \n",
      "vit_large_r50_s32_224 model average inference time : 16.60557508468628ms\n",
      "Benchmarking Inference tf_efficientnetv2_s \n",
      "tf_efficientnetv2_s model average inference time : 18.862860202789307ms\n",
      "pass regnetz_c16_evos\n",
      "Benchmarking Inference efficientnet_b4 \n",
      "efficientnet_b4 model average inference time : 16.42165184020996ms\n",
      "Benchmarking Inference resnet152d \n",
      "resnet152d model average inference time : 23.603663444519043ms\n",
      "Benchmarking Inference tf_efficientnet_b4_ap \n",
      "tf_efficientnet_b4_ap model average inference time : 16.7331862449646ms\n",
      "Benchmarking Inference convnext_base \n",
      "convnext_base model average inference time : 10.320703983306885ms\n",
      "Benchmarking Inference tf_efficientnet_b5 \n",
      "tf_efficientnet_b5 model average inference time : 32.24097490310669ms\n",
      "Benchmarking Inference regnety_064 \n",
      "regnety_064 model average inference time : 31.58870220184326ms\n",
      "Benchmarking Inference crossvit_15_dagger_408 \n",
      "crossvit_15_dagger_408 model average inference time : 21.499099731445312ms\n",
      "Benchmarking Inference resnetrs152 \n",
      "resnetrs152 model average inference time : 29.965431690216064ms\n",
      "Benchmarking Inference xcit_small_12_p16_224_dist \n",
      "xcit_small_12_p16_224_dist model average inference time : 11.068792343139648ms\n",
      "pass regnetv_040\n",
      "Benchmarking Inference deit_base_distilled_patch16_224 \n",
      "deit_base_distilled_patch16_224 model average inference time : 7.1504807472229ms\n",
      "pass xception65p\n",
      "Benchmarking Inference xcit_large_24_p8_224 \n",
      "xcit_large_24_p8_224 model average inference time : 68.53860855102539ms\n",
      "Benchmarking Inference xcit_tiny_24_p16_384_dist \n",
      "xcit_tiny_24_p16_384_dist model average inference time : 20.207009315490723ms\n",
      "Benchmarking Inference resnetv2_152x2_bit_teacher_384 \n",
      "resnetv2_152x2_bit_teacher_384 model average inference time : 94.05856132507324ms\n",
      "Benchmarking Inference ig_resnext101_32x8d \n",
      "ig_resnext101_32x8d model average inference time : 19.3076491355896ms\n",
      "Benchmarking Inference cait_xxs36_384 \n",
      "cait_xxs36_384 model average inference time : 47.40920305252075ms\n",
      "Benchmarking Inference dm_nfnet_f0 \n",
      "dm_nfnet_f0 model average inference time : 54.40583944320679ms\n",
      "Benchmarking Inference xcit_tiny_12_p8_384_dist \n",
      "xcit_tiny_12_p8_384_dist model average inference time : 21.14933729171753ms\n",
      "Benchmarking Inference swsl_resnext101_32x4d \n",
      "swsl_resnext101_32x4d model average inference time : 12.841134071350098ms\n",
      "Benchmarking Inference xception65 \n",
      "xception65 model average inference time : 15.948817729949951ms\n",
      "Benchmarking Inference convnext_small \n",
      "convnext_small model average inference time : 8.712043762207031ms\n",
      "pass swin_s3_base_224\n",
      "Benchmarking Inference xcit_tiny_24_p8_224_dist \n",
      "xcit_tiny_24_p8_224_dist model average inference time : 18.82086753845215ms\n",
      "Benchmarking Inference eca_nfnet_l0 \n",
      "eca_nfnet_l0 model average inference time : 16.580514907836914ms\n",
      "Benchmarking Inference nfnet_l0 \n",
      "nfnet_l0 model average inference time : 17.78585195541382ms\n",
      "Benchmarking Inference xcit_small_24_p8_224 \n",
      "xcit_small_24_p8_224 model average inference time : 29.920661449432373ms\n",
      "Benchmarking Inference tf_efficientnet_b4 \n",
      "tf_efficientnet_b4 model average inference time : 16.942265033721924ms\n",
      "Benchmarking Inference resnet101d \n",
      "resnet101d model average inference time : 16.97296380996704ms\n",
      "Benchmarking Inference regnety_032 \n",
      "regnety_032 model average inference time : 13.885552883148193ms\n",
      "Benchmarking Inference regnety_040 \n",
      "regnety_040 model average inference time : 21.932520866394043ms\n",
      "Benchmarking Inference vit_base_patch32_384 \n",
      "vit_base_patch32_384 model average inference time : 7.118480205535889ms\n",
      "Benchmarking Inference twins_svt_large \n",
      "twins_svt_large model average inference time : 14.513535499572754ms\n",
      "Benchmarking Inference twins_pcpvt_large \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "twins_pcpvt_large model average inference time : 24.546501636505127ms\n",
      "Benchmarking Inference regnetz_c16 \n",
      "regnetz_c16 model average inference time : 15.338287353515625ms\n",
      "pass swin_s3_small_224\n",
      "Benchmarking Inference deit_base_patch16_384 \n",
      "deit_base_patch16_384 model average inference time : 25.87766408920288ms\n",
      "Benchmarking Inference xcit_small_12_p8_224 \n",
      "xcit_small_12_p8_224 model average inference time : 16.080288887023926ms\n",
      "Benchmarking Inference tresnet_xl_448 \n",
      "pass tresnet_xl_448\n",
      "Benchmarking Inference resnetv2_50x1_bit_distilled \n",
      "resnetv2_50x1_bit_distilled model average inference time : 7.775211334228516ms\n",
      "Benchmarking Inference tresnet_m \n",
      "pass tresnet_m\n",
      "Benchmarking Inference twins_pcpvt_base \n",
      "twins_pcpvt_base model average inference time : 16.96429967880249ms\n",
      "Benchmarking Inference gc_efficientnetv2_rw_t \n",
      "gc_efficientnetv2_rw_t model average inference time : 21.715924739837646ms\n",
      "Benchmarking Inference resnetv2_101x1_bitm \n",
      "resnetv2_101x1_bitm model average inference time : 36.600871086120605ms\n",
      "Benchmarking Inference swin_small_patch4_window7_224 \n",
      "swin_small_patch4_window7_224 model average inference time : 13.078370094299316ms\n",
      "Benchmarking Inference efficientnetv2_rw_t \n",
      "efficientnetv2_rw_t model average inference time : 17.014365196228027ms\n",
      "Benchmarking Inference twins_svt_base \n",
      "twins_svt_base model average inference time : 13.793895244598389ms\n",
      "Benchmarking Inference pnasnet5large \n",
      "pnasnet5large model average inference time : 40.550715923309326ms\n",
      "Benchmarking Inference jx_nest_base \n",
      "jx_nest_base model average inference time : 13.861017227172852ms\n",
      "Benchmarking Inference swsl_resnext101_32x16d \n",
      "swsl_resnext101_32x16d model average inference time : 35.40154218673706ms\n",
      "Benchmarking Inference xcit_medium_24_p8_224 \n",
      "xcit_medium_24_p8_224 model average inference time : 41.44044876098633ms\n",
      "Benchmarking Inference swsl_resnext50_32x4d \n",
      "swsl_resnext50_32x4d model average inference time : 6.892509460449219ms\n",
      "Benchmarking Inference levit_384 \n",
      "levit_384 model average inference time : 8.430521488189697ms\n",
      "Benchmarking Inference tf_efficientnet_b2_ns \n",
      "tf_efficientnet_b2_ns model average inference time : 10.981707572937012ms\n",
      "Benchmarking Inference ecaresnet50t \n",
      "ecaresnet50t model average inference time : 11.607410907745361ms\n",
      "Benchmarking Inference jx_nest_small \n",
      "jx_nest_small model average inference time : 10.505123138427734ms\n",
      "Benchmarking Inference resnetv2_152x2_bit_teacher \n",
      "resnetv2_152x2_bit_teacher model average inference time : 46.51663780212402ms\n",
      "Benchmarking Inference resnet152 \n",
      "resnet152 model average inference time : 15.047299861907959ms\n",
      "Benchmarking Inference fbnetv3_g \n",
      "fbnetv3_g model average inference time : 14.769823551177979ms\n",
      "Benchmarking Inference resnext101_64x4d \n",
      "resnext101_64x4d model average inference time : 26.32493257522583ms\n",
      "Benchmarking Inference resnet61q \n",
      "resnet61q model average inference time : 14.141292572021484ms\n",
      "Benchmarking Inference efficientnet_b3 \n",
      "efficientnet_b3 model average inference time : 13.08703899383545ms\n",
      "Benchmarking Inference cait_xxs24_384 \n",
      "cait_xxs24_384 model average inference time : 32.03303098678589ms\n",
      "Benchmarking Inference resnet51q \n",
      "resnet51q model average inference time : 13.129756450653076ms\n",
      "Benchmarking Inference coat_lite_small \n",
      "coat_lite_small model average inference time : 13.34057092666626ms\n",
      "Benchmarking Inference xcit_tiny_24_p8_224 \n",
      "xcit_tiny_24_p8_224 model average inference time : 18.665645122528076ms\n",
      "Benchmarking Inference tresnet_l_448 \n",
      "pass tresnet_l_448\n",
      "Benchmarking Inference nasnetalarge \n",
      "nasnetalarge model average inference time : 46.04686260223389ms\n",
      "Benchmarking Inference crossvit_18_dagger_240 \n",
      "crossvit_18_dagger_240 model average inference time : 12.792778015136719ms\n",
      "Benchmarking Inference resnetv2_101 \n",
      "resnetv2_101 model average inference time : 10.557188987731934ms\n",
      "Benchmarking Inference crossvit_18_240 \n",
      "crossvit_18_240 model average inference time : 11.873033046722412ms\n",
      "Benchmarking Inference convnext_tiny \n",
      "convnext_tiny model average inference time : 5.080981254577637ms\n",
      "Benchmarking Inference ecaresnet101d \n",
      "ecaresnet101d model average inference time : 13.33733081817627ms\n",
      "Benchmarking Inference resnest101e \n",
      "resnest101e model average inference time : 30.30930519104004ms\n",
      "Benchmarking Inference pit_s_distilled_224 \n",
      "pit_s_distilled_224 model average inference time : 5.930109024047852ms\n",
      "Benchmarking Inference resnetv2_50d_gn \n",
      "resnetv2_50d_gn model average inference time : 9.855432510375977ms\n",
      "Benchmarking Inference resnetrs101 \n",
      "resnetrs101 model average inference time : 20.154764652252197ms\n",
      "pass poolformer_m48\n",
      "Benchmarking Inference tresnet_xl \n",
      "pass tresnet_xl\n",
      "Benchmarking Inference mixer_b16_224_miil \n",
      "mixer_b16_224_miil model average inference time : 5.06256103515625ms\n",
      "Benchmarking Inference xcit_tiny_12_p8_224_dist \n",
      "xcit_tiny_12_p8_224_dist model average inference time : 10.514352321624756ms\n",
      "Benchmarking Inference xcit_tiny_12_p16_384_dist \n",
      "xcit_tiny_12_p16_384_dist model average inference time : 12.020678520202637ms\n",
      "Benchmarking Inference convit_base \n",
      "convit_base model average inference time : 10.279090404510498ms\n",
      "Benchmarking Inference resnetv2_50d_evos \n",
      "resnetv2_50d_evos model average inference time : 14.797675609588623ms\n",
      "Benchmarking Inference tf_efficientnet_b3_ap \n",
      "tf_efficientnet_b3_ap model average inference time : 13.199121952056885ms\n",
      "Benchmarking Inference visformer_small \n",
      "visformer_small model average inference time : 12.263660430908203ms\n",
      "Benchmarking Inference crossvit_15_dagger_240 \n",
      "crossvit_15_dagger_240 model average inference time : 11.4286470413208ms\n",
      "Benchmarking Inference xcit_small_24_p16_224 \n",
      "xcit_small_24_p16_224 model average inference time : 18.83232355117798ms\n",
      "pass swin_s3_tiny_224\n",
      "Benchmarking Inference resnet101 \n",
      "resnet101 model average inference time : 9.94724988937378ms\n",
      "Benchmarking Inference crossvit_15_240 \n",
      "crossvit_15_240 model average inference time : 10.9995698928833ms\n",
      "pass xception41p\n",
      "Benchmarking Inference convit_small \n",
      "convit_small model average inference time : 7.385740280151367ms\n",
      "Benchmarking Inference tf_efficientnetv2_b3 \n",
      "tf_efficientnetv2_b3 model average inference time : 14.91908073425293ms\n",
      "Benchmarking Inference regnetz_b16 \n",
      "regnetz_b16 model average inference time : 14.061450958251953ms\n",
      "Benchmarking Inference xcit_small_12_p16_224 \n",
      "xcit_small_12_p16_224 model average inference time : 10.804126262664795ms\n",
      "Benchmarking Inference jx_nest_tiny \n",
      "jx_nest_tiny model average inference time : 7.265286445617676ms\n",
      "Benchmarking Inference deit_small_distilled_patch16_224 \n",
      "deit_small_distilled_patch16_224 model average inference time : 5.485577583312988ms\n",
      "Benchmarking Inference resmlp_36_distilled_224 \n",
      "resmlp_36_distilled_224 model average inference time : 8.495986461639404ms\n",
      "Benchmarking Inference xcit_large_24_p16_224 \n",
      "xcit_large_24_p16_224 model average inference time : 20.18990993499756ms\n",
      "pass poolformer_m36\n",
      "Benchmarking Inference xcit_medium_24_p16_224 \n",
      "xcit_medium_24_p16_224 model average inference time : 19.263627529144287ms\n",
      "Benchmarking Inference convnext_tiny_hnf \n",
      "convnext_tiny_hnf model average inference time : 5.24477481842041ms\n",
      "Benchmarking Inference tnt_s_patch16_224 \n",
      "tnt_s_patch16_224 model average inference time : 11.555273532867432ms\n",
      "Benchmarking Inference ssl_resnext101_32x16d \n",
      "ssl_resnext101_32x16d model average inference time : 35.39109468460083ms\n",
      "Benchmarking Inference vit_small_patch16_224 \n",
      "vit_small_patch16_224 model average inference time : 5.44100284576416ms\n",
      "Benchmarking Inference vit_small_r26_s32_224 \n",
      "vit_small_r26_s32_224 model average inference time : 9.454784393310547ms\n",
      "Benchmarking Inference convmixer_1536_20 \n",
      "pass convmixer_1536_20\n",
      "Benchmarking Inference rexnet_200 \n",
      "rexnet_200 model average inference time : 8.69786024093628ms\n",
      "Benchmarking Inference tf_efficientnet_b3 \n",
      "tf_efficientnet_b3 model average inference time : 13.566012382507324ms\n",
      "Benchmarking Inference deit_base_patch16_224 \n",
      "deit_base_patch16_224 model average inference time : 7.090437412261963ms\n",
      "Benchmarking Inference swsl_resnet50 \n",
      "swsl_resnet50 model average inference time : 5.860764980316162ms\n",
      "Benchmarking Inference tresnet_m_448 \n",
      "pass tresnet_m_448\n",
      "Benchmarking Inference tf_efficientnet_lite4 \n",
      "tf_efficientnet_lite4 model average inference time : 12.407727241516113ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference ssl_resnext101_32x8d \n",
      "ssl_resnext101_32x8d model average inference time : 19.145667552947998ms\n",
      "Benchmarking Inference coat_mini \n",
      "coat_mini model average inference time : 22.62336254119873ms\n",
      "Benchmarking Inference tresnet_l \n",
      "pass tresnet_l\n",
      "Benchmarking Inference twins_svt_small \n",
      "twins_svt_small model average inference time : 10.445923805236816ms\n",
      "Benchmarking Inference crossvit_base_240 \n",
      "crossvit_base_240 model average inference time : 10.446040630340576ms\n",
      "Benchmarking Inference levit_256 \n",
      "levit_256 model average inference time : 8.004951477050781ms\n",
      "Benchmarking Inference seresnext50_32x4d \n",
      "seresnext50_32x4d model average inference time : 10.552456378936768ms\n",
      "Benchmarking Inference crossvit_small_240 \n",
      "crossvit_small_240 model average inference time : 9.910666942596436ms\n",
      "Benchmarking Inference halo2botnet50ts_256 \n",
      "halo2botnet50ts_256 model average inference time : 10.324373245239258ms\n",
      "Benchmarking Inference pit_b_224 \n",
      "pit_b_224 model average inference time : 8.096179962158203ms\n",
      "Benchmarking Inference tf_efficientnet_b1_ns \n",
      "tf_efficientnet_b1_ns model average inference time : 10.720136165618896ms\n",
      "Benchmarking Inference swin_tiny_patch4_window7_224 \n",
      "swin_tiny_patch4_window7_224 model average inference time : 7.22991943359375ms\n",
      "Benchmarking Inference wide_resnet50_2 \n",
      "wide_resnet50_2 model average inference time : 11.204559803009033ms\n",
      "Benchmarking Inference gernet_l \n",
      "gernet_l model average inference time : 13.144361972808838ms\n",
      "pass poolformer_s36\n",
      "Benchmarking Inference efficientnet_el \n",
      "efficientnet_el model average inference time : 10.913615226745605ms\n",
      "Benchmarking Inference twins_pcpvt_small \n",
      "twins_pcpvt_small model average inference time : 10.25561809539795ms\n",
      "Benchmarking Inference resmlp_24_distilled_224 \n",
      "resmlp_24_distilled_224 model average inference time : 6.102869510650635ms\n",
      "Benchmarking Inference nf_resnet50 \n",
      "nf_resnet50 model average inference time : 10.765523910522461ms\n",
      "Benchmarking Inference resnest50d_4s2x40d \n",
      "resnest50d_4s2x40d model average inference time : 22.783632278442383ms\n",
      "Benchmarking Inference efficientnet_b3_pruned \n",
      "efficientnet_b3_pruned model average inference time : 12.694363594055176ms\n",
      "Benchmarking Inference sebotnet33ts_256 \n",
      "sebotnet33ts_256 model average inference time : 7.925839424133301ms\n",
      "Benchmarking Inference sehalonet33ts \n",
      "sehalonet33ts model average inference time : 8.051953315734863ms\n",
      "Benchmarking Inference repvgg_b3 \n",
      "repvgg_b3 model average inference time : 19.02237892150879ms\n",
      "Benchmarking Inference xcit_tiny_24_p16_224_dist \n",
      "xcit_tiny_24_p16_224_dist model average inference time : 18.665771484375ms\n",
      "Benchmarking Inference halonet50ts \n",
      "halonet50ts model average inference time : 9.902174472808838ms\n",
      "Benchmarking Inference ssl_resnext101_32x4d \n",
      "ssl_resnext101_32x4d model average inference time : 12.611494064331055ms\n",
      "Benchmarking Inference gcresnet50t \n",
      "gcresnet50t model average inference time : 11.630778312683105ms\n",
      "Benchmarking Inference ecaresnet50d \n",
      "ecaresnet50d model average inference time : 7.228231430053711ms\n",
      "Benchmarking Inference gluon_resnet152_v1s \n",
      "gluon_resnet152_v1s model average inference time : 15.292716026306152ms\n",
      "Benchmarking Inference haloregnetz_b \n",
      "haloregnetz_b model average inference time : 14.108097553253174ms\n",
      "Benchmarking Inference resnest50d_1s4x24d \n",
      "resnest50d_1s4x24d model average inference time : 13.995170593261719ms\n",
      "Benchmarking Inference resnetv2_50x1_bitm \n",
      "resnetv2_50x1_bitm model average inference time : 20.829427242279053ms\n",
      "Benchmarking Inference repvgg_b3g4 \n",
      "repvgg_b3g4 model average inference time : 21.494791507720947ms\n",
      "Benchmarking Inference lamhalobotnet50ts_256 \n",
      "lamhalobotnet50ts_256 model average inference time : 9.435303211212158ms\n",
      "Benchmarking Inference legacy_senet154 \n",
      "legacy_senet154 model average inference time : 34.86727952957153ms\n",
      "Benchmarking Inference cait_xxs36_224 \n",
      "cait_xxs36_224 model average inference time : 20.563640594482422ms\n",
      "Benchmarking Inference resnext50_32x4d \n",
      "resnext50_32x4d model average inference time : 6.777701377868652ms\n",
      "Benchmarking Inference gernet_m \n",
      "gernet_m model average inference time : 5.1569294929504395ms\n",
      "Benchmarking Inference pit_s_224 \n",
      "pit_s_224 model average inference time : 5.857207775115967ms\n",
      "Benchmarking Inference efficientnet_b2 \n",
      "efficientnet_b2 model average inference time : 11.215276718139648ms\n",
      "Benchmarking Inference vit_small_patch32_384 \n",
      "vit_small_patch32_384 model average inference time : 7.231400012969971ms\n",
      "Benchmarking Inference gluon_senet154 \n",
      "gluon_senet154 model average inference time : 34.84896659851074ms\n",
      "Benchmarking Inference resnest50d \n",
      "resnest50d model average inference time : 13.842880725860596ms\n",
      "Benchmarking Inference convmixer_768_32 \n",
      "pass convmixer_768_32\n",
      "Benchmarking Inference ecaresnet101d_pruned \n",
      "ecaresnet101d_pruned model average inference time : 12.142655849456787ms\n",
      "Benchmarking Inference efficientnet_el_pruned \n",
      "efficientnet_el_pruned model average inference time : 10.909664630889893ms\n",
      "Benchmarking Inference cspdarknet53 \n",
      "cspdarknet53 model average inference time : 12.367355823516846ms\n",
      "Benchmarking Inference inception_v4 \n",
      "inception_v4 model average inference time : 19.805145263671875ms\n",
      "Benchmarking Inference rexnet_150 \n",
      "rexnet_150 model average inference time : 8.9851713180542ms\n",
      "Benchmarking Inference inception_resnet_v2 \n",
      "inception_resnet_v2 model average inference time : 28.955624103546143ms\n",
      "Benchmarking Inference xcit_tiny_12_p8_224 \n",
      "xcit_tiny_12_p8_224 model average inference time : 10.839853286743164ms\n",
      "Benchmarking Inference ssl_resnext50_32x4d \n",
      "ssl_resnext50_32x4d model average inference time : 6.850457191467285ms\n",
      "Benchmarking Inference tf_efficientnet_el \n",
      "tf_efficientnet_el model average inference time : 11.13243818283081ms\n",
      "Benchmarking Inference gluon_resnet101_v1s \n",
      "gluon_resnet101_v1s model average inference time : 10.38534164428711ms\n",
      "Benchmarking Inference ecaresnetlight \n",
      "ecaresnetlight model average inference time : 7.019798755645752ms\n",
      "Benchmarking Inference lambda_resnet50ts \n",
      "lambda_resnet50ts model average inference time : 9.587419033050537ms\n",
      "pass poolformer_s24\n",
      "Benchmarking Inference gluon_seresnext101_32x4d \n",
      "gluon_seresnext101_32x4d model average inference time : 20.752921104431152ms\n",
      "Benchmarking Inference resnetv2_50 \n",
      "resnetv2_50 model average inference time : 5.9873270988464355ms\n",
      "Benchmarking Inference gcresnext50ts \n",
      "gcresnext50ts model average inference time : 13.992786407470703ms\n",
      "Benchmarking Inference seresnet33ts \n",
      "seresnet33ts model average inference time : 8.22908639907837ms\n",
      "Benchmarking Inference resnet50d \n",
      "resnet50d model average inference time : 6.174285411834717ms\n",
      "Benchmarking Inference ecaresnet26t \n",
      "ecaresnet26t model average inference time : 7.764883041381836ms\n",
      "Benchmarking Inference tf_efficientnet_b2_ap \n",
      "tf_efficientnet_b2_ap model average inference time : 11.208689212799072ms\n",
      "Benchmarking Inference gluon_seresnext101_64x4d \n",
      "gluon_seresnext101_64x4d model average inference time : 23.712027072906494ms\n",
      "Benchmarking Inference vit_base_patch32_224 \n",
      "vit_base_patch32_224 model average inference time : 5.620212554931641ms\n",
      "Benchmarking Inference fbnetv3_d \n",
      "fbnetv3_d model average inference time : 11.430552005767822ms\n",
      "Benchmarking Inference gluon_resnet152_v1d \n",
      "gluon_resnet152_v1d model average inference time : 15.431807041168213ms\n",
      "Benchmarking Inference vit_large_patch32_384 \n",
      "vit_large_patch32_384 model average inference time : 16.533348560333252ms\n",
      "Benchmarking Inference tf_efficientnetv2_b2 \n",
      "tf_efficientnetv2_b2 model average inference time : 11.760330200195312ms\n",
      "Benchmarking Inference tf_efficientnet_b2 \n",
      "tf_efficientnet_b2 model average inference time : 10.918102264404297ms\n",
      "Benchmarking Inference resnet50_gn \n",
      "resnet50_gn model average inference time : 6.137242317199707ms\n",
      "pass vit_base_patch16_224_sam\n",
      "Benchmarking Inference seresnet50 \n",
      "seresnet50 model average inference time : 9.397022724151611ms\n",
      "Benchmarking Inference gluon_resnet101_v1d \n",
      "gluon_resnet101_v1d model average inference time : 10.443148612976074ms\n",
      "Benchmarking Inference repvgg_b2g4 \n",
      "repvgg_b2g4 model average inference time : 19.88224744796753ms\n",
      "Benchmarking Inference gcresnet33ts \n",
      "gcresnet33ts model average inference time : 8.920974731445312ms\n",
      "Benchmarking Inference mixnet_xl \n",
      "mixnet_xl model average inference time : 15.17538070678711ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference ens_adv_inception_resnet_v2 \n",
      "ens_adv_inception_resnet_v2 model average inference time : 28.72898817062378ms\n",
      "Benchmarking Inference tf_efficientnet_lite3 \n",
      "tf_efficientnet_lite3 model average inference time : 7.2660040855407715ms\n",
      "Benchmarking Inference cspresnext50 \n",
      "cspresnext50 model average inference time : 7.168848514556885ms\n",
      "Benchmarking Inference ese_vovnet39b \n",
      "ese_vovnet39b model average inference time : 6.919662952423096ms\n",
      "Benchmarking Inference gluon_resnext101_32x4d \n",
      "gluon_resnext101_32x4d model average inference time : 12.791025638580322ms\n",
      "Benchmarking Inference legacy_seresnext101_32x4d \n",
      "legacy_seresnext101_32x4d model average inference time : 20.8756160736084ms\n",
      "Benchmarking Inference eca_resnet33ts \n",
      "eca_resnet33ts model average inference time : 7.969191074371338ms\n",
      "Benchmarking Inference xcit_tiny_24_p16_224 \n",
      "xcit_tiny_24_p16_224 model average inference time : 19.108028411865234ms\n",
      "Benchmarking Inference regnety_320 \n",
      "regnety_320 model average inference time : 36.981282234191895ms\n",
      "Benchmarking Inference cspresnet50 \n",
      "cspresnet50 model average inference time : 7.57429838180542ms\n",
      "Benchmarking Inference resnet50 \n",
      "resnet50 model average inference time : 5.7933878898620605ms\n",
      "Benchmarking Inference resmlp_big_24_224 \n",
      "resmlp_big_24_224 model average inference time : 34.056992530822754ms\n",
      "Benchmarking Inference xception71 \n",
      "xception71 model average inference time : 20.659208297729492ms\n",
      "Benchmarking Inference gluon_resnext101_64x4d \n",
      "gluon_resnext101_64x4d model average inference time : 19.74083423614502ms\n",
      "Benchmarking Inference efficientnet_em \n",
      "efficientnet_em model average inference time : 6.00083589553833ms\n",
      "Benchmarking Inference deit_small_patch16_224 \n",
      "deit_small_patch16_224 model average inference time : 5.465109348297119ms\n",
      "Benchmarking Inference pit_xs_distilled_224 \n",
      "pit_xs_distilled_224 model average inference time : 5.839943885803223ms\n",
      "Benchmarking Inference dpn107 \n",
      "dpn107 model average inference time : 25.170063972473145ms\n",
      "Benchmarking Inference efficientnet_b2_pruned \n",
      "efficientnet_b2_pruned model average inference time : 10.21066665649414ms\n",
      "Benchmarking Inference resmlp_36_224 \n",
      "resmlp_36_224 model average inference time : 8.788459300994873ms\n",
      "Benchmarking Inference ecaresnet50d_pruned \n",
      "ecaresnet50d_pruned model average inference time : 7.139780521392822ms\n",
      "Benchmarking Inference gluon_resnet152_v1c \n",
      "gluon_resnet152_v1c model average inference time : 15.062549114227295ms\n",
      "Benchmarking Inference levit_192 \n",
      "levit_192 model average inference time : 7.895545959472656ms\n",
      "Benchmarking Inference resnext50d_32x4d \n",
      "resnext50d_32x4d model average inference time : 7.192068099975586ms\n",
      "Benchmarking Inference tf_efficientnetv2_b1 \n",
      "tf_efficientnetv2_b1 model average inference time : 11.18004560470581ms\n",
      "Benchmarking Inference regnety_120 \n",
      "regnety_120 model average inference time : 23.375821113586426ms\n",
      "Benchmarking Inference fbnetv3_b \n",
      "fbnetv3_b model average inference time : 10.709824562072754ms\n",
      "Benchmarking Inference regnetx_320 \n",
      "regnetx_320 model average inference time : 36.26053810119629ms\n",
      "Benchmarking Inference dpn92 \n",
      "dpn92 model average inference time : 12.765398025512695ms\n",
      "Benchmarking Inference nf_regnet_b1 \n",
      "nf_regnet_b1 model average inference time : 15.710258483886719ms\n",
      "Benchmarking Inference rexnet_130 \n",
      "rexnet_130 model average inference time : 8.805513381958008ms\n",
      "Benchmarking Inference gluon_resnet152_v1b \n",
      "gluon_resnet152_v1b model average inference time : 15.094666481018066ms\n",
      "Benchmarking Inference resnetrs50 \n",
      "resnetrs50 model average inference time : 9.032797813415527ms\n",
      "Benchmarking Inference dpn131 \n",
      "dpn131 model average inference time : 23.090078830718994ms\n",
      "Benchmarking Inference regnetx_160 \n",
      "regnetx_160 model average inference time : 26.60965919494629ms\n",
      "Benchmarking Inference dla102x2 \n",
      "dla102x2 model average inference time : 16.048717498779297ms\n",
      "Benchmarking Inference gmlp_s16_224 \n",
      "gmlp_s16_224 model average inference time : 7.902042865753174ms\n",
      "Benchmarking Inference botnet26t_256 \n",
      "botnet26t_256 model average inference time : 5.721533298492432ms\n",
      "Benchmarking Inference gluon_seresnext50_32x4d \n",
      "gluon_seresnext50_32x4d model average inference time : 10.422158241271973ms\n",
      "Benchmarking Inference skresnext50_32x4d \n",
      "skresnext50_32x4d model average inference time : 14.28220510482788ms\n",
      "Benchmarking Inference dpn98 \n",
      "dpn98 model average inference time : 16.881685256958008ms\n",
      "Benchmarking Inference gluon_resnet101_v1c \n",
      "gluon_resnet101_v1c model average inference time : 10.45914888381958ms\n",
      "Benchmarking Inference lambda_resnet26t \n",
      "lambda_resnet26t model average inference time : 5.741283893585205ms\n",
      "Benchmarking Inference dpn68b \n",
      "dpn68b model average inference time : 10.936832427978516ms\n",
      "Benchmarking Inference resnetblur50 \n",
      "resnetblur50 model average inference time : 5.8751702308654785ms\n",
      "Benchmarking Inference resmlp_24_224 \n",
      "resmlp_24_224 model average inference time : 5.954220294952393ms\n",
      "Benchmarking Inference coat_lite_mini \n",
      "coat_lite_mini model average inference time : 7.50856876373291ms\n",
      "Benchmarking Inference cait_xxs24_224 \n",
      "cait_xxs24_224 model average inference time : 14.889631271362305ms\n",
      "Benchmarking Inference resnet33ts \n",
      "resnet33ts model average inference time : 7.780876159667969ms\n",
      "Benchmarking Inference xcit_tiny_12_p16_224_dist \n",
      "xcit_tiny_12_p16_224_dist model average inference time : 10.753610134124756ms\n",
      "Benchmarking Inference halonet26t \n",
      "halonet26t model average inference time : 5.956995487213135ms\n",
      "Benchmarking Inference resnext101_32x8d \n",
      "resnext101_32x8d model average inference time : 19.138154983520508ms\n",
      "Benchmarking Inference gluon_inception_v3 \n",
      "gluon_inception_v3 model average inference time : 10.75411319732666ms\n",
      "Benchmarking Inference resnet32ts \n",
      "resnet32ts model average inference time : 7.543859481811523ms\n",
      "Benchmarking Inference hrnet_w48 \n",
      "hrnet_w48 model average inference time : 35.02457857131958ms\n",
      "Benchmarking Inference gluon_xception65 \n",
      "gluon_xception65 model average inference time : 15.7515549659729ms\n",
      "Benchmarking Inference gluon_resnet101_v1b \n",
      "gluon_resnet101_v1b model average inference time : 10.130970478057861ms\n",
      "Benchmarking Inference tf_efficientnet_b1_ap \n",
      "tf_efficientnet_b1_ap model average inference time : 10.730195045471191ms\n",
      "Benchmarking Inference eca_halonext26ts \n",
      "eca_halonext26ts model average inference time : 6.872460842132568ms\n",
      "Benchmarking Inference regnetx_120 \n",
      "regnetx_120 model average inference time : 21.447408199310303ms\n",
      "Benchmarking Inference eca_botnext26ts_256 \n",
      "eca_botnext26ts_256 model average inference time : 6.703970432281494ms\n",
      "Benchmarking Inference xception \n",
      "xception model average inference time : 9.577939510345459ms\n",
      "Benchmarking Inference hrnet_w64 \n",
      "hrnet_w64 model average inference time : 32.95371055603027ms\n",
      "Benchmarking Inference ssl_resnet50 \n",
      "ssl_resnet50 model average inference time : 5.958406925201416ms\n",
      "Benchmarking Inference lambda_resnet26rpt_256 \n",
      "lambda_resnet26rpt_256 model average inference time : 6.539220809936523ms\n",
      "Benchmarking Inference res2net101_26w_4s \n",
      "res2net101_26w_4s model average inference time : 18.40484380722046ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b1_8e \n",
      "tf_efficientnet_cc_b1_8e model average inference time : 13.444218635559082ms\n",
      "Benchmarking Inference xcit_nano_12_p8_384_dist \n",
      "xcit_nano_12_p8_384_dist model average inference time : 14.677865505218506ms\n",
      "Benchmarking Inference gluon_resnext50_32x4d \n",
      "gluon_resnext50_32x4d model average inference time : 6.836788654327393ms\n",
      "Benchmarking Inference resnest26d \n",
      "resnest26d model average inference time : 9.251871109008789ms\n",
      "Benchmarking Inference tf_efficientnet_b0_ns \n",
      "tf_efficientnet_b0_ns model average inference time : 7.803337574005127ms\n",
      "Benchmarking Inference coat_tiny \n",
      "coat_tiny model average inference time : 22.171547412872314ms\n",
      "Benchmarking Inference dla169 \n",
      "dla169 model average inference time : 16.555702686309814ms\n",
      "Benchmarking Inference tf_efficientnet_b1 \n",
      "tf_efficientnet_b1 model average inference time : 10.539169311523438ms\n",
      "Benchmarking Inference legacy_seresnext50_32x4d \n",
      "legacy_seresnext50_32x4d model average inference time : 10.411221981048584ms\n",
      "Benchmarking Inference hrnet_w44 \n",
      "hrnet_w44 model average inference time : 34.888949394226074ms\n",
      "Benchmarking Inference regnetx_080 \n",
      "regnetx_080 model average inference time : 16.234798431396484ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference gluon_resnet50_v1s \n",
      "gluon_resnet50_v1s model average inference time : 6.035289764404297ms\n",
      "Benchmarking Inference res2net50_26w_8s \n",
      "res2net50_26w_8s model average inference time : 16.747329235076904ms\n",
      "Benchmarking Inference levit_128 \n",
      "levit_128 model average inference time : 7.820119857788086ms\n",
      "Benchmarking Inference vit_tiny_patch16_384 \n",
      "vit_tiny_patch16_384 model average inference time : 7.432727813720703ms\n",
      "Benchmarking Inference gluon_resnet50_v1d \n",
      "gluon_resnet50_v1d model average inference time : 6.278553009033203ms\n",
      "Benchmarking Inference dla60_res2next \n",
      "dla60_res2next model average inference time : 16.613309383392334ms\n",
      "Benchmarking Inference mixnet_l \n",
      "mixnet_l model average inference time : 12.269172668457031ms\n",
      "Benchmarking Inference tv_resnet152 \n",
      "tv_resnet152 model average inference time : 15.204079151153564ms\n",
      "Benchmarking Inference dla102x \n",
      "dla102x model average inference time : 12.948100566864014ms\n",
      "Benchmarking Inference dla60_res2net \n",
      "dla60_res2net model average inference time : 10.980570316314697ms\n",
      "Benchmarking Inference pit_xs_224 \n",
      "pit_xs_224 model average inference time : 5.659186840057373ms\n",
      "Benchmarking Inference xception41 \n",
      "xception41 model average inference time : 11.514616012573242ms\n",
      "Benchmarking Inference regnetx_064 \n",
      "regnetx_064 model average inference time : 10.897455215454102ms\n",
      "Benchmarking Inference hrnet_w40 \n",
      "hrnet_w40 model average inference time : 32.83499002456665ms\n",
      "Benchmarking Inference res2net50_26w_6s \n",
      "res2net50_26w_6s model average inference time : 13.311500549316406ms\n",
      "Benchmarking Inference repvgg_b2 \n",
      "repvgg_b2 model average inference time : 13.478734493255615ms\n",
      "Benchmarking Inference resmlp_12_distilled_224 \n",
      "resmlp_12_distilled_224 model average inference time : 3.605632781982422ms\n",
      "Benchmarking Inference legacy_seresnet152 \n",
      "legacy_seresnet152 model average inference time : 26.78049325942993ms\n",
      "Benchmarking Inference selecsls60b \n",
      "selecsls60b model average inference time : 7.022583484649658ms\n",
      "Benchmarking Inference hrnet_w32 \n",
      "hrnet_w32 model average inference time : 31.91704511642456ms\n",
      "Benchmarking Inference bat_resnext26ts \n",
      "bat_resnext26ts model average inference time : 11.96051836013794ms\n",
      "Benchmarking Inference tf_efficientnetv2_b0 \n",
      "tf_efficientnetv2_b0 model average inference time : 9.29534912109375ms\n",
      "Benchmarking Inference efficientnet_b1 \n",
      "efficientnet_b1 model average inference time : 10.567822456359863ms\n",
      "Benchmarking Inference regnetx_040 \n",
      "regnetx_040 model average inference time : 9.524917602539062ms\n",
      "Benchmarking Inference efficientnet_es \n",
      "efficientnet_es model average inference time : 4.870796203613281ms\n",
      "Benchmarking Inference hrnet_w30 \n",
      "hrnet_w30 model average inference time : 32.073707580566406ms\n",
      "Benchmarking Inference tf_mixnet_l \n",
      "tf_mixnet_l model average inference time : 12.706527709960938ms\n",
      "Benchmarking Inference wide_resnet101_2 \n",
      "wide_resnet101_2 model average inference time : 18.523643016815186ms\n",
      "Benchmarking Inference dla60x \n",
      "dla60x model average inference time : 7.814216613769531ms\n",
      "Benchmarking Inference legacy_seresnet101 \n",
      "legacy_seresnet101 model average inference time : 17.845802307128906ms\n",
      "Benchmarking Inference resnet26t \n",
      "resnet26t model average inference time : 5.457029342651367ms\n",
      "Benchmarking Inference coat_lite_tiny \n",
      "coat_lite_tiny model average inference time : 7.5011372566223145ms\n",
      "Benchmarking Inference tf_efficientnet_em \n",
      "tf_efficientnet_em model average inference time : 6.299922466278076ms\n",
      "Benchmarking Inference repvgg_b1 \n",
      "repvgg_b1 model average inference time : 10.364394187927246ms\n",
      "Benchmarking Inference efficientnet_b1_pruned \n",
      "efficientnet_b1_pruned model average inference time : 10.096492767333984ms\n",
      "Benchmarking Inference res2net50_26w_4s \n",
      "res2net50_26w_4s model average inference time : 9.876580238342285ms\n",
      "Benchmarking Inference hardcorenas_f \n",
      "hardcorenas_f model average inference time : 7.617213726043701ms\n",
      "Benchmarking Inference res2net50_14w_8s \n",
      "res2net50_14w_8s model average inference time : 15.424914360046387ms\n",
      "Benchmarking Inference selecsls60 \n",
      "selecsls60 model average inference time : 6.74813985824585ms\n",
      "pass mobilevit_s\n",
      "Benchmarking Inference regnetx_032 \n",
      "regnetx_032 model average inference time : 9.097542762756348ms\n",
      "Benchmarking Inference res2next50 \n",
      "res2next50 model average inference time : 16.03184938430786ms\n",
      "Benchmarking Inference gluon_resnet50_v1c \n",
      "gluon_resnet50_v1c model average inference time : 6.053919792175293ms\n",
      "Benchmarking Inference dla102 \n",
      "dla102 model average inference time : 10.662713050842285ms\n",
      "Benchmarking Inference gcresnext26ts \n",
      "gcresnext26ts model average inference time : 7.573559284210205ms\n",
      "Benchmarking Inference rexnet_100 \n",
      "rexnet_100 model average inference time : 8.967130184173584ms\n",
      "Benchmarking Inference seresnext26ts \n",
      "seresnext26ts model average inference time : 7.2696661949157715ms\n",
      "Benchmarking Inference tf_inception_v3 \n",
      "tf_inception_v3 model average inference time : 10.88449478149414ms\n",
      "Benchmarking Inference res2net50_48w_2s \n",
      "res2net50_48w_2s model average inference time : 6.728930473327637ms\n",
      "Benchmarking Inference xcit_tiny_12_p16_224 \n",
      "xcit_tiny_12_p16_224 model average inference time : 10.727407932281494ms\n",
      "Benchmarking Inference resnet34d \n",
      "resnet34d model average inference time : 4.745206832885742ms\n",
      "Benchmarking Inference tf_efficientnet_lite2 \n",
      "tf_efficientnet_lite2 model average inference time : 6.246969699859619ms\n",
      "pass poolformer_s12\n",
      "Benchmarking Inference efficientnet_b0 \n",
      "efficientnet_b0 model average inference time : 7.8281569480896ms\n",
      "Benchmarking Inference crossvit_9_dagger_240 \n",
      "crossvit_9_dagger_240 model average inference time : 9.307222366333008ms\n",
      "Benchmarking Inference hardcorenas_e \n",
      "hardcorenas_e model average inference time : 7.73256778717041ms\n",
      "Benchmarking Inference gmixer_24_224 \n",
      "gmixer_24_224 model average inference time : 8.668718338012695ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b0_8e \n",
      "tf_efficientnet_cc_b0_8e model average inference time : 9.725077152252197ms\n",
      "Benchmarking Inference regnety_016 \n",
      "regnety_016 model average inference time : 13.357937335968018ms\n",
      "Benchmarking Inference tv_resnext50_32x4d \n",
      "tv_resnext50_32x4d model average inference time : 6.831612586975098ms\n",
      "Benchmarking Inference gluon_resnet50_v1b \n",
      "gluon_resnet50_v1b model average inference time : 5.908632278442383ms\n",
      "Benchmarking Inference densenet161 \n",
      "densenet161 model average inference time : 18.09764862060547ms\n",
      "Benchmarking Inference adv_inception_v3 \n",
      "adv_inception_v3 model average inference time : 10.546283721923828ms\n",
      "Benchmarking Inference mobilenetv2_120d \n",
      "mobilenetv2_120d model average inference time : 6.720249652862549ms\n",
      "Benchmarking Inference seresnext26t_32x4d \n",
      "seresnext26t_32x4d model average inference time : 6.167941093444824ms\n",
      "Benchmarking Inference tv_resnet101 \n",
      "tv_resnet101 model average inference time : 10.379955768585205ms\n",
      "Benchmarking Inference tinynet_a \n",
      "tinynet_a model average inference time : 9.371922016143799ms\n",
      "Benchmarking Inference hardcorenas_d \n",
      "hardcorenas_d model average inference time : 7.696280479431152ms\n",
      "Benchmarking Inference inception_v3 \n",
      "inception_v3 model average inference time : 10.290961265563965ms\n",
      "Benchmarking Inference seresnext26d_32x4d \n",
      "seresnext26d_32x4d model average inference time : 6.1476969718933105ms\n",
      "Benchmarking Inference dla60 \n",
      "dla60 model average inference time : 6.594822406768799ms\n",
      "Benchmarking Inference xcit_nano_12_p8_224_dist \n",
      "xcit_nano_12_p8_224_dist model average inference time : 10.99086046218872ms\n",
      "Benchmarking Inference eca_resnext26ts \n",
      "eca_resnext26ts model average inference time : 6.967966556549072ms\n",
      "Benchmarking Inference repvgg_b1g4 \n",
      "repvgg_b1g4 model average inference time : 15.6068754196167ms\n",
      "Benchmarking Inference convmixer_1024_20_ks9_p14 \n",
      "pass convmixer_1024_20_ks9_p14\n",
      "Benchmarking Inference legacy_seresnet50 \n",
      "legacy_seresnet50 model average inference time : 9.246330261230469ms\n",
      "Benchmarking Inference tf_efficientnet_b0_ap \n",
      "tf_efficientnet_b0_ap model average inference time : 7.965834140777588ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b0_4e \n",
      "tf_efficientnet_cc_b0_4e model average inference time : 9.602515697479248ms\n",
      "Benchmarking Inference skresnet34 \n",
      "skresnet34 model average inference time : 11.708900928497314ms\n",
      "Benchmarking Inference resmlp_12_224 \n",
      "resmlp_12_224 model average inference time : 3.5886144638061523ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference mobilenetv3_large_100_miil \n",
      "mobilenetv3_large_100_miil model average inference time : 6.05299711227417ms\n",
      "Benchmarking Inference densenet201 \n",
      "densenet201 model average inference time : 22.879717350006104ms\n",
      "Benchmarking Inference gernet_s \n",
      "gernet_s model average inference time : 4.9816060066223145ms\n",
      "Benchmarking Inference legacy_seresnext26_32x4d \n",
      "legacy_seresnext26_32x4d model average inference time : 5.817451477050781ms\n",
      "Benchmarking Inference mixnet_m \n",
      "mixnet_m model average inference time : 11.988372802734375ms\n",
      "Benchmarking Inference tf_efficientnet_b0 \n",
      "tf_efficientnet_b0 model average inference time : 7.770888805389404ms\n",
      "Benchmarking Inference hrnet_w18 \n",
      "hrnet_w18 model average inference time : 30.80608367919922ms\n",
      "Benchmarking Inference resnext26ts \n",
      "resnext26ts model average inference time : 6.742100715637207ms\n",
      "Benchmarking Inference densenetblur121d \n",
      "densenetblur121d model average inference time : 13.999888896942139ms\n",
      "Benchmarking Inference selecsls42b \n",
      "selecsls42b model average inference time : 5.568068027496338ms\n",
      "Benchmarking Inference hardcorenas_c \n",
      "hardcorenas_c model average inference time : 5.877876281738281ms\n",
      "Benchmarking Inference tf_efficientnet_lite1 \n",
      "tf_efficientnet_lite1 model average inference time : 5.6064605712890625ms\n",
      "Benchmarking Inference regnetx_016 \n",
      "regnetx_016 model average inference time : 7.314951419830322ms\n",
      "Benchmarking Inference dpn68 \n",
      "dpn68 model average inference time : 10.054221153259277ms\n",
      "Benchmarking Inference mobilenetv2_140 \n",
      "mobilenetv2_140 model average inference time : 4.443831443786621ms\n",
      "Benchmarking Inference tf_efficientnet_es \n",
      "tf_efficientnet_es model average inference time : 4.689013957977295ms\n",
      "Benchmarking Inference tf_mixnet_m \n",
      "tf_mixnet_m model average inference time : 12.308733463287354ms\n",
      "Benchmarking Inference xcit_nano_12_p16_384_dist \n",
      "xcit_nano_12_p16_384_dist model average inference time : 12.118206024169922ms\n",
      "Benchmarking Inference ese_vovnet19b_dw \n",
      "ese_vovnet19b_dw model average inference time : 4.0004706382751465ms\n",
      "Benchmarking Inference levit_128s \n",
      "levit_128s model average inference time : 6.559152603149414ms\n",
      "Benchmarking Inference resnet26d \n",
      "resnet26d model average inference time : 4.040932655334473ms\n",
      "Benchmarking Inference repvgg_a2 \n",
      "repvgg_a2 model average inference time : 5.714998245239258ms\n",
      "Benchmarking Inference tv_resnet50 \n",
      "tv_resnet50 model average inference time : 5.802786350250244ms\n",
      "Benchmarking Inference hardcorenas_b \n",
      "hardcorenas_b model average inference time : 5.633726119995117ms\n",
      "Benchmarking Inference densenet121 \n",
      "densenet121 model average inference time : 13.749330043792725ms\n",
      "Benchmarking Inference vit_tiny_r_s16_p8_384 \n",
      "vit_tiny_r_s16_p8_384 model average inference time : 7.194309234619141ms\n",
      "Benchmarking Inference densenet169 \n",
      "densenet169 model average inference time : 19.284188747406006ms\n",
      "Benchmarking Inference mixnet_s \n",
      "mixnet_s model average inference time : 10.246307849884033ms\n",
      "Benchmarking Inference vit_small_patch32_224 \n",
      "vit_small_patch32_224 model average inference time : 5.250275135040283ms\n",
      "Benchmarking Inference regnety_008 \n",
      "regnety_008 model average inference time : 7.788288593292236ms\n",
      "Benchmarking Inference efficientnet_lite0 \n",
      "efficientnet_lite0 model average inference time : 4.412810802459717ms\n",
      "Benchmarking Inference resnest14d \n",
      "resnest14d model average inference time : 6.9300127029418945ms\n",
      "Benchmarking Inference hardcorenas_a \n",
      "hardcorenas_a model average inference time : 4.856572151184082ms\n",
      "Benchmarking Inference efficientnet_es_pruned \n",
      "efficientnet_es_pruned model average inference time : 4.939916133880615ms\n",
      "Benchmarking Inference mobilenetv3_rw \n",
      "mobilenetv3_rw model average inference time : 5.635652542114258ms\n",
      "Benchmarking Inference semnasnet_100 \n",
      "semnasnet_100 model average inference time : 5.670835971832275ms\n",
      "Benchmarking Inference mobilenetv3_large_100 \n",
      "mobilenetv3_large_100 model average inference time : 6.002504825592041ms\n",
      "Benchmarking Inference resnet34 \n",
      "resnet34 model average inference time : 4.344308376312256ms\n",
      "Benchmarking Inference vit_tiny_patch16_224 \n",
      "vit_tiny_patch16_224 model average inference time : 5.210075378417969ms\n",
      "Benchmarking Inference mobilenetv2_110d \n",
      "mobilenetv2_110d model average inference time : 5.651583671569824ms\n",
      "Benchmarking Inference tf_mixnet_s \n",
      "tf_mixnet_s model average inference time : 10.167324542999268ms\n",
      "Benchmarking Inference repvgg_b0 \n",
      "repvgg_b0 model average inference time : 6.4287614822387695ms\n",
      "Benchmarking Inference deit_tiny_distilled_patch16_224 \n",
      "deit_tiny_distilled_patch16_224 model average inference time : 5.610373020172119ms\n",
      "Benchmarking Inference mixer_b16_224 \n",
      "mixer_b16_224 model average inference time : 5.068957805633545ms\n",
      "Benchmarking Inference pit_ti_distilled_224 \n",
      "pit_ti_distilled_224 model average inference time : 5.421543121337891ms\n",
      "Benchmarking Inference hrnet_w18_small_v2 \n",
      "hrnet_w18_small_v2 model average inference time : 16.914896965026855ms\n",
      "Benchmarking Inference resnet26 \n",
      "resnet26 model average inference time : 3.7747788429260254ms\n",
      "Benchmarking Inference tf_efficientnet_lite0 \n",
      "tf_efficientnet_lite0 model average inference time : 4.839634895324707ms\n",
      "Benchmarking Inference tinynet_b \n",
      "tinynet_b model average inference time : 8.059356212615967ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_100 \n",
      "tf_mobilenetv3_large_100 model average inference time : 6.213738918304443ms\n",
      "Benchmarking Inference tv_densenet121 \n",
      "tv_densenet121 model average inference time : 13.973939418792725ms\n",
      "Benchmarking Inference regnety_006 \n",
      "regnety_006 model average inference time : 8.46891164779663ms\n",
      "Benchmarking Inference dla34 \n",
      "dla34 model average inference time : 4.637060165405273ms\n",
      "Benchmarking Inference xcit_nano_12_p8_224 \n",
      "xcit_nano_12_p8_224 model average inference time : 10.785064697265625ms\n",
      "Benchmarking Inference crossvit_9_240 \n",
      "crossvit_9_240 model average inference time : 8.890881538391113ms\n",
      "pass mobilevit_xs\n",
      "Benchmarking Inference fbnetc_100 \n",
      "fbnetc_100 model average inference time : 5.82402229309082ms\n",
      "Benchmarking Inference legacy_seresnet34 \n",
      "legacy_seresnet34 model average inference time : 7.060685157775879ms\n",
      "Benchmarking Inference gluon_resnet34_v1b \n",
      "gluon_resnet34_v1b model average inference time : 4.201843738555908ms\n",
      "Benchmarking Inference regnetx_008 \n",
      "regnetx_008 model average inference time : 6.097044944763184ms\n",
      "Benchmarking Inference mnasnet_100 \n",
      "mnasnet_100 model average inference time : 4.603738784790039ms\n",
      "Benchmarking Inference vgg19_bn \n",
      "vgg19_bn model average inference time : 12.289738655090332ms\n",
      "Benchmarking Inference convit_tiny \n",
      "convit_tiny model average inference time : 7.066531181335449ms\n",
      "Benchmarking Inference crossvit_tiny_240 \n",
      "crossvit_tiny_240 model average inference time : 9.960432052612305ms\n",
      "Benchmarking Inference spnasnet_100 \n",
      "spnasnet_100 model average inference time : 5.0150370597839355ms\n",
      "Benchmarking Inference ghostnet_100 \n",
      "ghostnet_100 model average inference time : 8.920471668243408ms\n",
      "Benchmarking Inference regnety_004 \n",
      "regnety_004 model average inference time : 10.127780437469482ms\n",
      "Benchmarking Inference skresnet18 \n",
      "skresnet18 model average inference time : 6.576483249664307ms\n",
      "Benchmarking Inference regnetx_006 \n",
      "regnetx_006 model average inference time : 5.821409225463867ms\n",
      "Benchmarking Inference pit_ti_224 \n",
      "pit_ti_224 model average inference time : 5.8481764793396ms\n",
      "Benchmarking Inference swsl_resnet18 \n",
      "swsl_resnet18 model average inference time : 2.8817200660705566ms\n",
      "Benchmarking Inference vgg16_bn \n",
      "vgg16_bn model average inference time : 10.760045051574707ms\n",
      "Benchmarking Inference semnasnet_075 \n",
      "semnasnet_075 model average inference time : 5.926918983459473ms\n",
      "Benchmarking Inference tv_resnet34 \n",
      "tv_resnet34 model average inference time : 4.236574172973633ms\n",
      "Benchmarking Inference resnet18d \n",
      "resnet18d model average inference time : 3.091740608215332ms\n",
      "Benchmarking Inference mobilenetv2_100 \n",
      "mobilenetv2_100 model average inference time : 4.582333564758301ms\n",
      "Benchmarking Inference xcit_nano_12_p16_224_dist \n",
      "xcit_nano_12_p16_224_dist model average inference time : 10.99285364151001ms\n",
      "pass vit_base_patch32_224_sam\n",
      "Benchmarking Inference ssl_resnet18 \n",
      "ssl_resnet18 model average inference time : 2.8758835792541504ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_075 \n",
      "tf_mobilenetv3_large_075 model average inference time : 5.792481899261475ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference deit_tiny_patch16_224 \n",
      "deit_tiny_patch16_224 model average inference time : 5.591640472412109ms\n",
      "Benchmarking Inference hrnet_w18_small \n",
      "hrnet_w18_small model average inference time : 9.659457206726074ms\n",
      "Benchmarking Inference vgg19 \n",
      "vgg19 model average inference time : 11.488819122314453ms\n",
      "Benchmarking Inference regnetx_004 \n",
      "regnetx_004 model average inference time : 9.148972034454346ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_minimal_100 \n",
      "tf_mobilenetv3_large_minimal_100 model average inference time : 4.442019462585449ms\n",
      "Benchmarking Inference legacy_seresnet18 \n",
      "legacy_seresnet18 model average inference time : 4.245562553405762ms\n",
      "Benchmarking Inference vgg16 \n",
      "vgg16 model average inference time : 10.01007080078125ms\n",
      "Benchmarking Inference vgg13_bn \n",
      "vgg13_bn model average inference time : 9.120914936065674ms\n",
      "Benchmarking Inference vit_tiny_r_s16_p8_224 \n",
      "vit_tiny_r_s16_p8_224 model average inference time : 5.55293083190918ms\n",
      "Benchmarking Inference lcnet_100 \n",
      "lcnet_100 model average inference time : 2.986466884613037ms\n",
      "Benchmarking Inference tinynet_c \n",
      "tinynet_c model average inference time : 6.865592002868652ms\n",
      "Benchmarking Inference gluon_resnet18_v1b \n",
      "gluon_resnet18_v1b model average inference time : 2.757880687713623ms\n",
      "Benchmarking Inference vgg11_bn \n",
      "vgg11_bn model average inference time : 7.43910551071167ms\n",
      "Benchmarking Inference xcit_nano_12_p16_224 \n",
      "xcit_nano_12_p16_224 model average inference time : 10.890634059906006ms\n",
      "Benchmarking Inference regnety_002 \n",
      "regnety_002 model average inference time : 8.584651947021484ms\n",
      "Benchmarking Inference mixer_l16_224 \n",
      "mixer_l16_224 model average inference time : 15.549030303955078ms\n",
      "Benchmarking Inference resnet18 \n",
      "resnet18 model average inference time : 2.706878185272217ms\n",
      "Benchmarking Inference vgg13 \n",
      "vgg13 model average inference time : 8.521652221679688ms\n",
      "pass mobilevit_xxs\n",
      "Benchmarking Inference vgg11 \n",
      "vgg11 model average inference time : 7.000517845153809ms\n",
      "Benchmarking Inference regnetx_002 \n",
      "regnetx_002 model average inference time : 5.940232276916504ms\n",
      "Benchmarking Inference lcnet_075 \n",
      "lcnet_075 model average inference time : 3.4865260124206543ms\n",
      "Benchmarking Inference dla60x_c \n",
      "dla60x_c model average inference time : 6.420600414276123ms\n",
      "Benchmarking Inference mobilenetv3_small_100 \n",
      "mobilenetv3_small_100 model average inference time : 4.828383922576904ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_100 \n",
      "tf_mobilenetv3_small_100 model average inference time : 5.2097296714782715ms\n",
      "Benchmarking Inference tinynet_d \n",
      "tinynet_d model average inference time : 5.136370658874512ms\n",
      "Benchmarking Inference mnasnet_small \n",
      "mnasnet_small model average inference time : 6.423203945159912ms\n",
      "Benchmarking Inference dla46x_c \n",
      "dla46x_c model average inference time : 4.918155670166016ms\n",
      "Benchmarking Inference mobilenetv2_050 \n",
      "mobilenetv2_050 model average inference time : 4.91044282913208ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_075 \n",
      "tf_mobilenetv3_small_075 model average inference time : 5.418448448181152ms\n",
      "Benchmarking Inference dla46_c \n",
      "dla46_c model average inference time : 5.151412487030029ms\n",
      "Benchmarking Inference mobilenetv3_small_075 \n",
      "mobilenetv3_small_075 model average inference time : 5.458409786224365ms\n",
      "Benchmarking Inference lcnet_050 \n",
      "lcnet_050 model average inference time : 3.001708984375ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_minimal_100 \n",
      "tf_mobilenetv3_small_minimal_100 model average inference time : 3.7972640991210938ms\n",
      "Benchmarking Inference tinynet_e \n",
      "tinynet_e model average inference time : 4.524264335632324ms\n",
      "Benchmarking Inference mobilenetv3_small_050 \n",
      "mobilenetv3_small_050 model average inference time : 4.833028316497803ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beit_large_patch16_512': {'fp32': 187.91571378707886,\n",
       "  'top1': 90.689,\n",
       "  'imsize': 512},\n",
       " 'beit_large_patch16_384': {'fp32': 79.08053874969482,\n",
       "  'top1': 90.61,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnet_l2_ns': {'fp32': 608.8841009140015,\n",
       "  'top1': 90.563,\n",
       "  'imsize': 800},\n",
       " 'tf_efficientnet_l2_ns_475': {'fp32': 255.66667079925537,\n",
       "  'top1': 90.54,\n",
       "  'imsize': 475},\n",
       " 'convnext_xlarge_384_in22ft1k': {'fp32': 56.37524366378784,\n",
       "  'top1': 90.452,\n",
       "  'imsize': 384},\n",
       " 'beit_base_patch16_384': {'fp32': 30.774567127227783,\n",
       "  'top1': 90.373,\n",
       "  'imsize': 384},\n",
       " 'convnext_large_384_in22ft1k': {'fp32': 40.837438106536865,\n",
       "  'top1': 90.258,\n",
       "  'imsize': 384},\n",
       " 'vit_large_patch16_384': {'fp32': 67.05897569656372,\n",
       "  'top1': 90.2,\n",
       "  'imsize': 384},\n",
       " 'cait_m48_448': {'fp32': 482.7632546424866, 'top1': 90.192, 'imsize': 448},\n",
       " 'beit_large_patch16_224': {'fp32': 22.212607860565186,\n",
       "  'top1': 90.151,\n",
       "  'imsize': 224},\n",
       " 'convnext_base_384_in22ft1k': {'fp32': 24.37373638153076,\n",
       "  'top1': 90.151,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnet_b7_ns': {'fp32': 92.93165683746338,\n",
       "  'top1': 90.1,\n",
       "  'imsize': 600},\n",
       " 'cait_m36_384': {'fp32': 207.56558895111084, 'top1': 90.046, 'imsize': 384},\n",
       " 'dm_nfnet_f6': {'fp32': 672.6956820487976, 'top1': 90.044, 'imsize': 576},\n",
       " 'swin_large_patch4_window12_384': {'fp32': 55.37781476974487,\n",
       "  'top1': 90.027,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnetv2_l_in21ft1k': {'fp32': 71.37280941009521,\n",
       "  'top1': 90.008,\n",
       "  'imsize': 480},\n",
       " 'swin_base_patch4_window12_384': {'fp32': 34.73442077636719,\n",
       "  'top1': 89.995,\n",
       "  'imsize': 384},\n",
       " 'vit_base_patch16_384': {'fp32': 26.0374116897583,\n",
       "  'top1': 89.984,\n",
       "  'imsize': 384},\n",
       " 'convnext_xlarge_in22ft1k': {'fp32': 22.533299922943115,\n",
       "  'top1': 89.933,\n",
       "  'imsize': 224},\n",
       " 'xcit_large_24_p8_384_dist': {'fp32': 171.54454708099365,\n",
       "  'top1': 89.886,\n",
       "  'imsize': 384},\n",
       " 'cait_s36_384': {'fp32': 100.09888172149658, 'top1': 89.846, 'imsize': 384},\n",
       " 'xcit_medium_24_p8_384_dist': {'fp32': 103.07622194290161,\n",
       "  'top1': 89.814,\n",
       "  'imsize': 384},\n",
       " 'convnext_large_in22ft1k': {'fp32': 15.546832084655762,\n",
       "  'top1': 89.811,\n",
       "  'imsize': 224},\n",
       " 'vit_large_r50_s32_384': {'fp32': 30.807855129241943,\n",
       "  'top1': 89.796,\n",
       "  'imsize': 384},\n",
       " 'swin_large_patch4_window7_224': {'fp32': 17.675859928131104,\n",
       "  'top1': 89.792,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnetv2_m_in21ft1k': {'fp32': 36.42094612121582,\n",
       "  'top1': 89.779,\n",
       "  'imsize': 480},\n",
       " 'tf_efficientnet_b6_ns': {'fp32': 53.91404390335083,\n",
       "  'top1': 89.777,\n",
       "  'imsize': 528},\n",
       " 'xcit_small_24_p8_384_dist': {'fp32': 75.50479650497437,\n",
       "  'top1': 89.739,\n",
       "  'imsize': 384},\n",
       " 'xcit_large_24_p16_384_dist': {'fp32': 50.74313163757324,\n",
       "  'top1': 89.662,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnet_b5_ns': {'fp32': 32.290048599243164,\n",
       "  'top1': 89.653,\n",
       "  'imsize': 456},\n",
       " 'convnext_base_in22ft1k': {'fp32': 10.318505764007568,\n",
       "  'top1': 89.628,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnetv2_xl_in21ft1k': {'fp32': 112.3640489578247,\n",
       "  'top1': 89.587,\n",
       "  'imsize': 512},\n",
       " 'tf_efficientnet_b8_ap': {'fp32': 137.68148183822632,\n",
       "  'top1': 89.581,\n",
       "  'imsize': 672},\n",
       " 'dm_nfnet_f4': {'fp32': 672.0425343513489, 'top1': 89.557, 'imsize': 512},\n",
       " 'xcit_large_24_p8_224_dist': {'fp32': 69.41962718963623,\n",
       "  'top1': 89.517,\n",
       "  'imsize': 224},\n",
       " 'xcit_small_12_p8_384_dist': {'fp32': 41.09152555465698,\n",
       "  'top1': 89.515,\n",
       "  'imsize': 384},\n",
       " 'cait_s24_384': {'fp32': 67.35388517379761, 'top1': 89.502, 'imsize': 384},\n",
       " 'dm_nfnet_f3': {'fp32': 292.4152183532715, 'top1': 89.485, 'imsize': 416},\n",
       " 'xcit_medium_24_p16_384_dist': {'fp32': 31.045682430267334,\n",
       "  'top1': 89.474,\n",
       "  'imsize': 384},\n",
       " 'dm_nfnet_f5': {'fp32': 794.8230934143066, 'top1': 89.463, 'imsize': 544},\n",
       " 'deit_base_distilled_patch16_384': {'fp32': 26.244633197784424,\n",
       "  'top1': 89.429,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnet_b7_ap': {'fp32': 93.15792560577393,\n",
       "  'top1': 89.429,\n",
       "  'imsize': 600},\n",
       " 'vit_base_patch8_224': {'fp32': 38.318350315093994,\n",
       "  'top1': 89.427,\n",
       "  'imsize': 224},\n",
       " 'beit_base_patch16_224': {'fp32': 7.689826488494873,\n",
       "  'top1': 89.41,\n",
       "  'imsize': 224},\n",
       " 'regnetz_e8': {'fp32': 31.81417465209961, 'top1': 89.38, 'imsize': 320},\n",
       " 'tf_efficientnetv2_l': {'fp32': 71.03377103805542,\n",
       "  'top1': 89.367,\n",
       "  'imsize': 480},\n",
       " 'tf_efficientnet_b8': {'fp32': 137.69964694976807,\n",
       "  'top1': 89.355,\n",
       "  'imsize': 672},\n",
       " 'tf_efficientnet_b6_ap': {'fp32': 53.95560264587402,\n",
       "  'top1': 89.342,\n",
       "  'imsize': 528},\n",
       " 'vit_large_patch16_224': {'fp32': 20.655953884124756,\n",
       "  'top1': 89.312,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b4_ns': {'fp32': 17.379508018493652,\n",
       "  'top1': 89.303,\n",
       "  'imsize': 380},\n",
       " 'xcit_small_24_p16_384_dist': {'fp32': 21.77457332611084,\n",
       "  'top1': 89.299,\n",
       "  'imsize': 384},\n",
       " 'xcit_medium_24_p8_224_dist': {'fp32': 41.69515609741211,\n",
       "  'top1': 89.293,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnetv2_m': {'fp32': 36.484036445617676,\n",
       "  'top1': 89.284,\n",
       "  'imsize': 480},\n",
       " 'xcit_small_24_p8_224_dist': {'fp32': 29.96450424194336,\n",
       "  'top1': 89.203,\n",
       "  'imsize': 224},\n",
       " 'xcit_small_12_p16_384_dist': {'fp32': 12.865972518920898,\n",
       "  'top1': 89.199,\n",
       "  'imsize': 384},\n",
       " 'swin_base_patch4_window7_224': {'fp32': 13.439774513244629,\n",
       "  'top1': 89.145,\n",
       "  'imsize': 224},\n",
       " 'cait_xs24_384': {'fp32': 48.526389598846436, 'top1': 89.141, 'imsize': 384},\n",
       " 'eca_nfnet_l2': {'fp32': 72.81731128692627, 'top1': 89.141, 'imsize': 384},\n",
       " 'ig_resnext101_32x48d': {'fp32': 210.53939580917358,\n",
       "  'top1': 89.118,\n",
       "  'imsize': 224},\n",
       " 'ig_resnext101_32x32d': {'fp32': 133.38236331939697,\n",
       "  'top1': 89.109,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b7': {'fp32': 92.8994870185852,\n",
       "  'top1': 89.083,\n",
       "  'imsize': 600},\n",
       " 'ecaresnet269d': {'fp32': 50.67777633666992, 'top1': 89.066, 'imsize': 352},\n",
       " 'xcit_large_24_p16_224_dist': {'fp32': 20.32648801803589,\n",
       "  'top1': 89.041,\n",
       "  'imsize': 224},\n",
       " 'resmlp_big_24_224_in22ft1k': {'fp32': 34.29241418838501,\n",
       "  'top1': 89.011,\n",
       "  'imsize': 224},\n",
       " 'dm_nfnet_f2': {'fp32': 185.6989073753357, 'top1': 89.007, 'imsize': 352},\n",
       " 'xcit_small_12_p8_224_dist': {'fp32': 16.310091018676758,\n",
       "  'top1': 89.002,\n",
       "  'imsize': 224},\n",
       " 'efficientnetv2_rw_m': {'fp32': 31.904401779174805,\n",
       "  'top1': 88.99,\n",
       "  'imsize': 416},\n",
       " 'tf_efficientnet_b5_ap': {'fp32': 32.3570990562439,\n",
       "  'top1': 88.942,\n",
       "  'imsize': 456},\n",
       " 'dm_nfnet_f1': {'fp32': 110.08667707443237, 'top1': 88.925, 'imsize': 320},\n",
       " 'tf_efficientnetv2_s_in21ft1k': {'fp32': 19.096014499664307,\n",
       "  'top1': 88.902,\n",
       "  'imsize': 384},\n",
       " 'vit_base_patch16_224': {'fp32': 7.161188125610352,\n",
       "  'top1': 88.864,\n",
       "  'imsize': 224},\n",
       " 'regnetz_d8': {'fp32': 19.865193367004395, 'top1': 88.857, 'imsize': 320},\n",
       " 'resnetrs420': {'fp32': 122.50638008117676, 'top1': 88.842, 'imsize': 416},\n",
       " 'regnetz_d8_evos': {'fp32': 29.344148635864258, 'top1': 88.84, 'imsize': 320},\n",
       " 'resnetrs270': {'fp32': 57.58063554763794, 'top1': 88.834, 'imsize': 352},\n",
       " 'ig_resnext101_32x16d': {'fp32': 35.88122367858887,\n",
       "  'top1': 88.825,\n",
       "  'imsize': 224},\n",
       " 'vit_small_r26_s32_384': {'fp32': 12.752251625061035,\n",
       "  'top1': 88.819,\n",
       "  'imsize': 384},\n",
       " 'vit_base_r50_s16_384': {'fp32': 39.00730848312378,\n",
       "  'top1': 88.806,\n",
       "  'imsize': 384},\n",
       " 'xcit_medium_24_p16_224_dist': {'fp32': 19.440722465515137,\n",
       "  'top1': 88.799,\n",
       "  'imsize': 224},\n",
       " 'seresnet152d': {'fp32': 31.543376445770264, 'top1': 88.793, 'imsize': 320},\n",
       " 'swsl_resnext101_32x8d': {'fp32': 19.418256282806396,\n",
       "  'top1': 88.778,\n",
       "  'imsize': 224},\n",
       " 'xcit_tiny_24_p8_384_dist': {'fp32': 38.722381591796875,\n",
       "  'top1': 88.776,\n",
       "  'imsize': 384},\n",
       " 'resnetrs200': {'fp32': 38.456058502197266, 'top1': 88.763, 'imsize': 320},\n",
       " 'tf_efficientnet_b6': {'fp32': 53.8628888130188,\n",
       "  'top1': 88.761,\n",
       "  'imsize': 528},\n",
       " 'resnetrs350': {'fp32': 80.18627882003784, 'top1': 88.757, 'imsize': 384},\n",
       " 'vit_base_patch16_224_miil': {'fp32': 6.964316368103027,\n",
       "  'top1': 88.742,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_152x2_bitm': {'fp32': 127.63757705688477,\n",
       "  'top1': 88.729,\n",
       "  'imsize': 448},\n",
       " 'regnety_160': {'fp32': 71.84243202209473, 'top1': 88.699, 'imsize': 288},\n",
       " 'pit_b_distilled_224': {'fp32': 8.21521520614624,\n",
       "  'top1': 88.674,\n",
       "  'imsize': 224},\n",
       " 'vit_small_patch16_384': {'fp32': 11.51090383529663,\n",
       "  'top1': 88.656,\n",
       "  'imsize': 384},\n",
       " 'regnetz_d32': {'fp32': 31.382534503936768, 'top1': 88.652, 'imsize': 320},\n",
       " 'regnety_080': {'fp32': 26.292824745178223, 'top1': 88.635, 'imsize': 288},\n",
       " 'eca_nfnet_l1': {'fp32': 36.145222187042236, 'top1': 88.624, 'imsize': 320},\n",
       " 'convnext_large': {'fp32': 15.460774898529053, 'top1': 88.573, 'imsize': 224},\n",
       " 'resnetv2_152x4_bitm': {'fp32': 443.8380432128906,\n",
       "  'top1': 88.554,\n",
       "  'imsize': 480},\n",
       " 'resnet200d': {'fp32': 30.661048889160156, 'top1': 88.543, 'imsize': 320},\n",
       " 'xcit_small_24_p16_224_dist': {'fp32': 18.936047554016113,\n",
       "  'top1': 88.541,\n",
       "  'imsize': 224},\n",
       " 'resnest269e': {'fp32': 191.641206741333, 'top1': 88.522, 'imsize': 416},\n",
       " 'seresnext101_32x8d': {'fp32': 29.890413284301758,\n",
       "  'top1': 88.505,\n",
       "  'imsize': 288},\n",
       " 'efficientnetv2_rw_s': {'fp32': 19.278180599212646,\n",
       "  'top1': 88.473,\n",
       "  'imsize': 384},\n",
       " 'crossvit_18_dagger_408': {'fp32': 28.73060703277588,\n",
       "  'top1': 88.471,\n",
       "  'imsize': 408},\n",
       " 'resnetv2_101x3_bitm': {'fp32': 165.76751947402954,\n",
       "  'top1': 88.464,\n",
       "  'imsize': 448},\n",
       " 'cait_s24_224': {'fp32': 14.428799152374268, 'top1': 88.451, 'imsize': 224},\n",
       " 'resnetv2_50x3_bitm': {'fp32': 96.11170530319214,\n",
       "  'top1': 88.447,\n",
       "  'imsize': 448},\n",
       " 'resmlp_big_24_distilled_224': {'fp32': 34.34579133987427,\n",
       "  'top1': 88.443,\n",
       "  'imsize': 224},\n",
       " 'resnest200e': {'fp32': 88.43701839447021, 'top1': 88.432, 'imsize': 320},\n",
       " 'tf_efficientnet_b3_ns': {'fp32': 13.30073356628418,\n",
       "  'top1': 88.426,\n",
       "  'imsize': 300},\n",
       " 'vit_large_r50_s32_224': {'fp32': 16.60557508468628,\n",
       "  'top1': 88.417,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnetv2_s': {'fp32': 18.862860202789307,\n",
       "  'top1': 88.396,\n",
       "  'imsize': 384},\n",
       " 'efficientnet_b4': {'fp32': 16.42165184020996, 'top1': 88.368, 'imsize': 384},\n",
       " 'resnet152d': {'fp32': 23.603663444519043, 'top1': 88.355, 'imsize': 320},\n",
       " 'tf_efficientnet_b4_ap': {'fp32': 16.7331862449646,\n",
       "  'top1': 88.349,\n",
       "  'imsize': 380},\n",
       " 'convnext_base': {'fp32': 10.320703983306885, 'top1': 88.345, 'imsize': 224},\n",
       " 'tf_efficientnet_b5': {'fp32': 32.24097490310669,\n",
       "  'top1': 88.321,\n",
       "  'imsize': 456},\n",
       " 'regnety_064': {'fp32': 31.58870220184326, 'top1': 88.319, 'imsize': 288},\n",
       " 'crossvit_15_dagger_408': {'fp32': 21.499099731445312,\n",
       "  'top1': 88.311,\n",
       "  'imsize': 408},\n",
       " 'resnetrs152': {'fp32': 29.965431690216064, 'top1': 88.253, 'imsize': 320},\n",
       " 'xcit_small_12_p16_224_dist': {'fp32': 11.068792343139648,\n",
       "  'top1': 88.251,\n",
       "  'imsize': 224},\n",
       " 'deit_base_distilled_patch16_224': {'fp32': 7.1504807472229,\n",
       "  'top1': 88.214,\n",
       "  'imsize': 224},\n",
       " 'xcit_large_24_p8_224': {'fp32': 68.53860855102539,\n",
       "  'top1': 88.159,\n",
       "  'imsize': 224},\n",
       " 'xcit_tiny_24_p16_384_dist': {'fp32': 20.207009315490723,\n",
       "  'top1': 88.159,\n",
       "  'imsize': 384},\n",
       " 'resnetv2_152x2_bit_teacher_384': {'fp32': 94.05856132507324,\n",
       "  'top1': 88.155,\n",
       "  'imsize': 384},\n",
       " 'ig_resnext101_32x8d': {'fp32': 19.3076491355896,\n",
       "  'top1': 88.155,\n",
       "  'imsize': 224},\n",
       " 'cait_xxs36_384': {'fp32': 47.40920305252075, 'top1': 88.142, 'imsize': 384},\n",
       " 'dm_nfnet_f0': {'fp32': 54.40583944320679, 'top1': 88.125, 'imsize': 256},\n",
       " 'xcit_tiny_12_p8_384_dist': {'fp32': 21.14933729171753,\n",
       "  'top1': 88.106,\n",
       "  'imsize': 384},\n",
       " 'swsl_resnext101_32x4d': {'fp32': 12.841134071350098,\n",
       "  'top1': 88.095,\n",
       "  'imsize': 224},\n",
       " 'xception65': {'fp32': 15.948817729949951, 'top1': 88.073, 'imsize': 299},\n",
       " 'convnext_small': {'fp32': 8.712043762207031, 'top1': 88.052, 'imsize': 224},\n",
       " 'xcit_tiny_24_p8_224_dist': {'fp32': 18.82086753845215,\n",
       "  'top1': 88.044,\n",
       "  'imsize': 224},\n",
       " 'eca_nfnet_l0': {'fp32': 16.580514907836914, 'top1': 87.975, 'imsize': 288},\n",
       " 'nfnet_l0': {'fp32': 17.78585195541382, 'top1': 87.971, 'imsize': 288},\n",
       " 'xcit_small_24_p8_224': {'fp32': 29.920661449432373,\n",
       "  'top1': 87.967,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b4': {'fp32': 16.942265033721924,\n",
       "  'top1': 87.965,\n",
       "  'imsize': 380},\n",
       " 'resnet101d': {'fp32': 16.97296380996704, 'top1': 87.937, 'imsize': 320},\n",
       " 'regnety_032': {'fp32': 13.885552883148193, 'top1': 87.933, 'imsize': 288},\n",
       " 'regnety_040': {'fp32': 21.932520866394043, 'top1': 87.915, 'imsize': 288},\n",
       " 'vit_base_patch32_384': {'fp32': 7.118480205535889,\n",
       "  'top1': 87.909,\n",
       "  'imsize': 384},\n",
       " 'twins_svt_large': {'fp32': 14.513535499572754,\n",
       "  'top1': 87.901,\n",
       "  'imsize': 224},\n",
       " 'twins_pcpvt_large': {'fp32': 24.546501636505127,\n",
       "  'top1': 87.877,\n",
       "  'imsize': 224},\n",
       " 'regnetz_c16': {'fp32': 15.338287353515625, 'top1': 87.858, 'imsize': 320},\n",
       " 'deit_base_patch16_384': {'fp32': 25.87766408920288,\n",
       "  'top1': 87.841,\n",
       "  'imsize': 384},\n",
       " 'xcit_small_12_p8_224': {'fp32': 16.080288887023926,\n",
       "  'top1': 87.826,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_50x1_bit_distilled': {'fp32': 7.775211334228516,\n",
       "  'top1': 87.792,\n",
       "  'imsize': 224},\n",
       " 'twins_pcpvt_base': {'fp32': 16.96429967880249,\n",
       "  'top1': 87.734,\n",
       "  'imsize': 224},\n",
       " 'gc_efficientnetv2_rw_t': {'fp32': 21.715924739837646,\n",
       "  'top1': 87.717,\n",
       "  'imsize': 288},\n",
       " 'resnetv2_101x1_bitm': {'fp32': 36.600871086120605,\n",
       "  'top1': 87.683,\n",
       "  'imsize': 448},\n",
       " 'swin_small_patch4_window7_224': {'fp32': 13.078370094299316,\n",
       "  'top1': 87.668,\n",
       "  'imsize': 224},\n",
       " 'efficientnetv2_rw_t': {'fp32': 17.014365196228027,\n",
       "  'top1': 87.644,\n",
       "  'imsize': 288},\n",
       " 'twins_svt_base': {'fp32': 13.793895244598389, 'top1': 87.642, 'imsize': 224},\n",
       " 'pnasnet5large': {'fp32': 40.550715923309326, 'top1': 87.64, 'imsize': 331},\n",
       " 'jx_nest_base': {'fp32': 13.861017227172852, 'top1': 87.608, 'imsize': 224},\n",
       " 'swsl_resnext101_32x16d': {'fp32': 35.40154218673706,\n",
       "  'top1': 87.608,\n",
       "  'imsize': 224},\n",
       " 'xcit_medium_24_p8_224': {'fp32': 41.44044876098633,\n",
       "  'top1': 87.604,\n",
       "  'imsize': 224},\n",
       " 'swsl_resnext50_32x4d': {'fp32': 6.892509460449219,\n",
       "  'top1': 87.595,\n",
       "  'imsize': 224},\n",
       " 'levit_384': {'fp32': 8.430521488189697, 'top1': 87.557, 'imsize': 224},\n",
       " 'tf_efficientnet_b2_ns': {'fp32': 10.981707572937012,\n",
       "  'top1': 87.555,\n",
       "  'imsize': 260},\n",
       " 'ecaresnet50t': {'fp32': 11.607410907745361, 'top1': 87.542, 'imsize': 320},\n",
       " 'jx_nest_small': {'fp32': 10.505123138427734, 'top1': 87.493, 'imsize': 224},\n",
       " 'resnetv2_152x2_bit_teacher': {'fp32': 46.51663780212402,\n",
       "  'top1': 87.493,\n",
       "  'imsize': 224},\n",
       " 'resnet152': {'fp32': 15.047299861907959, 'top1': 87.454, 'imsize': 224},\n",
       " 'fbnetv3_g': {'fp32': 14.769823551177979, 'top1': 87.452, 'imsize': 288},\n",
       " 'resnext101_64x4d': {'fp32': 26.32493257522583,\n",
       "  'top1': 87.439,\n",
       "  'imsize': 288},\n",
       " 'resnet61q': {'fp32': 14.141292572021484, 'top1': 87.439, 'imsize': 288},\n",
       " 'efficientnet_b3': {'fp32': 13.08703899383545, 'top1': 87.433, 'imsize': 320},\n",
       " 'cait_xxs24_384': {'fp32': 32.03303098678589, 'top1': 87.414, 'imsize': 384},\n",
       " 'resnet51q': {'fp32': 13.129756450653076, 'top1': 87.401, 'imsize': 288},\n",
       " 'coat_lite_small': {'fp32': 13.34057092666626, 'top1': 87.38, 'imsize': 224},\n",
       " 'xcit_tiny_24_p8_224': {'fp32': 18.665645122528076,\n",
       "  'top1': 87.377,\n",
       "  'imsize': 224},\n",
       " 'nasnetalarge': {'fp32': 46.04686260223389, 'top1': 87.35, 'imsize': 331},\n",
       " 'crossvit_18_dagger_240': {'fp32': 12.792778015136719,\n",
       "  'top1': 87.346,\n",
       "  'imsize': 240},\n",
       " 'resnetv2_101': {'fp32': 10.557188987731934, 'top1': 87.318, 'imsize': 224},\n",
       " 'crossvit_18_240': {'fp32': 11.873033046722412,\n",
       "  'top1': 87.313,\n",
       "  'imsize': 240},\n",
       " 'convnext_tiny': {'fp32': 5.080981254577637, 'top1': 87.313, 'imsize': 224},\n",
       " 'ecaresnet101d': {'fp32': 13.33733081817627, 'top1': 87.29, 'imsize': 224},\n",
       " 'resnest101e': {'fp32': 30.30930519104004, 'top1': 87.286, 'imsize': 256},\n",
       " 'pit_s_distilled_224': {'fp32': 5.930109024047852,\n",
       "  'top1': 87.273,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_50d_gn': {'fp32': 9.855432510375977, 'top1': 87.262, 'imsize': 288},\n",
       " 'resnetrs101': {'fp32': 20.154764652252197, 'top1': 87.249, 'imsize': 288},\n",
       " 'mixer_b16_224_miil': {'fp32': 5.06256103515625,\n",
       "  'top1': 87.228,\n",
       "  'imsize': 224},\n",
       " 'xcit_tiny_12_p8_224_dist': {'fp32': 10.514352321624756,\n",
       "  'top1': 87.222,\n",
       "  'imsize': 224},\n",
       " 'xcit_tiny_12_p16_384_dist': {'fp32': 12.020678520202637,\n",
       "  'top1': 87.205,\n",
       "  'imsize': 384},\n",
       " 'convit_base': {'fp32': 10.279090404510498, 'top1': 87.2, 'imsize': 224},\n",
       " 'resnetv2_50d_evos': {'fp32': 14.797675609588623,\n",
       "  'top1': 87.196,\n",
       "  'imsize': 288},\n",
       " 'tf_efficientnet_b3_ap': {'fp32': 13.199121952056885,\n",
       "  'top1': 87.192,\n",
       "  'imsize': 300},\n",
       " 'visformer_small': {'fp32': 12.263660430908203,\n",
       "  'top1': 87.185,\n",
       "  'imsize': 224},\n",
       " 'crossvit_15_dagger_240': {'fp32': 11.4286470413208,\n",
       "  'top1': 87.172,\n",
       "  'imsize': 240},\n",
       " 'xcit_small_24_p16_224': {'fp32': 18.83232355117798,\n",
       "  'top1': 87.132,\n",
       "  'imsize': 224},\n",
       " 'resnet101': {'fp32': 9.94724988937378, 'top1': 87.083, 'imsize': 224},\n",
       " 'crossvit_15_240': {'fp32': 10.9995698928833, 'top1': 87.053, 'imsize': 240},\n",
       " 'convit_small': {'fp32': 7.385740280151367, 'top1': 87.049, 'imsize': 224},\n",
       " 'tf_efficientnetv2_b3': {'fp32': 14.91908073425293,\n",
       "  'top1': 87.027,\n",
       "  'imsize': 300},\n",
       " 'regnetz_b16': {'fp32': 14.061450958251953, 'top1': 87.014, 'imsize': 288},\n",
       " 'xcit_small_12_p16_224': {'fp32': 10.804126262664795,\n",
       "  'top1': 87.012,\n",
       "  'imsize': 224},\n",
       " 'jx_nest_tiny': {'fp32': 7.265286445617676, 'top1': 87.008, 'imsize': 224},\n",
       " 'deit_small_distilled_patch16_224': {'fp32': 5.485577583312988,\n",
       "  'top1': 87.002,\n",
       "  'imsize': 224},\n",
       " 'resmlp_36_distilled_224': {'fp32': 8.495986461639404,\n",
       "  'top1': 86.989,\n",
       "  'imsize': 224},\n",
       " 'xcit_large_24_p16_224': {'fp32': 20.18990993499756,\n",
       "  'top1': 86.957,\n",
       "  'imsize': 224},\n",
       " 'xcit_medium_24_p16_224': {'fp32': 19.263627529144287,\n",
       "  'top1': 86.938,\n",
       "  'imsize': 224},\n",
       " 'convnext_tiny_hnf': {'fp32': 5.24477481842041,\n",
       "  'top1': 86.921,\n",
       "  'imsize': 224},\n",
       " 'tnt_s_patch16_224': {'fp32': 11.555273532867432,\n",
       "  'top1': 86.906,\n",
       "  'imsize': 224},\n",
       " 'ssl_resnext101_32x16d': {'fp32': 35.39109468460083,\n",
       "  'top1': 86.867,\n",
       "  'imsize': 224},\n",
       " 'vit_small_patch16_224': {'fp32': 5.44100284576416,\n",
       "  'top1': 86.865,\n",
       "  'imsize': 224},\n",
       " 'vit_small_r26_s32_224': {'fp32': 9.454784393310547,\n",
       "  'top1': 86.854,\n",
       "  'imsize': 224},\n",
       " 'rexnet_200': {'fp32': 8.69786024093628, 'top1': 86.844, 'imsize': 224},\n",
       " 'tf_efficientnet_b3': {'fp32': 13.566012382507324,\n",
       "  'top1': 86.835,\n",
       "  'imsize': 300},\n",
       " 'deit_base_patch16_224': {'fp32': 7.090437412261963,\n",
       "  'top1': 86.829,\n",
       "  'imsize': 224},\n",
       " 'swsl_resnet50': {'fp32': 5.860764980316162, 'top1': 86.825, 'imsize': 224},\n",
       " 'tf_efficientnet_lite4': {'fp32': 12.407727241516113,\n",
       "  'top1': 86.803,\n",
       "  'imsize': 380},\n",
       " 'ssl_resnext101_32x8d': {'fp32': 19.145667552947998,\n",
       "  'top1': 86.801,\n",
       "  'imsize': 224},\n",
       " 'coat_mini': {'fp32': 22.62336254119873, 'top1': 86.79, 'imsize': 224},\n",
       " 'twins_svt_small': {'fp32': 10.445923805236816,\n",
       "  'top1': 86.758,\n",
       "  'imsize': 224},\n",
       " 'crossvit_base_240': {'fp32': 10.446040630340576,\n",
       "  'top1': 86.735,\n",
       "  'imsize': 240},\n",
       " 'levit_256': {'fp32': 8.004951477050781, 'top1': 86.728, 'imsize': 224},\n",
       " 'seresnext50_32x4d': {'fp32': 10.552456378936768,\n",
       "  'top1': 86.696,\n",
       "  'imsize': 224},\n",
       " 'crossvit_small_240': {'fp32': 9.910666942596436,\n",
       "  'top1': 86.692,\n",
       "  'imsize': 240},\n",
       " 'halo2botnet50ts_256': {'fp32': 10.324373245239258,\n",
       "  'top1': 86.688,\n",
       "  'imsize': 256},\n",
       " 'pit_b_224': {'fp32': 8.096179962158203, 'top1': 86.688, 'imsize': 224},\n",
       " 'tf_efficientnet_b1_ns': {'fp32': 10.720136165618896,\n",
       "  'top1': 86.666,\n",
       "  'imsize': 240},\n",
       " 'swin_tiny_patch4_window7_224': {'fp32': 7.22991943359375,\n",
       "  'top1': 86.662,\n",
       "  'imsize': 224},\n",
       " 'wide_resnet50_2': {'fp32': 11.204559803009033,\n",
       "  'top1': 86.645,\n",
       "  'imsize': 224},\n",
       " 'gernet_l': {'fp32': 13.144361972808838, 'top1': 86.641, 'imsize': 256},\n",
       " 'efficientnet_el': {'fp32': 10.913615226745605,\n",
       "  'top1': 86.632,\n",
       "  'imsize': 300},\n",
       " 'twins_pcpvt_small': {'fp32': 10.25561809539795,\n",
       "  'top1': 86.624,\n",
       "  'imsize': 224},\n",
       " 'resmlp_24_distilled_224': {'fp32': 6.102869510650635,\n",
       "  'top1': 86.62,\n",
       "  'imsize': 224},\n",
       " 'nf_resnet50': {'fp32': 10.765523910522461, 'top1': 86.605, 'imsize': 288},\n",
       " 'resnest50d_4s2x40d': {'fp32': 22.783632278442383,\n",
       "  'top1': 86.588,\n",
       "  'imsize': 224},\n",
       " 'efficientnet_b3_pruned': {'fp32': 12.694363594055176,\n",
       "  'top1': 86.581,\n",
       "  'imsize': 300},\n",
       " 'sebotnet33ts_256': {'fp32': 7.925839424133301,\n",
       "  'top1': 86.566,\n",
       "  'imsize': 256},\n",
       " 'sehalonet33ts': {'fp32': 8.051953315734863, 'top1': 86.564, 'imsize': 256},\n",
       " 'repvgg_b3': {'fp32': 19.02237892150879, 'top1': 86.562, 'imsize': 224},\n",
       " 'xcit_tiny_24_p16_224_dist': {'fp32': 18.665771484375,\n",
       "  'top1': 86.534,\n",
       "  'imsize': 224},\n",
       " 'halonet50ts': {'fp32': 9.902174472808838, 'top1': 86.5, 'imsize': 256},\n",
       " 'ssl_resnext101_32x4d': {'fp32': 12.611494064331055,\n",
       "  'top1': 86.479,\n",
       "  'imsize': 224},\n",
       " 'gcresnet50t': {'fp32': 11.630778312683105, 'top1': 86.472, 'imsize': 256},\n",
       " 'ecaresnet50d': {'fp32': 7.228231430053711, 'top1': 86.47, 'imsize': 224},\n",
       " 'gluon_resnet152_v1s': {'fp32': 15.292716026306152,\n",
       "  'top1': 86.47,\n",
       "  'imsize': 224},\n",
       " 'haloregnetz_b': {'fp32': 14.108097553253174, 'top1': 86.464, 'imsize': 224},\n",
       " 'resnest50d_1s4x24d': {'fp32': 13.995170593261719,\n",
       "  'top1': 86.445,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_50x1_bitm': {'fp32': 20.829427242279053,\n",
       "  'top1': 86.442,\n",
       "  'imsize': 448},\n",
       " 'repvgg_b3g4': {'fp32': 21.494791507720947, 'top1': 86.361, 'imsize': 224},\n",
       " 'lamhalobotnet50ts_256': {'fp32': 9.435303211212158,\n",
       "  'top1': 86.355,\n",
       "  'imsize': 256},\n",
       " 'legacy_senet154': {'fp32': 34.86727952957153, 'top1': 86.34, 'imsize': 224},\n",
       " 'cait_xxs36_224': {'fp32': 20.563640594482422, 'top1': 86.338, 'imsize': 224},\n",
       " 'resnext50_32x4d': {'fp32': 6.777701377868652, 'top1': 86.334, 'imsize': 224},\n",
       " 'gernet_m': {'fp32': 5.1569294929504395, 'top1': 86.331, 'imsize': 224},\n",
       " 'pit_s_224': {'fp32': 5.857207775115967, 'top1': 86.325, 'imsize': 224},\n",
       " 'efficientnet_b2': {'fp32': 11.215276718139648,\n",
       "  'top1': 86.308,\n",
       "  'imsize': 288},\n",
       " 'vit_small_patch32_384': {'fp32': 7.231400012969971,\n",
       "  'top1': 86.308,\n",
       "  'imsize': 384},\n",
       " 'gluon_senet154': {'fp32': 34.84896659851074, 'top1': 86.272, 'imsize': 224},\n",
       " 'resnest50d': {'fp32': 13.842880725860596, 'top1': 86.24, 'imsize': 224},\n",
       " 'ecaresnet101d_pruned': {'fp32': 12.142655849456787,\n",
       "  'top1': 86.21,\n",
       "  'imsize': 224},\n",
       " 'efficientnet_el_pruned': {'fp32': 10.909664630889893,\n",
       "  'top1': 86.192,\n",
       "  'imsize': 300},\n",
       " 'cspdarknet53': {'fp32': 12.367355823516846, 'top1': 86.186, 'imsize': 256},\n",
       " 'inception_v4': {'fp32': 19.805145263671875, 'top1': 86.171, 'imsize': 299},\n",
       " 'rexnet_150': {'fp32': 8.9851713180542, 'top1': 86.156, 'imsize': 224},\n",
       " 'inception_resnet_v2': {'fp32': 28.955624103546143,\n",
       "  'top1': 86.135,\n",
       "  'imsize': 299},\n",
       " 'xcit_tiny_12_p8_224': {'fp32': 10.839853286743164,\n",
       "  'top1': 86.105,\n",
       "  'imsize': 224},\n",
       " 'ssl_resnext50_32x4d': {'fp32': 6.850457191467285,\n",
       "  'top1': 86.088,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_el': {'fp32': 11.13243818283081,\n",
       "  'top1': 86.082,\n",
       "  'imsize': 300},\n",
       " 'gluon_resnet101_v1s': {'fp32': 10.38534164428711,\n",
       "  'top1': 86.056,\n",
       "  'imsize': 224},\n",
       " 'ecaresnetlight': {'fp32': 7.019798755645752, 'top1': 86.047, 'imsize': 224},\n",
       " 'lambda_resnet50ts': {'fp32': 9.587419033050537,\n",
       "  'top1': 86.039,\n",
       "  'imsize': 256},\n",
       " 'gluon_seresnext101_32x4d': {'fp32': 20.752921104431152,\n",
       "  'top1': 86.032,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_50': {'fp32': 5.9873270988464355, 'top1': 86.022, 'imsize': 224},\n",
       " 'gcresnext50ts': {'fp32': 13.992786407470703, 'top1': 86.009, 'imsize': 256},\n",
       " 'seresnet33ts': {'fp32': 8.22908639907837, 'top1': 86.007, 'imsize': 256},\n",
       " 'resnet50d': {'fp32': 6.174285411834717, 'top1': 85.998, 'imsize': 224},\n",
       " 'ecaresnet26t': {'fp32': 7.764883041381836, 'top1': 85.979, 'imsize': 320},\n",
       " 'tf_efficientnet_b2_ap': {'fp32': 11.208689212799072,\n",
       "  'top1': 85.975,\n",
       "  'imsize': 260},\n",
       " 'gluon_seresnext101_64x4d': {'fp32': 23.712027072906494,\n",
       "  'top1': 85.958,\n",
       "  'imsize': 224},\n",
       " 'vit_base_patch32_224': {'fp32': 5.620212554931641,\n",
       "  'top1': 85.958,\n",
       "  'imsize': 224},\n",
       " 'fbnetv3_d': {'fp32': 11.430552005767822, 'top1': 85.926, 'imsize': 256},\n",
       " 'gluon_resnet152_v1d': {'fp32': 15.431807041168213,\n",
       "  'top1': 85.913,\n",
       "  'imsize': 224},\n",
       " 'vit_large_patch32_384': {'fp32': 16.533348560333252,\n",
       "  'top1': 85.911,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnetv2_b2': {'fp32': 11.760330200195312,\n",
       "  'top1': 85.9,\n",
       "  'imsize': 260},\n",
       " 'tf_efficientnet_b2': {'fp32': 10.918102264404297,\n",
       "  'top1': 85.898,\n",
       "  'imsize': 260},\n",
       " 'resnet50_gn': {'fp32': 6.137242317199707, 'top1': 85.885, 'imsize': 224},\n",
       " 'seresnet50': {'fp32': 9.397022724151611, 'top1': 85.853, 'imsize': 224},\n",
       " 'gluon_resnet101_v1d': {'fp32': 10.443148612976074,\n",
       "  'top1': 85.849,\n",
       "  'imsize': 224},\n",
       " 'repvgg_b2g4': {'fp32': 19.88224744796753, 'top1': 85.847, 'imsize': 224},\n",
       " 'gcresnet33ts': {'fp32': 8.920974731445312, 'top1': 85.806, 'imsize': 256},\n",
       " 'mixnet_xl': {'fp32': 15.17538070678711, 'top1': 85.795, 'imsize': 224},\n",
       " 'ens_adv_inception_resnet_v2': {'fp32': 28.72898817062378,\n",
       "  'top1': 85.778,\n",
       "  'imsize': 299},\n",
       " 'tf_efficientnet_lite3': {'fp32': 7.2660040855407715,\n",
       "  'top1': 85.753,\n",
       "  'imsize': 300},\n",
       " 'cspresnext50': {'fp32': 7.168848514556885, 'top1': 85.748, 'imsize': 224},\n",
       " 'ese_vovnet39b': {'fp32': 6.919662952423096, 'top1': 85.744, 'imsize': 224},\n",
       " 'gluon_resnext101_32x4d': {'fp32': 12.791025638580322,\n",
       "  'top1': 85.744,\n",
       "  'imsize': 224},\n",
       " 'legacy_seresnext101_32x4d': {'fp32': 20.8756160736084,\n",
       "  'top1': 85.744,\n",
       "  'imsize': 224},\n",
       " 'eca_resnet33ts': {'fp32': 7.969191074371338, 'top1': 85.738, 'imsize': 256},\n",
       " 'xcit_tiny_24_p16_224': {'fp32': 19.108028411865234,\n",
       "  'top1': 85.736,\n",
       "  'imsize': 224},\n",
       " 'regnety_320': {'fp32': 36.981282234191895, 'top1': 85.723, 'imsize': 224},\n",
       " 'cspresnet50': {'fp32': 7.57429838180542, 'top1': 85.721, 'imsize': 256},\n",
       " 'resnet50': {'fp32': 5.7933878898620605, 'top1': 85.719, 'imsize': 224},\n",
       " 'resmlp_big_24_224': {'fp32': 34.056992530822754,\n",
       "  'top1': 85.697,\n",
       "  'imsize': 224},\n",
       " 'xception71': {'fp32': 20.659208297729492, 'top1': 85.695, 'imsize': 299},\n",
       " 'gluon_resnext101_64x4d': {'fp32': 19.74083423614502,\n",
       "  'top1': 85.693,\n",
       "  'imsize': 224},\n",
       " 'efficientnet_em': {'fp32': 6.00083589553833, 'top1': 85.68, 'imsize': 240},\n",
       " 'deit_small_patch16_224': {'fp32': 5.465109348297119,\n",
       "  'top1': 85.678,\n",
       "  'imsize': 224},\n",
       " 'pit_xs_distilled_224': {'fp32': 5.839943885803223,\n",
       "  'top1': 85.652,\n",
       "  'imsize': 224},\n",
       " 'dpn107': {'fp32': 25.170063972473145, 'top1': 85.65, 'imsize': 224},\n",
       " 'efficientnet_b2_pruned': {'fp32': 10.21066665649414,\n",
       "  'top1': 85.642,\n",
       "  'imsize': 260},\n",
       " 'resmlp_36_224': {'fp32': 8.788459300994873, 'top1': 85.618, 'imsize': 224},\n",
       " 'ecaresnet50d_pruned': {'fp32': 7.139780521392822,\n",
       "  'top1': 85.58,\n",
       "  'imsize': 224},\n",
       " 'gluon_resnet152_v1c': {'fp32': 15.062549114227295,\n",
       "  'top1': 85.576,\n",
       "  'imsize': 224},\n",
       " 'levit_192': {'fp32': 7.895545959472656, 'top1': 85.569, 'imsize': 224},\n",
       " 'resnext50d_32x4d': {'fp32': 7.192068099975586,\n",
       "  'top1': 85.561,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnetv2_b1': {'fp32': 11.18004560470581,\n",
       "  'top1': 85.561,\n",
       "  'imsize': 240},\n",
       " 'regnety_120': {'fp32': 23.375821113586426, 'top1': 85.546, 'imsize': 224},\n",
       " 'fbnetv3_b': {'fp32': 10.709824562072754, 'top1': 85.522, 'imsize': 256},\n",
       " 'regnetx_320': {'fp32': 36.26053810119629, 'top1': 85.516, 'imsize': 224},\n",
       " 'dpn92': {'fp32': 12.765398025512695, 'top1': 85.503, 'imsize': 224},\n",
       " 'nf_regnet_b1': {'fp32': 15.710258483886719, 'top1': 85.503, 'imsize': 288},\n",
       " 'rexnet_130': {'fp32': 8.805513381958008, 'top1': 85.473, 'imsize': 224},\n",
       " 'gluon_resnet152_v1b': {'fp32': 15.094666481018066,\n",
       "  'top1': 85.467,\n",
       "  'imsize': 224},\n",
       " 'resnetrs50': {'fp32': 9.032797813415527, 'top1': 85.46, 'imsize': 224},\n",
       " 'dpn131': {'fp32': 23.090078830718994, 'top1': 85.394, 'imsize': 224},\n",
       " 'regnetx_160': {'fp32': 26.60965919494629, 'top1': 85.388, 'imsize': 224},\n",
       " 'dla102x2': {'fp32': 16.048717498779297, 'top1': 85.375, 'imsize': 224},\n",
       " 'gmlp_s16_224': {'fp32': 7.902042865753174, 'top1': 85.349, 'imsize': 224},\n",
       " 'botnet26t_256': {'fp32': 5.721533298492432, 'top1': 85.336, 'imsize': 256},\n",
       " 'gluon_seresnext50_32x4d': {'fp32': 10.422158241271973,\n",
       "  'top1': 85.336,\n",
       "  'imsize': 224},\n",
       " 'skresnext50_32x4d': {'fp32': 14.28220510482788,\n",
       "  'top1': 85.317,\n",
       "  'imsize': 224},\n",
       " 'dpn98': {'fp32': 16.881685256958008, 'top1': 85.309, 'imsize': 224},\n",
       " 'gluon_resnet101_v1c': {'fp32': 10.45914888381958,\n",
       "  'top1': 85.302,\n",
       "  'imsize': 224},\n",
       " 'lambda_resnet26t': {'fp32': 5.741283893585205, 'top1': 85.3, 'imsize': 256},\n",
       " 'dpn68b': {'fp32': 10.936832427978516, 'top1': 85.291, 'imsize': 224},\n",
       " 'resnetblur50': {'fp32': 5.8751702308654785, 'top1': 85.289, 'imsize': 224},\n",
       " 'resmlp_24_224': {'fp32': 5.954220294952393, 'top1': 85.268, 'imsize': 224},\n",
       " 'coat_lite_mini': {'fp32': 7.50856876373291, 'top1': 85.253, 'imsize': 224},\n",
       " 'cait_xxs24_224': {'fp32': 14.889631271362305, 'top1': 85.228, 'imsize': 224},\n",
       " 'resnet33ts': {'fp32': 7.780876159667969, 'top1': 85.225, 'imsize': 256},\n",
       " 'xcit_tiny_12_p16_224_dist': {'fp32': 10.753610134124756,\n",
       "  'top1': 85.206,\n",
       "  'imsize': 224},\n",
       " 'halonet26t': {'fp32': 5.956995487213135, 'top1': 85.204, 'imsize': 256},\n",
       " 'resnext101_32x8d': {'fp32': 19.138154983520508,\n",
       "  'top1': 85.195,\n",
       "  'imsize': 224},\n",
       " 'gluon_inception_v3': {'fp32': 10.75411319732666,\n",
       "  'top1': 85.183,\n",
       "  'imsize': 299},\n",
       " 'resnet32ts': {'fp32': 7.543859481811523, 'top1': 85.163, 'imsize': 256},\n",
       " 'hrnet_w48': {'fp32': 35.02457857131958, 'top1': 85.153, 'imsize': 224},\n",
       " 'gluon_xception65': {'fp32': 15.7515549659729, 'top1': 85.151, 'imsize': 299},\n",
       " 'gluon_resnet101_v1b': {'fp32': 10.130970478057861,\n",
       "  'top1': 85.144,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b1_ap': {'fp32': 10.730195045471191,\n",
       "  'top1': 85.131,\n",
       "  'imsize': 240},\n",
       " 'eca_halonext26ts': {'fp32': 6.872460842132568,\n",
       "  'top1': 85.129,\n",
       "  'imsize': 256},\n",
       " 'regnetx_120': {'fp32': 21.447408199310303, 'top1': 85.127, 'imsize': 224},\n",
       " 'eca_botnext26ts_256': {'fp32': 6.703970432281494,\n",
       "  'top1': 85.123,\n",
       "  'imsize': 256},\n",
       " 'xception': {'fp32': 9.577939510345459, 'top1': 85.117, 'imsize': 299},\n",
       " 'hrnet_w64': {'fp32': 32.95371055603027, 'top1': 85.112, 'imsize': 224},\n",
       " 'ssl_resnet50': {'fp32': 5.958406925201416, 'top1': 85.102, 'imsize': 224},\n",
       " 'lambda_resnet26rpt_256': {'fp32': 6.539220809936523,\n",
       "  'top1': 85.097,\n",
       "  'imsize': 256},\n",
       " 'res2net101_26w_4s': {'fp32': 18.40484380722046,\n",
       "  'top1': 85.093,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_cc_b1_8e': {'fp32': 13.444218635559082,\n",
       "  'top1': 85.065,\n",
       "  'imsize': 240},\n",
       " 'xcit_nano_12_p8_384_dist': {'fp32': 14.677865505218506,\n",
       "  'top1': 85.02,\n",
       "  'imsize': 384},\n",
       " 'gluon_resnext50_32x4d': {'fp32': 6.836788654327393,\n",
       "  'top1': 85.01,\n",
       "  'imsize': 224},\n",
       " 'resnest26d': {'fp32': 9.251871109008789, 'top1': 85.01, 'imsize': 224},\n",
       " 'tf_efficientnet_b0_ns': {'fp32': 7.803337574005127,\n",
       "  'top1': 84.986,\n",
       "  'imsize': 224},\n",
       " 'coat_tiny': {'fp32': 22.171547412872314, 'top1': 84.978, 'imsize': 224},\n",
       " 'dla169': {'fp32': 16.555702686309814, 'top1': 84.92, 'imsize': 224},\n",
       " 'tf_efficientnet_b1': {'fp32': 10.539169311523438,\n",
       "  'top1': 84.914,\n",
       "  'imsize': 240},\n",
       " 'legacy_seresnext50_32x4d': {'fp32': 10.411221981048584,\n",
       "  'top1': 84.897,\n",
       "  'imsize': 224},\n",
       " 'hrnet_w44': {'fp32': 34.888949394226074, 'top1': 84.884, 'imsize': 224},\n",
       " 'regnetx_080': {'fp32': 16.234798431396484, 'top1': 84.867, 'imsize': 224},\n",
       " 'gluon_resnet50_v1s': {'fp32': 6.035289764404297,\n",
       "  'top1': 84.856,\n",
       "  'imsize': 224},\n",
       " 'res2net50_26w_8s': {'fp32': 16.747329235076904,\n",
       "  'top1': 84.85,\n",
       "  'imsize': 224},\n",
       " 'levit_128': {'fp32': 7.820119857788086, 'top1': 84.843, 'imsize': 224},\n",
       " 'vit_tiny_patch16_384': {'fp32': 7.432727813720703,\n",
       "  'top1': 84.835,\n",
       "  'imsize': 384},\n",
       " 'gluon_resnet50_v1d': {'fp32': 6.278553009033203,\n",
       "  'top1': 84.83,\n",
       "  'imsize': 224},\n",
       " 'dla60_res2next': {'fp32': 16.613309383392334, 'top1': 84.83, 'imsize': 224},\n",
       " 'mixnet_l': {'fp32': 12.269172668457031, 'top1': 84.822, 'imsize': 224},\n",
       " 'tv_resnet152': {'fp32': 15.204079151153564, 'top1': 84.818, 'imsize': 224},\n",
       " 'dla102x': {'fp32': 12.948100566864014, 'top1': 84.813, 'imsize': 224},\n",
       " 'dla60_res2net': {'fp32': 10.980570316314697, 'top1': 84.809, 'imsize': 224},\n",
       " 'pit_xs_224': {'fp32': 5.659186840057373, 'top1': 84.79, 'imsize': 224},\n",
       " 'xception41': {'fp32': 11.514616012573242, 'top1': 84.788, 'imsize': 299},\n",
       " 'regnetx_064': {'fp32': 10.897455215454102, 'top1': 84.781, 'imsize': 224},\n",
       " 'hrnet_w40': {'fp32': 32.83499002456665, 'top1': 84.736, 'imsize': 224},\n",
       " 'res2net50_26w_6s': {'fp32': 13.311500549316406,\n",
       "  'top1': 84.732,\n",
       "  'imsize': 224},\n",
       " 'repvgg_b2': {'fp32': 13.478734493255615, 'top1': 84.722, 'imsize': 224},\n",
       " 'resmlp_12_distilled_224': {'fp32': 3.605632781982422,\n",
       "  'top1': 84.713,\n",
       "  'imsize': 224},\n",
       " 'legacy_seresnet152': {'fp32': 26.78049325942993,\n",
       "  'top1': 84.698,\n",
       "  'imsize': 224},\n",
       " 'selecsls60b': {'fp32': 7.022583484649658, 'top1': 84.655, 'imsize': 224},\n",
       " 'hrnet_w32': {'fp32': 31.91704511642456, 'top1': 84.649, 'imsize': 224},\n",
       " 'bat_resnext26ts': {'fp32': 11.96051836013794, 'top1': 84.638, 'imsize': 256},\n",
       " 'tf_efficientnetv2_b0': {'fp32': 9.29534912109375,\n",
       "  'top1': 84.63,\n",
       "  'imsize': 224},\n",
       " 'efficientnet_b1': {'fp32': 10.567822456359863,\n",
       "  'top1': 84.611,\n",
       "  'imsize': 256},\n",
       " 'regnetx_040': {'fp32': 9.524917602539062, 'top1': 84.6, 'imsize': 224},\n",
       " 'efficientnet_es': {'fp32': 4.870796203613281, 'top1': 84.581, 'imsize': 224},\n",
       " 'hrnet_w30': {'fp32': 32.073707580566406, 'top1': 84.574, 'imsize': 224},\n",
       " 'tf_mixnet_l': {'fp32': 12.706527709960938, 'top1': 84.564, 'imsize': 224},\n",
       " 'wide_resnet101_2': {'fp32': 18.523643016815186,\n",
       "  'top1': 84.551,\n",
       "  'imsize': 224},\n",
       " 'dla60x': {'fp32': 7.814216613769531, 'top1': 84.523, 'imsize': 224},\n",
       " 'legacy_seresnet101': {'fp32': 17.845802307128906,\n",
       "  'top1': 84.502,\n",
       "  'imsize': 224},\n",
       " 'resnet26t': {'fp32': 5.457029342651367, 'top1': 84.465, 'imsize': 256},\n",
       " 'coat_lite_tiny': {'fp32': 7.5011372566223145, 'top1': 84.461, 'imsize': 224},\n",
       " 'tf_efficientnet_em': {'fp32': 6.299922466278076,\n",
       "  'top1': 84.45,\n",
       "  'imsize': 240},\n",
       " 'repvgg_b1': {'fp32': 10.364394187927246, 'top1': 84.414, 'imsize': 224},\n",
       " 'efficientnet_b1_pruned': {'fp32': 10.096492767333984,\n",
       "  'top1': 84.393,\n",
       "  'imsize': 240},\n",
       " 'res2net50_26w_4s': {'fp32': 9.876580238342285,\n",
       "  'top1': 84.363,\n",
       "  'imsize': 224},\n",
       " 'hardcorenas_f': {'fp32': 7.617213726043701, 'top1': 84.322, 'imsize': 224},\n",
       " 'res2net50_14w_8s': {'fp32': 15.424914360046387,\n",
       "  'top1': 84.305,\n",
       "  'imsize': 224},\n",
       " 'selecsls60': {'fp32': 6.74813985824585, 'top1': 84.284, 'imsize': 224},\n",
       " 'regnetx_032': {'fp32': 9.097542762756348, 'top1': 84.239, 'imsize': 224},\n",
       " 'res2next50': {'fp32': 16.03184938430786, 'top1': 84.237, 'imsize': 224},\n",
       " 'gluon_resnet50_v1c': {'fp32': 6.053919792175293,\n",
       "  'top1': 84.211,\n",
       "  'imsize': 224},\n",
       " 'dla102': {'fp32': 10.662713050842285, 'top1': 84.192, 'imsize': 224},\n",
       " 'gcresnext26ts': {'fp32': 7.573559284210205, 'top1': 84.177, 'imsize': 256},\n",
       " 'rexnet_100': {'fp32': 8.967130184173584, 'top1': 84.164, 'imsize': 224},\n",
       " 'seresnext26ts': {'fp32': 7.2696661949157715, 'top1': 84.147, 'imsize': 256},\n",
       " 'tf_inception_v3': {'fp32': 10.88449478149414, 'top1': 84.139, 'imsize': 299},\n",
       " 'res2net50_48w_2s': {'fp32': 6.728930473327637,\n",
       "  'top1': 84.126,\n",
       "  'imsize': 224},\n",
       " 'xcit_tiny_12_p16_224': {'fp32': 10.727407932281494,\n",
       "  'top1': 84.094,\n",
       "  'imsize': 224},\n",
       " 'resnet34d': {'fp32': 4.745206832885742, 'top1': 84.094, 'imsize': 224},\n",
       " 'tf_efficientnet_lite2': {'fp32': 6.246969699859619,\n",
       "  'top1': 84.094,\n",
       "  'imsize': 260},\n",
       " 'efficientnet_b0': {'fp32': 7.8281569480896, 'top1': 84.025, 'imsize': 224},\n",
       " 'crossvit_9_dagger_240': {'fp32': 9.307222366333008,\n",
       "  'top1': 84.019,\n",
       "  'imsize': 240},\n",
       " 'hardcorenas_e': {'fp32': 7.73256778717041, 'top1': 83.968, 'imsize': 224},\n",
       " 'gmixer_24_224': {'fp32': 8.668718338012695, 'top1': 83.966, 'imsize': 224},\n",
       " 'tf_efficientnet_cc_b0_8e': {'fp32': 9.725077152252197,\n",
       "  'top1': 83.963,\n",
       "  'imsize': 224},\n",
       " 'regnety_016': {'fp32': 13.357937335968018, 'top1': 83.957, 'imsize': 224},\n",
       " 'tv_resnext50_32x4d': {'fp32': 6.831612586975098,\n",
       "  'top1': 83.957,\n",
       "  'imsize': 224},\n",
       " 'gluon_resnet50_v1b': {'fp32': 5.908632278442383,\n",
       "  'top1': 83.942,\n",
       "  'imsize': 224},\n",
       " 'densenet161': {'fp32': 18.09764862060547, 'top1': 83.908, 'imsize': 224},\n",
       " 'adv_inception_v3': {'fp32': 10.546283721923828, 'top1': 83.9, 'imsize': 299},\n",
       " 'mobilenetv2_120d': {'fp32': 6.720249652862549,\n",
       "  'top1': 83.891,\n",
       "  'imsize': 224},\n",
       " 'seresnext26t_32x4d': {'fp32': 6.167941093444824,\n",
       "  'top1': 83.874,\n",
       "  'imsize': 224},\n",
       " 'tv_resnet101': {'fp32': 10.379955768585205, 'top1': 83.85, 'imsize': 224},\n",
       " 'tinynet_a': {'fp32': 9.371922016143799, 'top1': 83.827, 'imsize': 192},\n",
       " 'hardcorenas_d': {'fp32': 7.696280479431152, 'top1': 83.759, 'imsize': 224},\n",
       " 'inception_v3': {'fp32': 10.290961265563965, 'top1': 83.759, 'imsize': 299},\n",
       " 'seresnext26d_32x4d': {'fp32': 6.1476969718933105,\n",
       "  'top1': 83.754,\n",
       "  'imsize': 224},\n",
       " 'dla60': {'fp32': 6.594822406768799, 'top1': 83.731, 'imsize': 224},\n",
       " 'xcit_nano_12_p8_224_dist': {'fp32': 10.99086046218872,\n",
       "  'top1': 83.729,\n",
       "  'imsize': 224},\n",
       " 'eca_resnext26ts': {'fp32': 6.967966556549072, 'top1': 83.699, 'imsize': 256},\n",
       " 'repvgg_b1g4': {'fp32': 15.6068754196167, 'top1': 83.695, 'imsize': 224},\n",
       " 'legacy_seresnet50': {'fp32': 9.246330261230469,\n",
       "  'top1': 83.662,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b0_ap': {'fp32': 7.965834140777588,\n",
       "  'top1': 83.652,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_cc_b0_4e': {'fp32': 9.602515697479248,\n",
       "  'top1': 83.635,\n",
       "  'imsize': 224},\n",
       " 'skresnet34': {'fp32': 11.708900928497314, 'top1': 83.635, 'imsize': 224},\n",
       " 'resmlp_12_224': {'fp32': 3.5886144638061523, 'top1': 83.569, 'imsize': 224},\n",
       " 'mobilenetv3_large_100_miil': {'fp32': 6.05299711227417,\n",
       "  'top1': 83.556,\n",
       "  'imsize': 224},\n",
       " 'densenet201': {'fp32': 22.879717350006104, 'top1': 83.554, 'imsize': 224},\n",
       " 'gernet_s': {'fp32': 4.9816060066223145, 'top1': 83.519, 'imsize': 224},\n",
       " 'legacy_seresnext26_32x4d': {'fp32': 5.817451477050781,\n",
       "  'top1': 83.519,\n",
       "  'imsize': 224},\n",
       " 'mixnet_m': {'fp32': 11.988372802734375, 'top1': 83.519, 'imsize': 224},\n",
       " 'tf_efficientnet_b0': {'fp32': 7.770888805389404,\n",
       "  'top1': 83.515,\n",
       "  'imsize': 224},\n",
       " 'hrnet_w18': {'fp32': 30.80608367919922, 'top1': 83.498, 'imsize': 224},\n",
       " 'resnext26ts': {'fp32': 6.742100715637207, 'top1': 83.47, 'imsize': 256},\n",
       " 'densenetblur121d': {'fp32': 13.999888896942139,\n",
       "  'top1': 83.466,\n",
       "  'imsize': 224},\n",
       " 'selecsls42b': {'fp32': 5.568068027496338, 'top1': 83.455, 'imsize': 224},\n",
       " 'hardcorenas_c': {'fp32': 5.877876281738281, 'top1': 83.34, 'imsize': 224},\n",
       " 'tf_efficientnet_lite1': {'fp32': 5.6064605712890625,\n",
       "  'top1': 83.34,\n",
       "  'imsize': 240},\n",
       " 'regnetx_016': {'fp32': 7.314951419830322, 'top1': 83.197, 'imsize': 224},\n",
       " 'dpn68': {'fp32': 10.054221153259277, 'top1': 83.18, 'imsize': 224},\n",
       " 'mobilenetv2_140': {'fp32': 4.443831443786621, 'top1': 83.18, 'imsize': 224},\n",
       " 'tf_efficientnet_es': {'fp32': 4.689013957977295,\n",
       "  'top1': 83.178,\n",
       "  'imsize': 224},\n",
       " 'tf_mixnet_m': {'fp32': 12.308733463287354, 'top1': 83.176, 'imsize': 224},\n",
       " 'xcit_nano_12_p16_384_dist': {'fp32': 12.118206024169922,\n",
       "  'top1': 83.171,\n",
       "  'imsize': 384},\n",
       " 'ese_vovnet19b_dw': {'fp32': 4.0004706382751465,\n",
       "  'top1': 83.114,\n",
       "  'imsize': 224},\n",
       " 'levit_128s': {'fp32': 6.559152603149414, 'top1': 83.062, 'imsize': 224},\n",
       " 'resnet26d': {'fp32': 4.040932655334473, 'top1': 83.062, 'imsize': 224},\n",
       " 'repvgg_a2': {'fp32': 5.714998245239258, 'top1': 83.001, 'imsize': 224},\n",
       " 'tv_resnet50': {'fp32': 5.802786350250244, 'top1': 82.954, 'imsize': 224},\n",
       " 'hardcorenas_b': {'fp32': 5.633726119995117, 'top1': 82.868, 'imsize': 224},\n",
       " 'densenet121': {'fp32': 13.749330043792725, 'top1': 82.821, 'imsize': 224},\n",
       " 'vit_tiny_r_s16_p8_384': {'fp32': 7.194309234619141,\n",
       "  'top1': 82.691,\n",
       "  'imsize': 384},\n",
       " 'densenet169': {'fp32': 19.284188747406006, 'top1': 82.678, 'imsize': 224},\n",
       " 'mixnet_s': {'fp32': 10.246307849884033, 'top1': 82.522, 'imsize': 224},\n",
       " 'vit_small_patch32_224': {'fp32': 5.250275135040283,\n",
       "  'top1': 82.507,\n",
       "  'imsize': 224},\n",
       " 'regnety_008': {'fp32': 7.788288593292236, 'top1': 82.488, 'imsize': 224},\n",
       " 'efficientnet_lite0': {'fp32': 4.412810802459717,\n",
       "  'top1': 82.386,\n",
       "  'imsize': 224},\n",
       " 'resnest14d': {'fp32': 6.9300127029418945, 'top1': 82.349, 'imsize': 224},\n",
       " 'hardcorenas_a': {'fp32': 4.856572151184082, 'top1': 82.311, 'imsize': 224},\n",
       " 'efficientnet_es_pruned': {'fp32': 4.939916133880615,\n",
       "  'top1': 82.287,\n",
       "  'imsize': 224},\n",
       " 'mobilenetv3_rw': {'fp32': 5.635652542114258, 'top1': 82.273, 'imsize': 224},\n",
       " 'semnasnet_100': {'fp32': 5.670835971832275, 'top1': 82.251, 'imsize': 224},\n",
       " 'mobilenetv3_large_100': {'fp32': 6.002504825592041,\n",
       "  'top1': 82.179,\n",
       "  'imsize': 224},\n",
       " 'resnet34': {'fp32': 4.344308376312256, 'top1': 82.144, 'imsize': 224},\n",
       " 'vit_tiny_patch16_224': {'fp32': 5.210075378417969,\n",
       "  'top1': 82.076,\n",
       "  'imsize': 224},\n",
       " 'mobilenetv2_110d': {'fp32': 5.651583671569824,\n",
       "  'top1': 82.074,\n",
       "  'imsize': 224},\n",
       " 'tf_mixnet_s': {'fp32': 10.167324542999268, 'top1': 82.038, 'imsize': 224},\n",
       " 'repvgg_b0': {'fp32': 6.4287614822387695, 'top1': 82.006, 'imsize': 224},\n",
       " 'deit_tiny_distilled_patch16_224': {'fp32': 5.610373020172119,\n",
       "  'top1': 81.997,\n",
       "  'imsize': 224},\n",
       " 'mixer_b16_224': {'fp32': 5.068957805633545, 'top1': 81.987, 'imsize': 224},\n",
       " 'pit_ti_distilled_224': {'fp32': 5.421543121337891,\n",
       "  'top1': 81.972,\n",
       "  'imsize': 224},\n",
       " 'hrnet_w18_small_v2': {'fp32': 16.914896965026855,\n",
       "  'top1': 81.963,\n",
       "  'imsize': 224},\n",
       " 'resnet26': {'fp32': 3.7747788429260254, 'top1': 81.954, 'imsize': 224},\n",
       " 'tf_efficientnet_lite0': {'fp32': 4.839634895324707,\n",
       "  'top1': 81.952,\n",
       "  'imsize': 224},\n",
       " 'tinynet_b': {'fp32': 8.059356212615967, 'top1': 81.873, 'imsize': 188},\n",
       " 'tf_mobilenetv3_large_100': {'fp32': 6.213738918304443,\n",
       "  'top1': 81.848,\n",
       "  'imsize': 224},\n",
       " 'tv_densenet121': {'fp32': 13.973939418792725, 'top1': 81.724, 'imsize': 224},\n",
       " 'regnety_006': {'fp32': 8.46891164779663, 'top1': 81.698, 'imsize': 224},\n",
       " 'dla34': {'fp32': 4.637060165405273, 'top1': 81.645, 'imsize': 224},\n",
       " 'xcit_nano_12_p8_224': {'fp32': 10.785064697265625,\n",
       "  'top1': 81.638,\n",
       "  'imsize': 224},\n",
       " 'crossvit_9_240': {'fp32': 8.890881538391113, 'top1': 81.615, 'imsize': 240},\n",
       " 'fbnetc_100': {'fp32': 5.82402229309082, 'top1': 81.559, 'imsize': 224},\n",
       " 'legacy_seresnet34': {'fp32': 7.060685157775879,\n",
       "  'top1': 81.536,\n",
       "  'imsize': 224},\n",
       " 'gluon_resnet34_v1b': {'fp32': 4.201843738555908,\n",
       "  'top1': 81.498,\n",
       "  'imsize': 224},\n",
       " 'regnetx_008': {'fp32': 6.097044944763184, 'top1': 81.481, 'imsize': 224},\n",
       " 'mnasnet_100': {'fp32': 4.603738784790039, 'top1': 81.453, 'imsize': 224},\n",
       " 'vgg19_bn': {'fp32': 12.289738655090332, 'top1': 81.446, 'imsize': 224},\n",
       " 'convit_tiny': {'fp32': 7.066531181335449, 'top1': 81.132, 'imsize': 224},\n",
       " 'crossvit_tiny_240': {'fp32': 9.960432052612305,\n",
       "  'top1': 81.09,\n",
       "  'imsize': 240},\n",
       " 'spnasnet_100': {'fp32': 5.0150370597839355, 'top1': 80.872, 'imsize': 224},\n",
       " 'ghostnet_100': {'fp32': 8.920471668243408, 'top1': 80.701, 'imsize': 224},\n",
       " 'regnety_004': {'fp32': 10.127780437469482, 'top1': 80.65, 'imsize': 224},\n",
       " 'skresnet18': {'fp32': 6.576483249664307, 'top1': 80.641, 'imsize': 224},\n",
       " 'regnetx_006': {'fp32': 5.821409225463867, 'top1': 80.635, 'imsize': 224},\n",
       " 'pit_ti_224': {'fp32': 5.8481764793396, 'top1': 80.614, 'imsize': 224},\n",
       " 'swsl_resnet18': {'fp32': 2.8817200660705566, 'top1': 80.573, 'imsize': 224},\n",
       " 'vgg16_bn': {'fp32': 10.760045051574707, 'top1': 80.556, 'imsize': 224},\n",
       " 'semnasnet_075': {'fp32': 5.926918983459473, 'top1': 80.473, 'imsize': 224},\n",
       " 'tv_resnet34': {'fp32': 4.236574172973633, 'top1': 80.389, 'imsize': 224},\n",
       " 'resnet18d': {'fp32': 3.091740608215332, 'top1': 80.385, 'imsize': 224},\n",
       " 'mobilenetv2_100': {'fp32': 4.582333564758301, 'top1': 80.255, 'imsize': 224},\n",
       " 'xcit_nano_12_p16_224_dist': {'fp32': 10.99285364151001,\n",
       "  'top1': 80.216,\n",
       "  'imsize': 224},\n",
       " 'ssl_resnet18': {'fp32': 2.8758835792541504, 'top1': 80.097, 'imsize': 224},\n",
       " 'tf_mobilenetv3_large_075': {'fp32': 5.792481899261475,\n",
       "  'top1': 80.091,\n",
       "  'imsize': 224},\n",
       " 'deit_tiny_patch16_224': {'fp32': 5.591640472412109,\n",
       "  'top1': 80.016,\n",
       "  'imsize': 224},\n",
       " 'hrnet_w18_small': {'fp32': 9.659457206726074, 'top1': 79.565, 'imsize': 224},\n",
       " 'vgg19': {'fp32': 11.488819122314453, 'top1': 79.478, 'imsize': 224},\n",
       " 'regnetx_004': {'fp32': 9.148972034454346, 'top1': 79.422, 'imsize': 224},\n",
       " 'tf_mobilenetv3_large_minimal_100': {'fp32': 4.442019462585449,\n",
       "  'top1': 79.224,\n",
       "  'imsize': 224},\n",
       " 'legacy_seresnet18': {'fp32': 4.245562553405762,\n",
       "  'top1': 79.157,\n",
       "  'imsize': 224},\n",
       " 'vgg16': {'fp32': 10.01007080078125, 'top1': 79.034, 'imsize': 224},\n",
       " 'vgg13_bn': {'fp32': 9.120914936065674, 'top1': 79.008, 'imsize': 224},\n",
       " 'vit_tiny_r_s16_p8_224': {'fp32': 5.55293083190918,\n",
       "  'top1': 78.991,\n",
       "  'imsize': 224},\n",
       " 'lcnet_100': {'fp32': 2.986466884613037, 'top1': 78.895, 'imsize': 224},\n",
       " 'tinynet_c': {'fp32': 6.865592002868652, 'top1': 78.432, 'imsize': 184},\n",
       " 'gluon_resnet18_v1b': {'fp32': 2.757880687713623,\n",
       "  'top1': 78.374,\n",
       "  'imsize': 224},\n",
       " 'vgg11_bn': {'fp32': 7.43910551071167, 'top1': 77.926, 'imsize': 224},\n",
       " 'xcit_nano_12_p16_224': {'fp32': 10.890634059906006,\n",
       "  'top1': 77.891,\n",
       "  'imsize': 224},\n",
       " 'regnety_002': {'fp32': 8.584651947021484, 'top1': 77.411, 'imsize': 224},\n",
       " 'mixer_l16_224': {'fp32': 15.549030303955078, 'top1': 77.283, 'imsize': 224},\n",
       " 'resnet18': {'fp32': 2.706878185272217, 'top1': 77.274, 'imsize': 224},\n",
       " 'vgg13': {'fp32': 8.521652221679688, 'top1': 77.227, 'imsize': 224},\n",
       " 'vgg11': {'fp32': 7.000517845153809, 'top1': 76.393, 'imsize': 224},\n",
       " 'regnetx_002': {'fp32': 5.940232276916504, 'top1': 76.117, 'imsize': 224},\n",
       " 'lcnet_075': {'fp32': 3.4865260124206543, 'top1': 76.057, 'imsize': 224},\n",
       " 'dla60x_c': {'fp32': 6.420600414276123, 'top1': 75.637, 'imsize': 224},\n",
       " 'mobilenetv3_small_100': {'fp32': 4.828383922576904,\n",
       "  'top1': 74.913,\n",
       "  'imsize': 224},\n",
       " 'tf_mobilenetv3_small_100': {'fp32': 5.2097296714782715,\n",
       "  'top1': 74.719,\n",
       "  'imsize': 224},\n",
       " 'tinynet_d': {'fp32': 5.136370658874512, 'top1': 74.281, 'imsize': 152},\n",
       " 'mnasnet_small': {'fp32': 6.423203945159912, 'top1': 73.816, 'imsize': 224},\n",
       " 'dla46x_c': {'fp32': 4.918155670166016, 'top1': 73.647, 'imsize': 224},\n",
       " 'mobilenetv2_050': {'fp32': 4.91044282913208, 'top1': 73.463, 'imsize': 224},\n",
       " 'tf_mobilenetv3_small_075': {'fp32': 5.418448448181152,\n",
       "  'top1': 72.806,\n",
       "  'imsize': 224},\n",
       " 'dla46_c': {'fp32': 5.151412487030029, 'top1': 72.607, 'imsize': 224},\n",
       " 'mobilenetv3_small_075': {'fp32': 5.458409786224365,\n",
       "  'top1': 72.325,\n",
       "  'imsize': 224},\n",
       " 'lcnet_050': {'fp32': 3.001708984375, 'top1': 70.393, 'imsize': 224},\n",
       " 'tf_mobilenetv3_small_minimal_100': {'fp32': 3.7972640991210938,\n",
       "  'top1': 70.111,\n",
       "  'imsize': 224},\n",
       " 'tinynet_e': {'fp32': 4.524264335632324, 'top1': 66.813, 'imsize': 106},\n",
       " 'mobilenetv3_small_050': {'fp32': 4.833028316497803,\n",
       "  'top1': 64.671,\n",
       "  'imsize': 224}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellist = df_models[\"model\"]\n",
    "benchmark = {}\n",
    "\n",
    "# inference float precision\n",
    "for i,modelname in tqdm(enumerate((modellist))):\n",
    "    imsize = int(df_models[df_models[\"model\"]==modelname][\"img_size\"])\n",
    "    try:\n",
    "        benchmark = inference_imsize(modelname, benchmark, imsize)\n",
    "    except:\n",
    "        print(\"pass {}\".format(modelname))\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(benchmark).T\n",
    "df_results\n",
    "df_results.to_csv(\"results_fp32_imsizeall.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
