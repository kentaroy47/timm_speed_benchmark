{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "#import torch.utils.benchmark as benchmark\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WARM_UP = 10\n",
    "BATCH_SIZE = 4\n",
    "NUM_TEST = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec 22 14:44:46 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.82.00    Driver Version: 470.82.00    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:09:00.0 Off |                  Off |\n",
      "| 30%   47C    P8    17W / 300W |     33MiB / 48682MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1262      G   /usr/lib/xorg/Xorg                 23MiB |\n",
      "|    0   N/A  N/A      1703      G   /usr/bin/gnome-shell                8MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>top1</th>\n",
       "      <th>top1_err</th>\n",
       "      <th>top5</th>\n",
       "      <th>top5_err</th>\n",
       "      <th>param_count</th>\n",
       "      <th>img_size</th>\n",
       "      <th>cropt_pct</th>\n",
       "      <th>interpolation</th>\n",
       "      <th>top1_diff</th>\n",
       "      <th>top5_diff</th>\n",
       "      <th>rank_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beit_large_patch16_512</td>\n",
       "      <td>90.695</td>\n",
       "      <td>9.305</td>\n",
       "      <td>98.770</td>\n",
       "      <td>1.230</td>\n",
       "      <td>305.67</td>\n",
       "      <td>512</td>\n",
       "      <td>1.000</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>2.111</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beit_large_patch16_384</td>\n",
       "      <td>90.601</td>\n",
       "      <td>9.399</td>\n",
       "      <td>98.777</td>\n",
       "      <td>1.223</td>\n",
       "      <td>305.00</td>\n",
       "      <td>384</td>\n",
       "      <td>1.000</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>2.219</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tf_efficientnet_l2_ns</td>\n",
       "      <td>90.572</td>\n",
       "      <td>9.428</td>\n",
       "      <td>98.779</td>\n",
       "      <td>1.221</td>\n",
       "      <td>480.31</td>\n",
       "      <td>800</td>\n",
       "      <td>0.960</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>2.226</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tf_efficientnet_l2_ns_475</td>\n",
       "      <td>90.527</td>\n",
       "      <td>9.473</td>\n",
       "      <td>98.706</td>\n",
       "      <td>1.294</td>\n",
       "      <td>480.31</td>\n",
       "      <td>475</td>\n",
       "      <td>0.936</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>2.289</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beit_base_patch16_384</td>\n",
       "      <td>90.388</td>\n",
       "      <td>9.612</td>\n",
       "      <td>98.730</td>\n",
       "      <td>1.270</td>\n",
       "      <td>86.74</td>\n",
       "      <td>384</td>\n",
       "      <td>1.000</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>3.580</td>\n",
       "      <td>0.590</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model    top1  top1_err    top5  top5_err  param_count  \\\n",
       "0     beit_large_patch16_512  90.695     9.305  98.770     1.230       305.67   \n",
       "1     beit_large_patch16_384  90.601     9.399  98.777     1.223       305.00   \n",
       "2      tf_efficientnet_l2_ns  90.572     9.428  98.779     1.221       480.31   \n",
       "3  tf_efficientnet_l2_ns_475  90.527     9.473  98.706     1.294       480.31   \n",
       "4      beit_base_patch16_384  90.388     9.612  98.730     1.270        86.74   \n",
       "\n",
       "   img_size  cropt_pct interpolation  top1_diff  top5_diff  rank_diff  \n",
       "0       512      1.000       bicubic      2.111      0.110          0  \n",
       "1       384      1.000       bicubic      2.219      0.169          0  \n",
       "2       800      0.960       bicubic      2.226      0.125          0  \n",
       "3       475      0.936       bicubic      2.289      0.156          0  \n",
       "4       384      1.000       bicubic      3.580      0.590          4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models = pd.read_csv(\"results-imagenet-real.csv\")\n",
    "# use models with img size 224\n",
    "modellist = df_models[df_models[\"img_size\"]==224][\"model\"]\n",
    "df_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "    def __init__(self,  length, imsize):\n",
    "        self.len = length\n",
    "        self.data = torch.randn( 3, imsize, imsize, length)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[:,:,:,index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "rand_loader = DataLoader(dataset=RandomDataset(BATCH_SIZE*(WARM_UP + NUM_TEST), 224),\n",
    "                         batch_size=BATCH_SIZE, shuffle=False,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ryujaehun/pytorch-gpu-benchmark/blob/master/benchmark_models.py\n",
    "def inference(modelname, benchmark, half=False):\n",
    "    with torch.no_grad():\n",
    "        model = timm.create_model(modelname,)\n",
    "        model=model.to('cuda')\n",
    "        model.eval()\n",
    "        precision = \"float\"\n",
    "        durations = []\n",
    "        print(f'Benchmarking Inference {modelname} ')\n",
    "        for step,img in enumerate(rand_loader):\n",
    "            img=getattr(img,precision)()\n",
    "            torch.cuda.synchronize()\n",
    "            start = time.time()\n",
    "            model(img.to('cuda'))\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            if step >= WARM_UP:\n",
    "                durations.append((end - start)*1000)\n",
    "        print(f'{modelname} model average inference time : {sum(durations)/len(durations)}ms')\n",
    "        \n",
    "        if half:\n",
    "            durations_half = []\n",
    "            print(f'Benchmarking Inference half precision type {modelname} ')\n",
    "            model.half()\n",
    "            precision = \"half\"\n",
    "            for step,img in enumerate(rand_loader):\n",
    "                img=getattr(img,precision)()\n",
    "                torch.cuda.synchronize()\n",
    "                start = time.time()\n",
    "                model(img.to('cuda'))\n",
    "                torch.cuda.synchronize()\n",
    "                end = time.time()\n",
    "                if step >= WARM_UP:\n",
    "                    durations_half.append((end - start)*1000)\n",
    "            print(f'{modelname} half model average inference time : {sum(durations_half)/len(durations_half)}ms')\n",
    "            \n",
    "        if half:\n",
    "            benchmark[modelname] = {\"fp32\": np.mean(durations), \"fp16\": np.mean(durations_half), \"top1\": df_models[df_models[\"model\"]==modelname][\"top1\"]}\n",
    "        else:\n",
    "            benchmark[modelname] = {\"fp32\": np.mean(durations), \"top1\": float(df_models[df_models[\"model\"]==modelname][\"top1\"])}\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b825893fd69e43408292533bbc84eec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference beit_large_patch16_224 \n",
      "beit_large_patch16_224 model average inference time : 21.222758293151855ms\n",
      "Benchmarking Inference swin_large_patch4_window7_224 \n",
      "swin_large_patch4_window7_224 model average inference time : 17.0994234085083ms\n",
      "Benchmarking Inference xcit_large_24_p8_224_dist \n",
      "xcit_large_24_p8_224_dist model average inference time : 66.53245449066162ms\n",
      "Benchmarking Inference beit_base_patch16_224 \n",
      "beit_base_patch16_224 model average inference time : 7.464489936828613ms\n",
      "Benchmarking Inference vit_large_patch16_224 \n",
      "vit_large_patch16_224 model average inference time : 20.04459857940674ms\n",
      "Benchmarking Inference xcit_medium_24_p8_224_dist \n",
      "xcit_medium_24_p8_224_dist model average inference time : 40.78274726867676ms\n",
      "Benchmarking Inference xcit_small_24_p8_224_dist \n",
      "xcit_small_24_p8_224_dist model average inference time : 29.373767375946045ms\n",
      "Benchmarking Inference swin_base_patch4_window7_224 \n",
      "swin_base_patch4_window7_224 model average inference time : 12.806141376495361ms\n",
      "Benchmarking Inference ig_resnext101_32x32d \n",
      "ig_resnext101_32x32d model average inference time : 132.56885290145874ms\n",
      "Benchmarking Inference ig_resnext101_32x48d \n",
      "ig_resnext101_32x48d model average inference time : 210.10546445846558ms\n",
      "Benchmarking Inference xcit_large_24_p16_224_dist \n",
      "xcit_large_24_p16_224_dist model average inference time : 19.736363887786865ms\n",
      "Benchmarking Inference resmlp_big_24_224_in22ft1k \n",
      "resmlp_big_24_224_in22ft1k model average inference time : 33.9638614654541ms\n",
      "Benchmarking Inference xcit_small_12_p8_224_dist \n",
      "xcit_small_12_p8_224_dist model average inference time : 16.07722043991089ms\n",
      "Benchmarking Inference vit_base_patch16_224 \n",
      "vit_base_patch16_224 model average inference time : 7.092115879058838ms\n",
      "Benchmarking Inference xcit_medium_24_p16_224_dist \n",
      "xcit_medium_24_p16_224_dist model average inference time : 19.059040546417236ms\n",
      "Benchmarking Inference ig_resnext101_32x16d \n",
      "ig_resnext101_32x16d model average inference time : 35.41270971298218ms\n",
      "Benchmarking Inference swsl_resnext101_32x8d \n",
      "swsl_resnext101_32x8d model average inference time : 19.28312063217163ms\n",
      "Benchmarking Inference vit_base_patch16_224_miil \n",
      "vit_base_patch16_224_miil model average inference time : 6.86307430267334ms\n",
      "Benchmarking Inference pit_b_distilled_224 \n",
      "pit_b_distilled_224 model average inference time : 8.121466636657715ms\n",
      "Benchmarking Inference xcit_small_24_p16_224_dist \n",
      "xcit_small_24_p16_224_dist model average inference time : 18.69269609451294ms\n",
      "Benchmarking Inference cait_s24_224 \n",
      "cait_s24_224 model average inference time : 14.812660217285156ms\n",
      "Benchmarking Inference resmlp_big_24_distilled_224 \n",
      "resmlp_big_24_distilled_224 model average inference time : 33.96995306015015ms\n",
      "Benchmarking Inference vit_large_r50_s32_224 \n",
      "vit_large_r50_s32_224 model average inference time : 16.82636022567749ms\n",
      "Benchmarking Inference xcit_small_12_p16_224_dist \n",
      "xcit_small_12_p16_224_dist model average inference time : 10.687386989593506ms\n",
      "Benchmarking Inference deit_base_distilled_patch16_224 \n",
      "deit_base_distilled_patch16_224 model average inference time : 7.080423831939697ms\n",
      "Benchmarking Inference ig_resnext101_32x8d \n",
      "ig_resnext101_32x8d model average inference time : 19.176130294799805ms\n",
      "Benchmarking Inference xcit_large_24_p8_224 \n",
      "xcit_large_24_p8_224 model average inference time : 68.2600736618042ms\n",
      "Benchmarking Inference swsl_resnext101_32x4d \n",
      "swsl_resnext101_32x4d model average inference time : 12.613909244537354ms\n",
      "Benchmarking Inference xcit_tiny_24_p8_224_dist \n",
      "xcit_tiny_24_p8_224_dist model average inference time : 18.30082416534424ms\n",
      "Benchmarking Inference xcit_small_24_p8_224 \n",
      "xcit_small_24_p8_224 model average inference time : 29.7322678565979ms\n",
      "Benchmarking Inference twins_svt_large \n",
      "twins_svt_large model average inference time : 14.635822772979736ms\n",
      "Benchmarking Inference twins_pcpvt_large \n",
      "twins_pcpvt_large model average inference time : 24.414920806884766ms\n",
      "Benchmarking Inference xcit_small_12_p8_224 \n",
      "xcit_small_12_p8_224 model average inference time : 16.07599973678589ms\n",
      "Benchmarking Inference resnetv2_50x1_bit_distilled \n",
      "resnetv2_50x1_bit_distilled model average inference time : 8.04631233215332ms\n",
      "Benchmarking Inference tresnet_m \n",
      "pass tresnet_m\n",
      "Benchmarking Inference twins_pcpvt_base \n",
      "twins_pcpvt_base model average inference time : 16.830954551696777ms\n",
      "Benchmarking Inference swin_small_patch4_window7_224 \n",
      "swin_small_patch4_window7_224 model average inference time : 13.139035701751709ms\n",
      "Benchmarking Inference twins_svt_base \n",
      "twins_svt_base model average inference time : 13.144330978393555ms\n",
      "Benchmarking Inference xcit_medium_24_p8_224 \n",
      "xcit_medium_24_p8_224 model average inference time : 41.48906946182251ms\n",
      "Benchmarking Inference jx_nest_base \n",
      "jx_nest_base model average inference time : 13.87157917022705ms\n",
      "Benchmarking Inference swsl_resnext101_32x16d \n",
      "swsl_resnext101_32x16d model average inference time : 35.50509452819824ms\n",
      "Benchmarking Inference swsl_resnext50_32x4d \n",
      "swsl_resnext50_32x4d model average inference time : 6.88831090927124ms\n",
      "Benchmarking Inference levit_384 \n",
      "levit_384 model average inference time : 7.732181549072266ms\n",
      "Benchmarking Inference jx_nest_small \n",
      "jx_nest_small model average inference time : 10.803375244140625ms\n",
      "Benchmarking Inference resnetv2_152x2_bit_teacher \n",
      "resnetv2_152x2_bit_teacher model average inference time : 46.50394678115845ms\n",
      "Benchmarking Inference xcit_tiny_24_p8_224 \n",
      "xcit_tiny_24_p8_224 model average inference time : 18.08338165283203ms\n",
      "Benchmarking Inference coat_lite_small \n",
      "coat_lite_small model average inference time : 13.0839204788208ms\n",
      "Benchmarking Inference resnetv2_101 \n",
      "resnetv2_101 model average inference time : 10.269548892974854ms\n",
      "Benchmarking Inference ecaresnet101d \n",
      "ecaresnet101d model average inference time : 13.389935493469238ms\n",
      "Benchmarking Inference pit_s_distilled_224 \n",
      "pit_s_distilled_224 model average inference time : 5.669441223144531ms\n",
      "Benchmarking Inference mixer_b16_224_miil \n",
      "mixer_b16_224_miil model average inference time : 5.0153279304504395ms\n",
      "Benchmarking Inference tresnet_xl \n",
      "pass tresnet_xl\n",
      "Benchmarking Inference xcit_tiny_12_p8_224_dist \n",
      "xcit_tiny_12_p8_224_dist model average inference time : 10.577220916748047ms\n",
      "Benchmarking Inference convit_base \n",
      "convit_base model average inference time : 10.248382091522217ms\n",
      "Benchmarking Inference visformer_small \n",
      "visformer_small model average inference time : 12.276256084442139ms\n",
      "Benchmarking Inference xcit_small_24_p16_224 \n",
      "xcit_small_24_p16_224 model average inference time : 18.592159748077393ms\n",
      "Benchmarking Inference convit_small \n",
      "convit_small model average inference time : 7.061395645141602ms\n",
      "Benchmarking Inference jx_nest_tiny \n",
      "jx_nest_tiny model average inference time : 7.174441814422607ms\n",
      "Benchmarking Inference xcit_small_12_p16_224 \n",
      "xcit_small_12_p16_224 model average inference time : 10.355837345123291ms\n",
      "Benchmarking Inference deit_small_distilled_patch16_224 \n",
      "deit_small_distilled_patch16_224 model average inference time : 5.395364761352539ms\n",
      "Benchmarking Inference resmlp_36_distilled_224 \n",
      "resmlp_36_distilled_224 model average inference time : 8.569638729095459ms\n",
      "Benchmarking Inference xcit_large_24_p16_224 \n",
      "xcit_large_24_p16_224 model average inference time : 19.858109951019287ms\n",
      "Benchmarking Inference xcit_medium_24_p16_224 \n",
      "xcit_medium_24_p16_224 model average inference time : 18.936972618103027ms\n",
      "Benchmarking Inference tnt_s_patch16_224 \n",
      "tnt_s_patch16_224 model average inference time : 11.9808030128479ms\n",
      "Benchmarking Inference convmixer_1536_20 \n",
      "pass convmixer_1536_20\n",
      "Benchmarking Inference rexnet_200 \n",
      "rexnet_200 model average inference time : 8.933818340301514ms\n",
      "Benchmarking Inference vit_small_patch16_224 \n",
      "vit_small_patch16_224 model average inference time : 5.296797752380371ms\n",
      "Benchmarking Inference ssl_resnext101_32x16d \n",
      "ssl_resnext101_32x16d model average inference time : 35.33586263656616ms\n",
      "Benchmarking Inference vit_small_r26_s32_224 \n",
      "vit_small_r26_s32_224 model average inference time : 9.251573085784912ms\n",
      "Benchmarking Inference deit_base_patch16_224 \n",
      "deit_base_patch16_224 model average inference time : 7.058782577514648ms\n",
      "Benchmarking Inference coat_mini \n",
      "coat_mini model average inference time : 22.302887439727783ms\n",
      "Benchmarking Inference swsl_resnet50 \n",
      "swsl_resnet50 model average inference time : 5.740089416503906ms\n",
      "Benchmarking Inference ssl_resnext101_32x8d \n",
      "ssl_resnext101_32x8d model average inference time : 19.183614253997803ms\n",
      "Benchmarking Inference tresnet_l \n",
      "pass tresnet_l\n",
      "Benchmarking Inference twins_svt_small \n",
      "twins_svt_small model average inference time : 10.310540199279785ms\n",
      "Benchmarking Inference levit_256 \n",
      "levit_256 model average inference time : 7.933638095855713ms\n",
      "Benchmarking Inference seresnext50_32x4d \n",
      "seresnext50_32x4d model average inference time : 10.537798404693604ms\n",
      "Benchmarking Inference pit_b_224 \n",
      "pit_b_224 model average inference time : 8.083999156951904ms\n",
      "Benchmarking Inference swin_tiny_patch4_window7_224 \n",
      "swin_tiny_patch4_window7_224 model average inference time : 7.519328594207764ms\n",
      "Benchmarking Inference wide_resnet50_2 \n",
      "wide_resnet50_2 model average inference time : 11.235213279724121ms\n",
      "Benchmarking Inference twins_pcpvt_small \n",
      "twins_pcpvt_small model average inference time : 10.131669044494629ms\n",
      "Benchmarking Inference resmlp_24_distilled_224 \n",
      "resmlp_24_distilled_224 model average inference time : 6.0874199867248535ms\n",
      "Benchmarking Inference resnest50d_4s2x40d \n",
      "resnest50d_4s2x40d model average inference time : 22.870047092437744ms\n",
      "Benchmarking Inference repvgg_b3 \n",
      "repvgg_b3 model average inference time : 19.00216579437256ms\n",
      "Benchmarking Inference xcit_tiny_24_p16_224_dist \n",
      "xcit_tiny_24_p16_224_dist model average inference time : 19.405126571655273ms\n",
      "Benchmarking Inference ecaresnet50d \n",
      "ecaresnet50d model average inference time : 7.205207347869873ms\n",
      "Benchmarking Inference ssl_resnext101_32x4d \n",
      "ssl_resnext101_32x4d model average inference time : 12.962768077850342ms\n",
      "Benchmarking Inference gluon_resnet152_v1s \n",
      "gluon_resnet152_v1s model average inference time : 14.70705509185791ms\n",
      "Benchmarking Inference haloregnetz_b \n",
      "haloregnetz_b model average inference time : 13.94322156906128ms\n",
      "Benchmarking Inference resnest50d_1s4x24d \n",
      "resnest50d_1s4x24d model average inference time : 14.099588394165039ms\n",
      "Benchmarking Inference repvgg_b3g4 \n",
      "repvgg_b3g4 model average inference time : 21.578655242919922ms\n",
      "Benchmarking Inference legacy_senet154 \n",
      "legacy_senet154 model average inference time : 35.050692558288574ms\n",
      "Benchmarking Inference gernet_m \n",
      "gernet_m model average inference time : 4.982576370239258ms\n",
      "Benchmarking Inference cait_xxs36_224 \n",
      "cait_xxs36_224 model average inference time : 20.291597843170166ms\n",
      "Benchmarking Inference pit_s_224 \n",
      "pit_s_224 model average inference time : 5.699214935302734ms\n",
      "Benchmarking Inference gluon_senet154 \n",
      "gluon_senet154 model average inference time : 35.667269229888916ms\n",
      "Benchmarking Inference resnest50d \n",
      "resnest50d model average inference time : 13.990790843963623ms\n",
      "Benchmarking Inference convmixer_768_32 \n",
      "pass convmixer_768_32\n",
      "Benchmarking Inference ecaresnet101d_pruned \n",
      "ecaresnet101d_pruned model average inference time : 11.902644634246826ms\n",
      "Benchmarking Inference rexnet_150 \n",
      "rexnet_150 model average inference time : 8.516361713409424ms\n",
      "Benchmarking Inference xcit_tiny_12_p8_224 \n",
      "xcit_tiny_12_p8_224 model average inference time : 10.543198585510254ms\n",
      "Benchmarking Inference ssl_resnext50_32x4d \n",
      "ssl_resnext50_32x4d model average inference time : 6.872310638427734ms\n",
      "Benchmarking Inference ecaresnetlight \n",
      "ecaresnetlight model average inference time : 7.006616592407227ms\n",
      "Benchmarking Inference gluon_resnet101_v1s \n",
      "gluon_resnet101_v1s model average inference time : 10.721702575683594ms\n",
      "Benchmarking Inference resnetv2_50 \n",
      "resnetv2_50 model average inference time : 5.681214332580566ms\n",
      "Benchmarking Inference gluon_seresnext101_32x4d \n",
      "gluon_seresnext101_32x4d model average inference time : 20.829873085021973ms\n",
      "Benchmarking Inference resnet50d \n",
      "resnet50d model average inference time : 6.009654998779297ms\n",
      "Benchmarking Inference vit_base_patch32_224 \n",
      "vit_base_patch32_224 model average inference time : 5.190515518188477ms\n",
      "Benchmarking Inference gluon_seresnext101_64x4d \n",
      "gluon_seresnext101_64x4d model average inference time : 23.46662998199463ms\n",
      "Benchmarking Inference gluon_resnet152_v1d \n",
      "gluon_resnet152_v1d model average inference time : 14.824655055999756ms\n",
      "Benchmarking Inference vit_base_patch16_sam_224 \n",
      "vit_base_patch16_sam_224 model average inference time : 7.050213813781738ms\n",
      "Benchmarking Inference repvgg_b2g4 \n",
      "repvgg_b2g4 model average inference time : 19.92868661880493ms\n",
      "Benchmarking Inference seresnet50 \n",
      "seresnet50 model average inference time : 9.327127933502197ms\n",
      "Benchmarking Inference gluon_resnet101_v1d \n",
      "gluon_resnet101_v1d model average inference time : 10.482888221740723ms\n",
      "Benchmarking Inference mixnet_xl \n",
      "mixnet_xl model average inference time : 15.067610740661621ms\n",
      "Benchmarking Inference cspresnext50 \n",
      "cspresnext50 model average inference time : 6.738874912261963ms\n",
      "Benchmarking Inference gluon_resnext101_32x4d \n",
      "gluon_resnext101_32x4d model average inference time : 12.563707828521729ms\n",
      "Benchmarking Inference ese_vovnet39b \n",
      "ese_vovnet39b model average inference time : 6.843414306640625ms\n",
      "Benchmarking Inference legacy_seresnext101_32x4d \n",
      "legacy_seresnext101_32x4d model average inference time : 20.458691120147705ms\n",
      "Benchmarking Inference xcit_tiny_24_p16_224 \n",
      "xcit_tiny_24_p16_224 model average inference time : 18.694677352905273ms\n",
      "Benchmarking Inference regnety_320 \n",
      "regnety_320 model average inference time : 36.93737506866455ms\n",
      "Benchmarking Inference resnet50 \n",
      "resnet50 model average inference time : 5.8392333984375ms\n",
      "Benchmarking Inference gluon_resnext101_64x4d \n",
      "gluon_resnext101_64x4d model average inference time : 19.55361843109131ms\n",
      "Benchmarking Inference resmlp_big_24_224 \n",
      "resmlp_big_24_224 model average inference time : 34.003565311431885ms\n",
      "Benchmarking Inference deit_small_patch16_224 \n",
      "deit_small_patch16_224 model average inference time : 5.30376672744751ms\n",
      "Benchmarking Inference dpn107 \n",
      "dpn107 model average inference time : 25.07070302963257ms\n",
      "Benchmarking Inference pit_xs_distilled_224 \n",
      "pit_xs_distilled_224 model average inference time : 5.718038082122803ms\n",
      "Benchmarking Inference resmlp_36_224 \n",
      "resmlp_36_224 model average inference time : 8.562207221984863ms\n",
      "Benchmarking Inference levit_192 \n",
      "levit_192 model average inference time : 7.820937633514404ms\n",
      "Benchmarking Inference gluon_resnet152_v1c \n",
      "gluon_resnet152_v1c model average inference time : 14.790723323822021ms\n",
      "Benchmarking Inference ecaresnet50d_pruned \n",
      "ecaresnet50d_pruned model average inference time : 6.682915687561035ms\n",
      "Benchmarking Inference resnext50d_32x4d \n",
      "resnext50d_32x4d model average inference time : 7.0255208015441895ms\n",
      "Benchmarking Inference regnety_120 \n",
      "regnety_120 model average inference time : 23.444221019744873ms\n",
      "Benchmarking Inference regnetx_320 \n",
      "regnetx_320 model average inference time : 36.329240798950195ms\n",
      "Benchmarking Inference dpn92 \n",
      "dpn92 model average inference time : 12.439408302307129ms\n",
      "Benchmarking Inference rexnet_130 \n",
      "rexnet_130 model average inference time : 8.482873439788818ms\n",
      "Benchmarking Inference gluon_resnet152_v1b \n",
      "gluon_resnet152_v1b model average inference time : 14.631612300872803ms\n",
      "Benchmarking Inference resnetrs50 \n",
      "resnetrs50 model average inference time : 9.213309288024902ms\n",
      "Benchmarking Inference dpn131 \n",
      "dpn131 model average inference time : 22.95206308364868ms\n",
      "Benchmarking Inference dla102x2 \n",
      "dla102x2 model average inference time : 15.781023502349854ms\n",
      "Benchmarking Inference regnetx_160 \n",
      "regnetx_160 model average inference time : 26.581060886383057ms\n",
      "Benchmarking Inference gmlp_s16_224 \n",
      "gmlp_s16_224 model average inference time : 7.8601789474487305ms\n",
      "Benchmarking Inference gluon_seresnext50_32x4d \n",
      "gluon_seresnext50_32x4d model average inference time : 10.296087265014648ms\n",
      "Benchmarking Inference skresnext50_32x4d \n",
      "skresnext50_32x4d model average inference time : 14.00026798248291ms\n",
      "Benchmarking Inference gluon_resnet101_v1c \n",
      "gluon_resnet101_v1c model average inference time : 10.544290542602539ms\n",
      "Benchmarking Inference dpn98 \n",
      "dpn98 model average inference time : 16.838343143463135ms\n",
      "Benchmarking Inference regnety_064 \n",
      "regnety_064 model average inference time : 15.869503021240234ms\n",
      "Benchmarking Inference dpn68b \n",
      "dpn68b model average inference time : 10.606613159179688ms\n",
      "Benchmarking Inference resnetblur50 \n",
      "resnetblur50 model average inference time : 5.8940863609313965ms\n",
      "Benchmarking Inference resmlp_24_224 \n",
      "resmlp_24_224 model average inference time : 6.166572570800781ms\n",
      "Benchmarking Inference coat_lite_mini \n",
      "coat_lite_mini model average inference time : 7.513597011566162ms\n",
      "Benchmarking Inference resnext50_32x4d \n",
      "resnext50_32x4d model average inference time : 6.959478855133057ms\n",
      "Benchmarking Inference regnety_080 \n",
      "regnety_080 model average inference time : 14.425852298736572ms\n",
      "Benchmarking Inference cait_xxs24_224 \n",
      "cait_xxs24_224 model average inference time : 14.630074501037598ms\n",
      "Benchmarking Inference xcit_tiny_12_p16_224_dist \n",
      "xcit_tiny_12_p16_224_dist model average inference time : 10.864458084106445ms\n",
      "Benchmarking Inference resnext101_32x8d \n",
      "resnext101_32x8d model average inference time : 19.254169464111328ms\n",
      "Benchmarking Inference hrnet_w48 \n",
      "hrnet_w48 model average inference time : 34.230711460113525ms\n",
      "Benchmarking Inference regnetx_120 \n",
      "regnetx_120 model average inference time : 21.44188404083252ms\n",
      "Benchmarking Inference gluon_resnet101_v1b \n",
      "gluon_resnet101_v1b model average inference time : 9.984734058380127ms\n",
      "Benchmarking Inference hrnet_w64 \n",
      "hrnet_w64 model average inference time : 33.04595232009888ms\n",
      "Benchmarking Inference ssl_resnet50 \n",
      "ssl_resnet50 model average inference time : 5.827453136444092ms\n",
      "Benchmarking Inference res2net101_26w_4s \n",
      "res2net101_26w_4s model average inference time : 17.982370853424072ms\n",
      "Benchmarking Inference gluon_resnext50_32x4d \n",
      "gluon_resnext50_32x4d model average inference time : 6.866660118103027ms\n",
      "Benchmarking Inference tf_efficientnet_b0_ns \n",
      "tf_efficientnet_b0_ns model average inference time : 7.480754852294922ms\n",
      "Benchmarking Inference resnest26d \n",
      "resnest26d model average inference time : 9.21252727508545ms\n",
      "Benchmarking Inference coat_tiny \n",
      "coat_tiny model average inference time : 22.003560066223145ms\n",
      "Benchmarking Inference regnety_040 \n",
      "regnety_040 model average inference time : 12.508735656738281ms\n",
      "Benchmarking Inference dla169 \n",
      "dla169 model average inference time : 16.491498947143555ms\n",
      "Benchmarking Inference legacy_seresnext50_32x4d \n",
      "legacy_seresnext50_32x4d model average inference time : 9.978797435760498ms\n",
      "Benchmarking Inference hrnet_w44 \n",
      "hrnet_w44 model average inference time : 34.55578088760376ms\n",
      "Benchmarking Inference regnetx_080 \n",
      "regnetx_080 model average inference time : 16.284196376800537ms\n",
      "Benchmarking Inference gluon_resnet50_v1s \n",
      "gluon_resnet50_v1s model average inference time : 6.026053428649902ms\n",
      "Benchmarking Inference res2net50_26w_8s \n",
      "res2net50_26w_8s model average inference time : 16.22917652130127ms\n",
      "Benchmarking Inference dla60_res2next \n",
      "dla60_res2next model average inference time : 16.423168182373047ms\n",
      "Benchmarking Inference mixnet_l \n",
      "mixnet_l model average inference time : 11.95857048034668ms\n",
      "Benchmarking Inference levit_128 \n",
      "levit_128 model average inference time : 7.7445220947265625ms\n",
      "Benchmarking Inference dla60_res2net \n",
      "dla60_res2net model average inference time : 10.492653846740723ms\n",
      "Benchmarking Inference tv_resnet152 \n",
      "tv_resnet152 model average inference time : 14.771018028259277ms\n",
      "Benchmarking Inference dla102x \n",
      "dla102x model average inference time : 12.74256944656372ms\n",
      "Benchmarking Inference gluon_resnet50_v1d \n",
      "gluon_resnet50_v1d model average inference time : 5.942518711090088ms\n",
      "Benchmarking Inference regnetx_064 \n",
      "regnetx_064 model average inference time : 10.907056331634521ms\n",
      "Benchmarking Inference pit_xs_224 \n",
      "pit_xs_224 model average inference time : 5.417320728302002ms\n",
      "Benchmarking Inference hrnet_w40 \n",
      "hrnet_w40 model average inference time : 31.760694980621338ms\n",
      "Benchmarking Inference repvgg_b2 \n",
      "repvgg_b2 model average inference time : 13.380820751190186ms\n",
      "Benchmarking Inference res2net50_26w_6s \n",
      "res2net50_26w_6s model average inference time : 13.04659128189087ms\n",
      "Benchmarking Inference resmlp_12_distilled_224 \n",
      "resmlp_12_distilled_224 model average inference time : 3.3237171173095703ms\n",
      "Benchmarking Inference legacy_seresnet152 \n",
      "legacy_seresnet152 model average inference time : 26.403536796569824ms\n",
      "Benchmarking Inference selecsls60b \n",
      "selecsls60b model average inference time : 6.648528575897217ms\n",
      "Benchmarking Inference hrnet_w32 \n",
      "hrnet_w32 model average inference time : 31.174631118774414ms\n",
      "Benchmarking Inference tf_efficientnetv2_b0 \n",
      "tf_efficientnetv2_b0 model average inference time : 9.105782508850098ms\n",
      "Benchmarking Inference regnetx_040 \n",
      "regnetx_040 model average inference time : 9.47070598602295ms\n",
      "Benchmarking Inference hrnet_w30 \n",
      "hrnet_w30 model average inference time : 32.16704845428467ms\n",
      "Benchmarking Inference efficientnet_es \n",
      "efficientnet_es model average inference time : 4.538414478302002ms\n",
      "Benchmarking Inference tf_mixnet_l \n",
      "tf_mixnet_l model average inference time : 12.606806755065918ms\n",
      "Benchmarking Inference wide_resnet101_2 \n",
      "wide_resnet101_2 model average inference time : 18.493614196777344ms\n",
      "Benchmarking Inference dla60x \n",
      "dla60x model average inference time : 7.526495456695557ms\n",
      "Benchmarking Inference legacy_seresnet101 \n",
      "legacy_seresnet101 model average inference time : 17.574009895324707ms\n",
      "Benchmarking Inference coat_lite_tiny \n",
      "coat_lite_tiny model average inference time : 7.392082214355469ms\n",
      "Benchmarking Inference repvgg_b1 \n",
      "repvgg_b1 model average inference time : 10.306687355041504ms\n",
      "Benchmarking Inference res2net50_26w_4s \n",
      "res2net50_26w_4s model average inference time : 9.69325304031372ms\n",
      "Benchmarking Inference hardcorenas_f \n",
      "hardcorenas_f model average inference time : 7.530560493469238ms\n",
      "Benchmarking Inference res2net50_14w_8s \n",
      "res2net50_14w_8s model average inference time : 15.195362567901611ms\n",
      "Benchmarking Inference selecsls60 \n",
      "selecsls60 model average inference time : 6.841988563537598ms\n",
      "Benchmarking Inference res2next50 \n",
      "res2next50 model average inference time : 16.007883548736572ms\n",
      "Benchmarking Inference regnetx_032 \n",
      "regnetx_032 model average inference time : 9.208292961120605ms\n",
      "Benchmarking Inference gluon_resnet50_v1c \n",
      "gluon_resnet50_v1c model average inference time : 6.052649021148682ms\n",
      "Benchmarking Inference dla102 \n",
      "dla102 model average inference time : 10.941462516784668ms\n",
      "Benchmarking Inference rexnet_100 \n",
      "rexnet_100 model average inference time : 8.449954986572266ms\n",
      "Benchmarking Inference res2net50_48w_2s \n",
      "res2net50_48w_2s model average inference time : 6.536848545074463ms\n",
      "Benchmarking Inference resnet34d \n",
      "resnet34d model average inference time : 4.470558166503906ms\n",
      "Benchmarking Inference xcit_tiny_12_p16_224 \n",
      "xcit_tiny_12_p16_224 model average inference time : 10.63784122467041ms\n",
      "Benchmarking Inference efficientnet_b0 \n",
      "efficientnet_b0 model average inference time : 7.568955421447754ms\n",
      "Benchmarking Inference hardcorenas_e \n",
      "hardcorenas_e model average inference time : 7.396128177642822ms\n",
      "Benchmarking Inference gmixer_24_224 \n",
      "gmixer_24_224 model average inference time : 8.387062549591064ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b0_8e \n",
      "tf_efficientnet_cc_b0_8e model average inference time : 9.599294662475586ms\n",
      "Benchmarking Inference regnety_016 \n",
      "regnety_016 model average inference time : 13.486073017120361ms\n",
      "Benchmarking Inference tv_resnext50_32x4d \n",
      "tv_resnext50_32x4d model average inference time : 6.946098804473877ms\n",
      "Benchmarking Inference gluon_resnet50_v1b \n",
      "gluon_resnet50_v1b model average inference time : 5.7448625564575195ms\n",
      "Benchmarking Inference densenet161 \n",
      "densenet161 model average inference time : 18.091626167297363ms\n",
      "Benchmarking Inference seresnext26t_32x4d \n",
      "seresnext26t_32x4d model average inference time : 5.766298770904541ms\n",
      "Benchmarking Inference mobilenetv2_120d \n",
      "mobilenetv2_120d model average inference time : 6.469125747680664ms\n",
      "Benchmarking Inference tv_resnet101 \n",
      "tv_resnet101 model average inference time : 10.18514633178711ms\n",
      "Benchmarking Inference hardcorenas_d \n",
      "hardcorenas_d model average inference time : 7.6528215408325195ms\n",
      "Benchmarking Inference dla60 \n",
      "dla60 model average inference time : 6.767768859863281ms\n",
      "Benchmarking Inference xcit_nano_12_p8_224_dist \n",
      "xcit_nano_12_p8_224_dist model average inference time : 10.852313041687012ms\n",
      "Benchmarking Inference seresnext26d_32x4d \n",
      "seresnext26d_32x4d model average inference time : 5.781450271606445ms\n",
      "Benchmarking Inference repvgg_b1g4 \n",
      "repvgg_b1g4 model average inference time : 15.741524696350098ms\n",
      "Benchmarking Inference convmixer_1024_20_ks9_p14 \n",
      "pass convmixer_1024_20_ks9_p14\n",
      "Benchmarking Inference legacy_seresnet50 \n",
      "legacy_seresnet50 model average inference time : 9.04362678527832ms\n",
      "Benchmarking Inference tf_efficientnet_b0_ap \n",
      "tf_efficientnet_b0_ap model average inference time : 7.821083068847656ms\n",
      "Benchmarking Inference skresnet34 \n",
      "skresnet34 model average inference time : 11.947510242462158ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b0_4e \n",
      "tf_efficientnet_cc_b0_4e model average inference time : 9.393877983093262ms\n",
      "Benchmarking Inference resmlp_12_224 \n",
      "resmlp_12_224 model average inference time : 3.5558176040649414ms\n",
      "Benchmarking Inference mobilenetv3_large_100_miil \n",
      "mobilenetv3_large_100_miil model average inference time : 5.717058181762695ms\n",
      "Benchmarking Inference densenet201 \n",
      "densenet201 model average inference time : 22.792253494262695ms\n",
      "Benchmarking Inference gernet_s \n",
      "gernet_s model average inference time : 4.975404739379883ms\n",
      "Benchmarking Inference legacy_seresnext26_32x4d \n",
      "legacy_seresnext26_32x4d model average inference time : 5.526425838470459ms\n",
      "Benchmarking Inference mixnet_m \n",
      "mixnet_m model average inference time : 12.208683490753174ms\n",
      "Benchmarking Inference tf_efficientnet_b0 \n",
      "tf_efficientnet_b0 model average inference time : 7.39795446395874ms\n",
      "Benchmarking Inference hrnet_w18 \n",
      "hrnet_w18 model average inference time : 30.66802978515625ms\n",
      "Benchmarking Inference densenetblur121d \n",
      "densenetblur121d model average inference time : 13.869426250457764ms\n",
      "Benchmarking Inference selecsls42b \n",
      "selecsls42b model average inference time : 5.463900566101074ms\n",
      "Benchmarking Inference hardcorenas_c \n",
      "hardcorenas_c model average inference time : 5.89510440826416ms\n",
      "Benchmarking Inference regnetx_016 \n",
      "regnetx_016 model average inference time : 7.057490348815918ms\n",
      "Benchmarking Inference mobilenetv2_140 \n",
      "mobilenetv2_140 model average inference time : 4.270687103271484ms\n",
      "Benchmarking Inference tf_mixnet_m \n",
      "tf_mixnet_m model average inference time : 12.038166522979736ms\n",
      "Benchmarking Inference dpn68 \n",
      "dpn68 model average inference time : 9.72515344619751ms\n",
      "Benchmarking Inference tf_efficientnet_es \n",
      "tf_efficientnet_es model average inference time : 4.743032455444336ms\n",
      "Benchmarking Inference ese_vovnet19b_dw \n",
      "ese_vovnet19b_dw model average inference time : 4.022977352142334ms\n",
      "Benchmarking Inference levit_128s \n",
      "levit_128s model average inference time : 6.251623630523682ms\n",
      "Benchmarking Inference resnet26d \n",
      "resnet26d model average inference time : 3.824455738067627ms\n",
      "Benchmarking Inference repvgg_a2 \n",
      "repvgg_a2 model average inference time : 5.800914764404297ms\n",
      "Benchmarking Inference tv_resnet50 \n",
      "tv_resnet50 model average inference time : 5.629220008850098ms\n",
      "Benchmarking Inference hardcorenas_b \n",
      "hardcorenas_b model average inference time : 5.557959079742432ms\n",
      "Benchmarking Inference densenet121 \n",
      "densenet121 model average inference time : 13.61299991607666ms\n",
      "Benchmarking Inference densenet169 \n",
      "densenet169 model average inference time : 18.831112384796143ms\n",
      "Benchmarking Inference mixnet_s \n",
      "mixnet_s model average inference time : 9.757490158081055ms\n",
      "Benchmarking Inference vit_small_patch32_224 \n",
      "vit_small_patch32_224 model average inference time : 5.096225738525391ms\n",
      "Benchmarking Inference regnety_008 \n",
      "regnety_008 model average inference time : 7.901732921600342ms\n",
      "Benchmarking Inference efficientnet_lite0 \n",
      "efficientnet_lite0 model average inference time : 4.191188812255859ms\n",
      "Benchmarking Inference resnest14d \n",
      "resnest14d model average inference time : 6.851811408996582ms\n",
      "Benchmarking Inference hardcorenas_a \n",
      "hardcorenas_a model average inference time : 4.8409199714660645ms\n",
      "Benchmarking Inference efficientnet_es_pruned \n",
      "efficientnet_es_pruned model average inference time : 4.648795127868652ms\n",
      "Benchmarking Inference mobilenetv3_rw \n",
      "mobilenetv3_rw model average inference time : 5.667610168457031ms\n",
      "Benchmarking Inference semnasnet_100 \n",
      "semnasnet_100 model average inference time : 5.82747220993042ms\n",
      "Benchmarking Inference mobilenetv3_large_100 \n",
      "mobilenetv3_large_100 model average inference time : 5.91533899307251ms\n",
      "Benchmarking Inference resnet34 \n",
      "resnet34 model average inference time : 4.090702533721924ms\n",
      "Benchmarking Inference mobilenetv2_110d \n",
      "mobilenetv2_110d model average inference time : 5.3720855712890625ms\n",
      "Benchmarking Inference vit_tiny_patch16_224 \n",
      "vit_tiny_patch16_224 model average inference time : 5.227022171020508ms\n",
      "Benchmarking Inference tf_mixnet_s \n",
      "tf_mixnet_s model average inference time : 10.010137557983398ms\n",
      "Benchmarking Inference repvgg_b0 \n",
      "repvgg_b0 model average inference time : 6.675727367401123ms\n",
      "Benchmarking Inference deit_tiny_distilled_patch16_224 \n",
      "deit_tiny_distilled_patch16_224 model average inference time : 5.460071563720703ms\n",
      "Benchmarking Inference mixer_b16_224 \n",
      "mixer_b16_224 model average inference time : 5.086991786956787ms\n",
      "Benchmarking Inference pit_ti_distilled_224 \n",
      "pit_ti_distilled_224 model average inference time : 5.3986382484436035ms\n",
      "Benchmarking Inference hrnet_w18_small_v2 \n",
      "hrnet_w18_small_v2 model average inference time : 16.57296895980835ms\n",
      "Benchmarking Inference tf_efficientnet_lite0 \n",
      "tf_efficientnet_lite0 model average inference time : 4.450747966766357ms\n",
      "Benchmarking Inference resnet26 \n",
      "resnet26 model average inference time : 3.575725555419922ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_100 \n",
      "tf_mobilenetv3_large_100 model average inference time : 5.966911315917969ms\n",
      "Benchmarking Inference tv_densenet121 \n",
      "tv_densenet121 model average inference time : 13.520746231079102ms\n",
      "Benchmarking Inference regnety_006 \n",
      "regnety_006 model average inference time : 8.412299156188965ms\n",
      "Benchmarking Inference dla34 \n",
      "dla34 model average inference time : 4.329702854156494ms\n",
      "Benchmarking Inference xcit_nano_12_p8_224 \n",
      "xcit_nano_12_p8_224 model average inference time : 10.801050662994385ms\n",
      "Benchmarking Inference fbnetc_100 \n",
      "fbnetc_100 model average inference time : 5.238170623779297ms\n",
      "Benchmarking Inference legacy_seresnet34 \n",
      "legacy_seresnet34 model average inference time : 7.046689987182617ms\n",
      "Benchmarking Inference regnetx_008 \n",
      "regnetx_008 model average inference time : 5.828697681427002ms\n",
      "Benchmarking Inference gluon_resnet34_v1b \n",
      "gluon_resnet34_v1b model average inference time : 4.112353324890137ms\n",
      "Benchmarking Inference mnasnet_100 \n",
      "mnasnet_100 model average inference time : 4.512279033660889ms\n",
      "Benchmarking Inference vgg19_bn \n",
      "vgg19_bn model average inference time : 12.25665807723999ms\n",
      "Benchmarking Inference convit_tiny \n",
      "convit_tiny model average inference time : 6.963202953338623ms\n",
      "Benchmarking Inference spnasnet_100 \n",
      "spnasnet_100 model average inference time : 5.339231491088867ms\n",
      "Benchmarking Inference ghostnet_100 \n",
      "ghostnet_100 model average inference time : 8.784103393554688ms\n",
      "Benchmarking Inference regnety_004 \n",
      "regnety_004 model average inference time : 9.942929744720459ms\n",
      "Benchmarking Inference skresnet18 \n",
      "skresnet18 model average inference time : 6.443450450897217ms\n",
      "Benchmarking Inference regnetx_006 \n",
      "regnetx_006 model average inference time : 5.590357780456543ms\n",
      "Benchmarking Inference pit_ti_224 \n",
      "pit_ti_224 model average inference time : 5.664281845092773ms\n",
      "Benchmarking Inference swsl_resnet18 \n",
      "swsl_resnet18 model average inference time : 2.8646159172058105ms\n",
      "Benchmarking Inference vgg16_bn \n",
      "vgg16_bn model average inference time : 10.735476016998291ms\n",
      "Benchmarking Inference resnet18d \n",
      "resnet18d model average inference time : 3.0302071571350098ms\n",
      "Benchmarking Inference tv_resnet34 \n",
      "tv_resnet34 model average inference time : 4.167530536651611ms\n",
      "Benchmarking Inference mobilenetv2_100 \n",
      "mobilenetv2_100 model average inference time : 4.245607852935791ms\n",
      "Benchmarking Inference xcit_nano_12_p16_224_dist \n",
      "xcit_nano_12_p16_224_dist model average inference time : 10.799438953399658ms\n",
      "Benchmarking Inference vit_base_patch32_sam_224 \n",
      "vit_base_patch32_sam_224 model average inference time : 5.403764247894287ms\n",
      "Benchmarking Inference ssl_resnet18 \n",
      "ssl_resnet18 model average inference time : 2.6334023475646973ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_075 \n",
      "tf_mobilenetv3_large_075 model average inference time : 5.989499092102051ms\n",
      "Benchmarking Inference deit_tiny_patch16_224 \n",
      "deit_tiny_patch16_224 model average inference time : 5.194070339202881ms\n",
      "Benchmarking Inference hrnet_w18_small \n",
      "hrnet_w18_small model average inference time : 9.595694541931152ms\n",
      "Benchmarking Inference vgg19 \n",
      "vgg19 model average inference time : 11.495828628540039ms\n",
      "Benchmarking Inference regnetx_004 \n",
      "regnetx_004 model average inference time : 8.82101058959961ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_minimal_100 \n",
      "tf_mobilenetv3_large_minimal_100 model average inference time : 4.257955551147461ms\n",
      "Benchmarking Inference legacy_seresnet18 \n",
      "legacy_seresnet18 model average inference time : 4.220445156097412ms\n",
      "Benchmarking Inference vgg16 \n",
      "vgg16 model average inference time : 9.98368501663208ms\n",
      "Benchmarking Inference vit_tiny_r_s16_p8_224 \n",
      "vit_tiny_r_s16_p8_224 model average inference time : 5.392265319824219ms\n",
      "Benchmarking Inference vgg13_bn \n",
      "vgg13_bn model average inference time : 9.115087985992432ms\n",
      "Benchmarking Inference gluon_resnet18_v1b \n",
      "gluon_resnet18_v1b model average inference time : 2.794067859649658ms\n",
      "Benchmarking Inference vgg11_bn \n",
      "vgg11_bn model average inference time : 7.375471591949463ms\n",
      "Benchmarking Inference xcit_nano_12_p16_224 \n",
      "xcit_nano_12_p16_224 model average inference time : 10.941822528839111ms\n",
      "Benchmarking Inference regnety_002 \n",
      "regnety_002 model average inference time : 8.2291841506958ms\n",
      "Benchmarking Inference mixer_l16_224 \n",
      "mixer_l16_224 model average inference time : 15.571436882019043ms\n",
      "Benchmarking Inference resnet18 \n",
      "resnet18 model average inference time : 2.7054572105407715ms\n",
      "Benchmarking Inference vgg13 \n",
      "vgg13 model average inference time : 8.459031581878662ms\n",
      "Benchmarking Inference vgg11 \n",
      "vgg11 model average inference time : 7.024950981140137ms\n",
      "Benchmarking Inference regnetx_002 \n",
      "regnetx_002 model average inference time : 5.828824043273926ms\n",
      "Benchmarking Inference dla60x_c \n",
      "dla60x_c model average inference time : 5.9967803955078125ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_100 \n",
      "tf_mobilenetv3_small_100 model average inference time : 5.031616687774658ms\n",
      "Benchmarking Inference dla46x_c \n",
      "dla46x_c model average inference time : 4.911093711853027ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_075 \n",
      "tf_mobilenetv3_small_075 model average inference time : 5.292332172393799ms\n",
      "Benchmarking Inference dla46_c \n",
      "dla46_c model average inference time : 5.090696811676025ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_minimal_100 \n",
      "tf_mobilenetv3_small_minimal_100 model average inference time : 3.612961769104004ms\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beit_large_patch16_224': {'fp32': 21.222758293151855, 'top1': 90.157},\n",
       " 'swin_large_patch4_window7_224': {'fp32': 17.0994234085083, 'top1': 89.796},\n",
       " 'xcit_large_24_p8_224_dist': {'fp32': 66.53245449066162, 'top1': 89.519},\n",
       " 'beit_base_patch16_224': {'fp32': 7.464489936828613, 'top1': 89.438},\n",
       " 'vit_large_patch16_224': {'fp32': 20.04459857940674, 'top1': 89.308},\n",
       " 'xcit_medium_24_p8_224_dist': {'fp32': 40.78274726867676, 'top1': 89.286},\n",
       " 'xcit_small_24_p8_224_dist': {'fp32': 29.373767375946045, 'top1': 89.207},\n",
       " 'swin_base_patch4_window7_224': {'fp32': 12.806141376495361, 'top1': 89.19},\n",
       " 'ig_resnext101_32x32d': {'fp32': 132.56885290145874, 'top1': 89.109},\n",
       " 'ig_resnext101_32x48d': {'fp32': 210.10546445846558, 'top1': 89.107},\n",
       " 'xcit_large_24_p16_224_dist': {'fp32': 19.736363887786865, 'top1': 89.045},\n",
       " 'resmlp_big_24_224_in22ft1k': {'fp32': 33.9638614654541, 'top1': 89.019},\n",
       " 'xcit_small_12_p8_224_dist': {'fp32': 16.07722043991089, 'top1': 89.007},\n",
       " 'vit_base_patch16_224': {'fp32': 7.092115879058838, 'top1': 88.857},\n",
       " 'xcit_medium_24_p16_224_dist': {'fp32': 19.059040546417236, 'top1': 88.806},\n",
       " 'ig_resnext101_32x16d': {'fp32': 35.41270971298218, 'top1': 88.804},\n",
       " 'swsl_resnext101_32x8d': {'fp32': 19.28312063217163, 'top1': 88.757},\n",
       " 'vit_base_patch16_224_miil': {'fp32': 6.86307430267334, 'top1': 88.748},\n",
       " 'pit_b_distilled_224': {'fp32': 8.121466636657715, 'top1': 88.678},\n",
       " 'xcit_small_24_p16_224_dist': {'fp32': 18.69269609451294, 'top1': 88.535},\n",
       " 'cait_s24_224': {'fp32': 14.812660217285156, 'top1': 88.451},\n",
       " 'resmlp_big_24_distilled_224': {'fp32': 33.96995306015015, 'top1': 88.447},\n",
       " 'vit_large_r50_s32_224': {'fp32': 16.82636022567749, 'top1': 88.424},\n",
       " 'xcit_small_12_p16_224_dist': {'fp32': 10.687386989593506, 'top1': 88.251},\n",
       " 'deit_base_distilled_patch16_224': {'fp32': 7.080423831939697,\n",
       "  'top1': 88.217},\n",
       " 'ig_resnext101_32x8d': {'fp32': 19.176130294799805, 'top1': 88.161},\n",
       " 'xcit_large_24_p8_224': {'fp32': 68.2600736618042, 'top1': 88.161},\n",
       " 'swsl_resnext101_32x4d': {'fp32': 12.613909244537354, 'top1': 88.086},\n",
       " 'xcit_tiny_24_p8_224_dist': {'fp32': 18.30082416534424, 'top1': 88.048},\n",
       " 'xcit_small_24_p8_224': {'fp32': 29.7322678565979, 'top1': 87.975},\n",
       " 'twins_svt_large': {'fp32': 14.635822772979736, 'top1': 87.907},\n",
       " 'twins_pcpvt_large': {'fp32': 24.414920806884766, 'top1': 87.879},\n",
       " 'xcit_small_12_p8_224': {'fp32': 16.07599973678589, 'top1': 87.832},\n",
       " 'resnetv2_50x1_bit_distilled': {'fp32': 8.04631233215332, 'top1': 87.802},\n",
       " 'twins_pcpvt_base': {'fp32': 16.830954551696777, 'top1': 87.728},\n",
       " 'swin_small_patch4_window7_224': {'fp32': 13.139035701751709, 'top1': 87.678},\n",
       " 'twins_svt_base': {'fp32': 13.144330978393555, 'top1': 87.629},\n",
       " 'xcit_medium_24_p8_224': {'fp32': 41.48906946182251, 'top1': 87.619},\n",
       " 'jx_nest_base': {'fp32': 13.87157917022705, 'top1': 87.602},\n",
       " 'swsl_resnext101_32x16d': {'fp32': 35.50509452819824, 'top1': 87.595},\n",
       " 'swsl_resnext50_32x4d': {'fp32': 6.88831090927124, 'top1': 87.593},\n",
       " 'levit_384': {'fp32': 7.732181549072266, 'top1': 87.559},\n",
       " 'jx_nest_small': {'fp32': 10.803375244140625, 'top1': 87.495},\n",
       " 'resnetv2_152x2_bit_teacher': {'fp32': 46.50394678115845, 'top1': 87.491},\n",
       " 'xcit_tiny_24_p8_224': {'fp32': 18.08338165283203, 'top1': 87.375},\n",
       " 'coat_lite_small': {'fp32': 13.0839204788208, 'top1': 87.365},\n",
       " 'resnetv2_101': {'fp32': 10.269548892974854, 'top1': 87.296},\n",
       " 'ecaresnet101d': {'fp32': 13.389935493469238, 'top1': 87.281},\n",
       " 'pit_s_distilled_224': {'fp32': 5.669441223144531, 'top1': 87.264},\n",
       " 'mixer_b16_224_miil': {'fp32': 5.0153279304504395, 'top1': 87.23},\n",
       " 'xcit_tiny_12_p8_224_dist': {'fp32': 10.577220916748047, 'top1': 87.224},\n",
       " 'convit_base': {'fp32': 10.248382091522217, 'top1': 87.205},\n",
       " 'visformer_small': {'fp32': 12.276256084442139, 'top1': 87.185},\n",
       " 'xcit_small_24_p16_224': {'fp32': 18.592159748077393, 'top1': 87.136},\n",
       " 'convit_small': {'fp32': 7.061395645141602, 'top1': 87.044},\n",
       " 'jx_nest_tiny': {'fp32': 7.174441814422607, 'top1': 87.014},\n",
       " 'xcit_small_12_p16_224': {'fp32': 10.355837345123291, 'top1': 87.0},\n",
       " 'deit_small_distilled_patch16_224': {'fp32': 5.395364761352539,\n",
       "  'top1': 86.993},\n",
       " 'resmlp_36_distilled_224': {'fp32': 8.569638729095459, 'top1': 86.987},\n",
       " 'xcit_large_24_p16_224': {'fp32': 19.858109951019287, 'top1': 86.961},\n",
       " 'xcit_medium_24_p16_224': {'fp32': 18.936972618103027, 'top1': 86.94},\n",
       " 'tnt_s_patch16_224': {'fp32': 11.9808030128479, 'top1': 86.901},\n",
       " 'rexnet_200': {'fp32': 8.933818340301514, 'top1': 86.854},\n",
       " 'vit_small_patch16_224': {'fp32': 5.296797752380371, 'top1': 86.852},\n",
       " 'ssl_resnext101_32x16d': {'fp32': 35.33586263656616, 'top1': 86.85},\n",
       " 'vit_small_r26_s32_224': {'fp32': 9.251573085784912, 'top1': 86.84},\n",
       " 'deit_base_patch16_224': {'fp32': 7.058782577514648, 'top1': 86.827},\n",
       " 'coat_mini': {'fp32': 22.302887439727783, 'top1': 86.81},\n",
       " 'swsl_resnet50': {'fp32': 5.740089416503906, 'top1': 86.801},\n",
       " 'ssl_resnext101_32x8d': {'fp32': 19.183614253997803, 'top1': 86.797},\n",
       " 'twins_svt_small': {'fp32': 10.310540199279785, 'top1': 86.754},\n",
       " 'levit_256': {'fp32': 7.933638095855713, 'top1': 86.733},\n",
       " 'seresnext50_32x4d': {'fp32': 10.537798404693604, 'top1': 86.705},\n",
       " 'pit_b_224': {'fp32': 8.083999156951904, 'top1': 86.69},\n",
       " 'swin_tiny_patch4_window7_224': {'fp32': 7.519328594207764, 'top1': 86.671},\n",
       " 'wide_resnet50_2': {'fp32': 11.235213279724121, 'top1': 86.647},\n",
       " 'twins_pcpvt_small': {'fp32': 10.131669044494629, 'top1': 86.609},\n",
       " 'resmlp_24_distilled_224': {'fp32': 6.0874199867248535, 'top1': 86.607},\n",
       " 'resnest50d_4s2x40d': {'fp32': 22.870047092437744, 'top1': 86.581},\n",
       " 'repvgg_b3': {'fp32': 19.00216579437256, 'top1': 86.57},\n",
       " 'xcit_tiny_24_p16_224_dist': {'fp32': 19.405126571655273, 'top1': 86.543},\n",
       " 'ecaresnet50d': {'fp32': 7.205207347869873, 'top1': 86.479},\n",
       " 'ssl_resnext101_32x4d': {'fp32': 12.962768077850342, 'top1': 86.474},\n",
       " 'gluon_resnet152_v1s': {'fp32': 14.70705509185791, 'top1': 86.453},\n",
       " 'haloregnetz_b': {'fp32': 13.94322156906128, 'top1': 86.449},\n",
       " 'resnest50d_1s4x24d': {'fp32': 14.099588394165039, 'top1': 86.44},\n",
       " 'repvgg_b3g4': {'fp32': 21.578655242919922, 'top1': 86.359},\n",
       " 'legacy_senet154': {'fp32': 35.050692558288574, 'top1': 86.334},\n",
       " 'gernet_m': {'fp32': 4.982576370239258, 'top1': 86.325},\n",
       " 'cait_xxs36_224': {'fp32': 20.291597843170166, 'top1': 86.321},\n",
       " 'pit_s_224': {'fp32': 5.699214935302734, 'top1': 86.319},\n",
       " 'gluon_senet154': {'fp32': 35.667269229888916, 'top1': 86.274},\n",
       " 'resnest50d': {'fp32': 13.990790843963623, 'top1': 86.231},\n",
       " 'ecaresnet101d_pruned': {'fp32': 11.902644634246826, 'top1': 86.182},\n",
       " 'rexnet_150': {'fp32': 8.516361713409424, 'top1': 86.165},\n",
       " 'xcit_tiny_12_p8_224': {'fp32': 10.543198585510254, 'top1': 86.118},\n",
       " 'ssl_resnext50_32x4d': {'fp32': 6.872310638427734, 'top1': 86.075},\n",
       " 'ecaresnetlight': {'fp32': 7.006616592407227, 'top1': 86.045},\n",
       " 'gluon_resnet101_v1s': {'fp32': 10.721702575683594, 'top1': 86.037},\n",
       " 'resnetv2_50': {'fp32': 5.681214332580566, 'top1': 86.02},\n",
       " 'gluon_seresnext101_32x4d': {'fp32': 20.829873085021973, 'top1': 86.007},\n",
       " 'resnet50d': {'fp32': 6.009654998779297, 'top1': 85.994},\n",
       " 'vit_base_patch32_224': {'fp32': 5.190515518188477, 'top1': 85.96},\n",
       " 'gluon_seresnext101_64x4d': {'fp32': 23.46662998199463, 'top1': 85.951},\n",
       " 'gluon_resnet152_v1d': {'fp32': 14.824655055999756, 'top1': 85.906},\n",
       " 'vit_base_patch16_sam_224': {'fp32': 7.050213813781738, 'top1': 85.879},\n",
       " 'repvgg_b2g4': {'fp32': 19.92868661880493, 'top1': 85.857},\n",
       " 'seresnet50': {'fp32': 9.327127933502197, 'top1': 85.83},\n",
       " 'gluon_resnet101_v1d': {'fp32': 10.482888221740723, 'top1': 85.827},\n",
       " 'mixnet_xl': {'fp32': 15.067610740661621, 'top1': 85.785},\n",
       " 'cspresnext50': {'fp32': 6.738874912261963, 'top1': 85.763},\n",
       " 'gluon_resnext101_32x4d': {'fp32': 12.563707828521729, 'top1': 85.744},\n",
       " 'ese_vovnet39b': {'fp32': 6.843414306640625, 'top1': 85.742},\n",
       " 'legacy_seresnext101_32x4d': {'fp32': 20.458691120147705, 'top1': 85.738},\n",
       " 'xcit_tiny_24_p16_224': {'fp32': 18.694677352905273, 'top1': 85.736},\n",
       " 'regnety_320': {'fp32': 36.93737506866455, 'top1': 85.723},\n",
       " 'resnet50': {'fp32': 5.8392333984375, 'top1': 85.704},\n",
       " 'gluon_resnext101_64x4d': {'fp32': 19.55361843109131, 'top1': 85.704},\n",
       " 'resmlp_big_24_224': {'fp32': 34.003565311431885, 'top1': 85.697},\n",
       " 'deit_small_patch16_224': {'fp32': 5.30376672744751, 'top1': 85.663},\n",
       " 'dpn107': {'fp32': 25.07070302963257, 'top1': 85.65},\n",
       " 'pit_xs_distilled_224': {'fp32': 5.718038082122803, 'top1': 85.644},\n",
       " 'resmlp_36_224': {'fp32': 8.562207221984863, 'top1': 85.623},\n",
       " 'levit_192': {'fp32': 7.820937633514404, 'top1': 85.586},\n",
       " 'gluon_resnet152_v1c': {'fp32': 14.790723323822021, 'top1': 85.576},\n",
       " 'ecaresnet50d_pruned': {'fp32': 6.682915687561035, 'top1': 85.573},\n",
       " 'resnext50d_32x4d': {'fp32': 7.0255208015441895, 'top1': 85.561},\n",
       " 'regnety_120': {'fp32': 23.444221019744873, 'top1': 85.541},\n",
       " 'regnetx_320': {'fp32': 36.329240798950195, 'top1': 85.516},\n",
       " 'dpn92': {'fp32': 12.439408302307129, 'top1': 85.484},\n",
       " 'rexnet_130': {'fp32': 8.482873439788818, 'top1': 85.465},\n",
       " 'gluon_resnet152_v1b': {'fp32': 14.631612300872803, 'top1': 85.458},\n",
       " 'resnetrs50': {'fp32': 9.213309288024902, 'top1': 85.433},\n",
       " 'dpn131': {'fp32': 22.95206308364868, 'top1': 85.411},\n",
       " 'dla102x2': {'fp32': 15.781023502349854, 'top1': 85.383},\n",
       " 'regnetx_160': {'fp32': 26.581060886383057, 'top1': 85.364},\n",
       " 'gmlp_s16_224': {'fp32': 7.8601789474487305, 'top1': 85.349},\n",
       " 'gluon_seresnext50_32x4d': {'fp32': 10.296087265014648, 'top1': 85.343},\n",
       " 'skresnext50_32x4d': {'fp32': 14.00026798248291, 'top1': 85.315},\n",
       " 'gluon_resnet101_v1c': {'fp32': 10.544290542602539, 'top1': 85.311},\n",
       " 'dpn98': {'fp32': 16.838343143463135, 'top1': 85.309},\n",
       " 'regnety_064': {'fp32': 15.869503021240234, 'top1': 85.287},\n",
       " 'dpn68b': {'fp32': 10.606613159179688, 'top1': 85.285},\n",
       " 'resnetblur50': {'fp32': 5.8940863609313965, 'top1': 85.277},\n",
       " 'resmlp_24_224': {'fp32': 6.166572570800781, 'top1': 85.275},\n",
       " 'coat_lite_mini': {'fp32': 7.513597011566162, 'top1': 85.249},\n",
       " 'resnext50_32x4d': {'fp32': 6.959478855133057, 'top1': 85.232},\n",
       " 'regnety_080': {'fp32': 14.425852298736572, 'top1': 85.232},\n",
       " 'cait_xxs24_224': {'fp32': 14.630074501037598, 'top1': 85.221},\n",
       " 'xcit_tiny_12_p16_224_dist': {'fp32': 10.864458084106445, 'top1': 85.206},\n",
       " 'resnext101_32x8d': {'fp32': 19.254169464111328, 'top1': 85.187},\n",
       " 'hrnet_w48': {'fp32': 34.230711460113525, 'top1': 85.155},\n",
       " 'regnetx_120': {'fp32': 21.44188404083252, 'top1': 85.138},\n",
       " 'gluon_resnet101_v1b': {'fp32': 9.984734058380127, 'top1': 85.129},\n",
       " 'hrnet_w64': {'fp32': 33.04595232009888, 'top1': 85.117},\n",
       " 'ssl_resnet50': {'fp32': 5.827453136444092, 'top1': 85.104},\n",
       " 'res2net101_26w_4s': {'fp32': 17.982370853424072, 'top1': 85.089},\n",
       " 'gluon_resnext50_32x4d': {'fp32': 6.866660118103027, 'top1': 85.01},\n",
       " 'tf_efficientnet_b0_ns': {'fp32': 7.480754852294922, 'top1': 85.003},\n",
       " 'resnest26d': {'fp32': 9.21252727508545, 'top1': 84.997},\n",
       " 'coat_tiny': {'fp32': 22.003560066223145, 'top1': 84.969},\n",
       " 'regnety_040': {'fp32': 12.508735656738281, 'top1': 84.948},\n",
       " 'dla169': {'fp32': 16.491498947143555, 'top1': 84.914},\n",
       " 'legacy_seresnext50_32x4d': {'fp32': 9.978797435760498, 'top1': 84.909},\n",
       " 'hrnet_w44': {'fp32': 34.55578088760376, 'top1': 84.886},\n",
       " 'regnetx_080': {'fp32': 16.284196376800537, 'top1': 84.875},\n",
       " 'gluon_resnet50_v1s': {'fp32': 6.026053428649902, 'top1': 84.852},\n",
       " 'res2net50_26w_8s': {'fp32': 16.22917652130127, 'top1': 84.843},\n",
       " 'dla60_res2next': {'fp32': 16.423168182373047, 'top1': 84.828},\n",
       " 'mixnet_l': {'fp32': 11.95857048034668, 'top1': 84.826},\n",
       " 'levit_128': {'fp32': 7.7445220947265625, 'top1': 84.822},\n",
       " 'dla60_res2net': {'fp32': 10.492653846740723, 'top1': 84.82},\n",
       " 'tv_resnet152': {'fp32': 14.771018028259277, 'top1': 84.818},\n",
       " 'dla102x': {'fp32': 12.74256944656372, 'top1': 84.813},\n",
       " 'gluon_resnet50_v1d': {'fp32': 5.942518711090088, 'top1': 84.811},\n",
       " 'regnetx_064': {'fp32': 10.907056331634521, 'top1': 84.783},\n",
       " 'pit_xs_224': {'fp32': 5.417320728302002, 'top1': 84.783},\n",
       " 'hrnet_w40': {'fp32': 31.760694980621338, 'top1': 84.745},\n",
       " 'repvgg_b2': {'fp32': 13.380820751190186, 'top1': 84.726},\n",
       " 'res2net50_26w_6s': {'fp32': 13.04659128189087, 'top1': 84.724},\n",
       " 'resmlp_12_distilled_224': {'fp32': 3.3237171173095703, 'top1': 84.707},\n",
       " 'legacy_seresnet152': {'fp32': 26.403536796569824, 'top1': 84.696},\n",
       " 'selecsls60b': {'fp32': 6.648528575897217, 'top1': 84.655},\n",
       " 'hrnet_w32': {'fp32': 31.174631118774414, 'top1': 84.653},\n",
       " 'tf_efficientnetv2_b0': {'fp32': 9.105782508850098, 'top1': 84.625},\n",
       " 'regnetx_040': {'fp32': 9.47070598602295, 'top1': 84.6},\n",
       " 'hrnet_w30': {'fp32': 32.16704845428467, 'top1': 84.591},\n",
       " 'efficientnet_es': {'fp32': 4.538414478302002, 'top1': 84.591},\n",
       " 'tf_mixnet_l': {'fp32': 12.606806755065918, 'top1': 84.559},\n",
       " 'wide_resnet101_2': {'fp32': 18.493614196777344, 'top1': 84.555},\n",
       " 'dla60x': {'fp32': 7.526495456695557, 'top1': 84.529},\n",
       " 'legacy_seresnet101': {'fp32': 17.574009895324707, 'top1': 84.502},\n",
       " 'coat_lite_tiny': {'fp32': 7.392082214355469, 'top1': 84.457},\n",
       " 'repvgg_b1': {'fp32': 10.306687355041504, 'top1': 84.399},\n",
       " 'res2net50_26w_4s': {'fp32': 9.69325304031372, 'top1': 84.371},\n",
       " 'hardcorenas_f': {'fp32': 7.530560493469238, 'top1': 84.322},\n",
       " 'res2net50_14w_8s': {'fp32': 15.195362567901611, 'top1': 84.307},\n",
       " 'selecsls60': {'fp32': 6.841988563537598, 'top1': 84.282},\n",
       " 'res2next50': {'fp32': 16.007883548736572, 'top1': 84.23},\n",
       " 'regnetx_032': {'fp32': 9.208292961120605, 'top1': 84.23},\n",
       " 'gluon_resnet50_v1c': {'fp32': 6.052649021148682, 'top1': 84.209},\n",
       " 'dla102': {'fp32': 10.941462516784668, 'top1': 84.192},\n",
       " 'rexnet_100': {'fp32': 8.449954986572266, 'top1': 84.173},\n",
       " 'res2net50_48w_2s': {'fp32': 6.536848545074463, 'top1': 84.121},\n",
       " 'resnet34d': {'fp32': 4.470558166503906, 'top1': 84.104},\n",
       " 'xcit_tiny_12_p16_224': {'fp32': 10.63784122467041, 'top1': 84.083},\n",
       " 'efficientnet_b0': {'fp32': 7.568955421447754, 'top1': 84.034},\n",
       " 'hardcorenas_e': {'fp32': 7.396128177642822, 'top1': 83.972},\n",
       " 'gmixer_24_224': {'fp32': 8.387062549591064, 'top1': 83.97},\n",
       " 'tf_efficientnet_cc_b0_8e': {'fp32': 9.599294662475586, 'top1': 83.97},\n",
       " 'regnety_016': {'fp32': 13.486073017120361, 'top1': 83.955},\n",
       " 'tv_resnext50_32x4d': {'fp32': 6.946098804473877, 'top1': 83.955},\n",
       " 'gluon_resnet50_v1b': {'fp32': 5.7448625564575195, 'top1': 83.942},\n",
       " 'densenet161': {'fp32': 18.091626167297363, 'top1': 83.9},\n",
       " 'seresnext26t_32x4d': {'fp32': 5.766298770904541, 'top1': 83.887},\n",
       " 'mobilenetv2_120d': {'fp32': 6.469125747680664, 'top1': 83.887},\n",
       " 'tv_resnet101': {'fp32': 10.18514633178711, 'top1': 83.855},\n",
       " 'hardcorenas_d': {'fp32': 7.6528215408325195, 'top1': 83.763},\n",
       " 'dla60': {'fp32': 6.767768859863281, 'top1': 83.735},\n",
       " 'xcit_nano_12_p8_224_dist': {'fp32': 10.852313041687012, 'top1': 83.733},\n",
       " 'seresnext26d_32x4d': {'fp32': 5.781450271606445, 'top1': 83.724},\n",
       " 'repvgg_b1g4': {'fp32': 15.741524696350098, 'top1': 83.695},\n",
       " 'legacy_seresnet50': {'fp32': 9.04362678527832, 'top1': 83.671},\n",
       " 'tf_efficientnet_b0_ap': {'fp32': 7.821083068847656, 'top1': 83.66},\n",
       " 'skresnet34': {'fp32': 11.947510242462158, 'top1': 83.65},\n",
       " 'tf_efficientnet_cc_b0_4e': {'fp32': 9.393877983093262, 'top1': 83.639},\n",
       " 'resmlp_12_224': {'fp32': 3.5558176040649414, 'top1': 83.573},\n",
       " 'mobilenetv3_large_100_miil': {'fp32': 5.717058181762695, 'top1': 83.549},\n",
       " 'densenet201': {'fp32': 22.792253494262695, 'top1': 83.547},\n",
       " 'gernet_s': {'fp32': 4.975404739379883, 'top1': 83.522},\n",
       " 'legacy_seresnext26_32x4d': {'fp32': 5.526425838470459, 'top1': 83.515},\n",
       " 'mixnet_m': {'fp32': 12.208683490753174, 'top1': 83.513},\n",
       " 'tf_efficientnet_b0': {'fp32': 7.39795446395874, 'top1': 83.513},\n",
       " 'hrnet_w18': {'fp32': 30.66802978515625, 'top1': 83.5},\n",
       " 'densenetblur121d': {'fp32': 13.869426250457764, 'top1': 83.475},\n",
       " 'selecsls42b': {'fp32': 5.463900566101074, 'top1': 83.46},\n",
       " 'hardcorenas_c': {'fp32': 5.89510440826416, 'top1': 83.336},\n",
       " 'regnetx_016': {'fp32': 7.057490348815918, 'top1': 83.186},\n",
       " 'mobilenetv2_140': {'fp32': 4.270687103271484, 'top1': 83.176},\n",
       " 'tf_mixnet_m': {'fp32': 12.038166522979736, 'top1': 83.174},\n",
       " 'dpn68': {'fp32': 9.72515344619751, 'top1': 83.171},\n",
       " 'tf_efficientnet_es': {'fp32': 4.743032455444336, 'top1': 83.167},\n",
       " 'ese_vovnet19b_dw': {'fp32': 4.022977352142334, 'top1': 83.114},\n",
       " 'levit_128s': {'fp32': 6.251623630523682, 'top1': 83.065},\n",
       " 'resnet26d': {'fp32': 3.824455738067627, 'top1': 83.043},\n",
       " 'repvgg_a2': {'fp32': 5.800914764404297, 'top1': 82.999},\n",
       " 'tv_resnet50': {'fp32': 5.629220008850098, 'top1': 82.954},\n",
       " 'hardcorenas_b': {'fp32': 5.557959079742432, 'top1': 82.877},\n",
       " 'densenet121': {'fp32': 13.61299991607666, 'top1': 82.815},\n",
       " 'densenet169': {'fp32': 18.831112384796143, 'top1': 82.661},\n",
       " 'mixnet_s': {'fp32': 9.757490158081055, 'top1': 82.525},\n",
       " 'vit_small_patch32_224': {'fp32': 5.096225738525391, 'top1': 82.51},\n",
       " 'regnety_008': {'fp32': 7.901732921600342, 'top1': 82.478},\n",
       " 'efficientnet_lite0': {'fp32': 4.191188812255859, 'top1': 82.388},\n",
       " 'resnest14d': {'fp32': 6.851811408996582, 'top1': 82.362},\n",
       " 'hardcorenas_a': {'fp32': 4.8409199714660645, 'top1': 82.305},\n",
       " 'efficientnet_es_pruned': {'fp32': 4.648795127868652, 'top1': 82.279},\n",
       " 'mobilenetv3_rw': {'fp32': 5.667610168457031, 'top1': 82.268},\n",
       " 'semnasnet_100': {'fp32': 5.82747220993042, 'top1': 82.253},\n",
       " 'mobilenetv3_large_100': {'fp32': 5.91533899307251, 'top1': 82.177},\n",
       " 'resnet34': {'fp32': 4.090702533721924, 'top1': 82.125},\n",
       " 'mobilenetv2_110d': {'fp32': 5.3720855712890625, 'top1': 82.076},\n",
       " 'vit_tiny_patch16_224': {'fp32': 5.227022171020508, 'top1': 82.044},\n",
       " 'tf_mixnet_s': {'fp32': 10.010137557983398, 'top1': 82.04},\n",
       " 'repvgg_b0': {'fp32': 6.675727367401123, 'top1': 82.006},\n",
       " 'deit_tiny_distilled_patch16_224': {'fp32': 5.460071563720703,\n",
       "  'top1': 82.001},\n",
       " 'mixer_b16_224': {'fp32': 5.086991786956787, 'top1': 81.997},\n",
       " 'pit_ti_distilled_224': {'fp32': 5.3986382484436035, 'top1': 81.972},\n",
       " 'hrnet_w18_small_v2': {'fp32': 16.57296895980835, 'top1': 81.959},\n",
       " 'tf_efficientnet_lite0': {'fp32': 4.450747966766357, 'top1': 81.95},\n",
       " 'resnet26': {'fp32': 3.575725555419922, 'top1': 81.942},\n",
       " 'tf_mobilenetv3_large_100': {'fp32': 5.966911315917969, 'top1': 81.841},\n",
       " 'tv_densenet121': {'fp32': 13.520746231079102, 'top1': 81.728},\n",
       " 'regnety_006': {'fp32': 8.412299156188965, 'top1': 81.703},\n",
       " 'dla34': {'fp32': 4.329702854156494, 'top1': 81.643},\n",
       " 'xcit_nano_12_p8_224': {'fp32': 10.801050662994385, 'top1': 81.641},\n",
       " 'fbnetc_100': {'fp32': 5.238170623779297, 'top1': 81.555},\n",
       " 'legacy_seresnet34': {'fp32': 7.046689987182617, 'top1': 81.532},\n",
       " 'regnetx_008': {'fp32': 5.828697681427002, 'top1': 81.508},\n",
       " 'gluon_resnet34_v1b': {'fp32': 4.112353324890137, 'top1': 81.489},\n",
       " 'mnasnet_100': {'fp32': 4.512279033660889, 'top1': 81.472},\n",
       " 'vgg19_bn': {'fp32': 12.25665807723999, 'top1': 81.451},\n",
       " 'convit_tiny': {'fp32': 6.963202953338623, 'top1': 81.115},\n",
       " 'spnasnet_100': {'fp32': 5.339231491088867, 'top1': 80.866},\n",
       " 'ghostnet_100': {'fp32': 8.784103393554688, 'top1': 80.699},\n",
       " 'regnety_004': {'fp32': 9.942929744720459, 'top1': 80.648},\n",
       " 'skresnet18': {'fp32': 6.443450450897217, 'top1': 80.624},\n",
       " 'regnetx_006': {'fp32': 5.590357780456543, 'top1': 80.616},\n",
       " 'pit_ti_224': {'fp32': 5.664281845092773, 'top1': 80.597},\n",
       " 'swsl_resnet18': {'fp32': 2.8646159172058105, 'top1': 80.562},\n",
       " 'vgg16_bn': {'fp32': 10.735476016998291, 'top1': 80.535},\n",
       " 'resnet18d': {'fp32': 3.0302071571350098, 'top1': 80.387},\n",
       " 'tv_resnet34': {'fp32': 4.167530536651611, 'top1': 80.377},\n",
       " 'mobilenetv2_100': {'fp32': 4.245607852935791, 'top1': 80.257},\n",
       " 'xcit_nano_12_p16_224_dist': {'fp32': 10.799438953399658, 'top1': 80.225},\n",
       " 'vit_base_patch32_sam_224': {'fp32': 5.403764247894287, 'top1': 80.212},\n",
       " 'ssl_resnet18': {'fp32': 2.6334023475646973, 'top1': 80.114},\n",
       " 'tf_mobilenetv3_large_075': {'fp32': 5.989499092102051, 'top1': 80.088},\n",
       " 'deit_tiny_patch16_224': {'fp32': 5.194070339202881, 'top1': 80.009},\n",
       " 'hrnet_w18_small': {'fp32': 9.595694541931152, 'top1': 79.544},\n",
       " 'vgg19': {'fp32': 11.495828628540039, 'top1': 79.484},\n",
       " 'regnetx_004': {'fp32': 8.82101058959961, 'top1': 79.424},\n",
       " 'tf_mobilenetv3_large_minimal_100': {'fp32': 4.257955551147461,\n",
       "  'top1': 79.232},\n",
       " 'legacy_seresnet18': {'fp32': 4.220445156097412, 'top1': 79.151},\n",
       " 'vgg16': {'fp32': 9.98368501663208, 'top1': 79.031},\n",
       " 'vit_tiny_r_s16_p8_224': {'fp32': 5.392265319824219, 'top1': 78.997},\n",
       " 'vgg13_bn': {'fp32': 9.115087985992432, 'top1': 78.987},\n",
       " 'gluon_resnet18_v1b': {'fp32': 2.794067859649658, 'top1': 78.376},\n",
       " 'vgg11_bn': {'fp32': 7.375471591949463, 'top1': 77.926},\n",
       " 'xcit_nano_12_p16_224': {'fp32': 10.941822528839111, 'top1': 77.909},\n",
       " 'regnety_002': {'fp32': 8.2291841506958, 'top1': 77.417},\n",
       " 'mixer_l16_224': {'fp32': 15.571436882019043, 'top1': 77.294},\n",
       " 'resnet18': {'fp32': 2.7054572105407715, 'top1': 77.276},\n",
       " 'vgg13': {'fp32': 8.459031581878662, 'top1': 77.234},\n",
       " 'vgg11': {'fp32': 7.024950981140137, 'top1': 76.397},\n",
       " 'regnetx_002': {'fp32': 5.828824043273926, 'top1': 76.102},\n",
       " 'dla60x_c': {'fp32': 5.9967803955078125, 'top1': 75.656},\n",
       " 'tf_mobilenetv3_small_100': {'fp32': 5.031616687774658, 'top1': 74.736},\n",
       " 'dla46x_c': {'fp32': 4.911093711853027, 'top1': 73.645},\n",
       " 'tf_mobilenetv3_small_075': {'fp32': 5.292332172393799, 'top1': 72.816},\n",
       " 'dla46_c': {'fp32': 5.090696811676025, 'top1': 72.607},\n",
       " 'tf_mobilenetv3_small_minimal_100': {'fp32': 3.612961769104004,\n",
       "  'top1': 70.107}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = {}\n",
    "\n",
    "# inference float precision\n",
    "for i,modelname in tqdm(enumerate((modellist))):\n",
    "    try:\n",
    "        benchmark = inference(modelname, benchmark)\n",
    "    except:\n",
    "        print(\"pass {}\".format(modelname))\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp32</th>\n",
       "      <th>top1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beit_large_patch16_224</th>\n",
       "      <td>21.222758</td>\n",
       "      <td>90.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swin_large_patch4_window7_224</th>\n",
       "      <td>17.099423</td>\n",
       "      <td>89.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xcit_large_24_p8_224_dist</th>\n",
       "      <td>66.532454</td>\n",
       "      <td>89.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beit_base_patch16_224</th>\n",
       "      <td>7.464490</td>\n",
       "      <td>89.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_large_patch16_224</th>\n",
       "      <td>20.044599</td>\n",
       "      <td>89.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_mobilenetv3_small_100</th>\n",
       "      <td>5.031617</td>\n",
       "      <td>74.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dla46x_c</th>\n",
       "      <td>4.911094</td>\n",
       "      <td>73.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_mobilenetv3_small_075</th>\n",
       "      <td>5.292332</td>\n",
       "      <td>72.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dla46_c</th>\n",
       "      <td>5.090697</td>\n",
       "      <td>72.607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_mobilenetv3_small_minimal_100</th>\n",
       "      <td>3.612962</td>\n",
       "      <td>70.107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>322 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       fp32    top1\n",
       "beit_large_patch16_224            21.222758  90.157\n",
       "swin_large_patch4_window7_224     17.099423  89.796\n",
       "xcit_large_24_p8_224_dist         66.532454  89.519\n",
       "beit_base_patch16_224              7.464490  89.438\n",
       "vit_large_patch16_224             20.044599  89.308\n",
       "...                                     ...     ...\n",
       "tf_mobilenetv3_small_100           5.031617  74.736\n",
       "dla46x_c                           4.911094  73.645\n",
       "tf_mobilenetv3_small_075           5.292332  72.816\n",
       "dla46_c                            5.090697  72.607\n",
       "tf_mobilenetv3_small_minimal_100   3.612962  70.107\n",
       "\n",
       "[322 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(benchmark).T\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"results_fp32_224.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7efec36ae978>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot(y='top1', x='fp32',  \n",
    "           data=df_results, logx=True,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.8})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For various image size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ryujaehun/pytorch-gpu-benchmark/blob/master/benchmark_models.py\n",
    "def inference_imsize(modelname, benchmark, imsize):\n",
    "    with torch.no_grad():\n",
    "        model = timm.create_model(modelname,)\n",
    "        model=model.to('cuda')\n",
    "        model.eval()\n",
    "        precision = \"float\"\n",
    "        durations = []\n",
    "        rand_loader = DataLoader(dataset=RandomDataset(BATCH_SIZE*(WARM_UP + NUM_TEST), imsize),\n",
    "                         batch_size=BATCH_SIZE, shuffle=False,num_workers=8)\n",
    "        print(f'Benchmarking Inference {modelname} ')\n",
    "        for step,img in enumerate(rand_loader):\n",
    "            img=getattr(img,precision)()\n",
    "            torch.cuda.synchronize()\n",
    "            start = time.time()\n",
    "            model(img.to('cuda'))\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            if step >= WARM_UP:\n",
    "                durations.append((end - start)*1000)\n",
    "        print(f'{modelname} model average inference time : {sum(durations)/len(durations)}ms')\n",
    "        \n",
    "        benchmark[modelname] = {\"fp32\": np.mean(durations), \"top1\": float(df_models[df_models[\"model\"]==modelname][\"top1\"]), \"imsize\": imsize}\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d39bd3bec7b48e48e7e59a25ad100a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference beit_large_patch16_512 \n",
      "beit_large_patch16_512 model average inference time : 187.82024145126343ms\n",
      "Benchmarking Inference beit_large_patch16_384 \n",
      "beit_large_patch16_384 model average inference time : 78.99953365325928ms\n",
      "Benchmarking Inference tf_efficientnet_l2_ns \n",
      "tf_efficientnet_l2_ns model average inference time : 605.894718170166ms\n",
      "Benchmarking Inference tf_efficientnet_l2_ns_475 \n",
      "tf_efficientnet_l2_ns_475 model average inference time : 255.02083778381348ms\n",
      "Benchmarking Inference beit_base_patch16_384 \n",
      "beit_base_patch16_384 model average inference time : 30.691065788269043ms\n",
      "Benchmarking Inference vit_large_patch16_384 \n",
      "vit_large_patch16_384 model average inference time : 67.07225799560547ms\n",
      "Benchmarking Inference cait_m48_448 \n",
      "cait_m48_448 model average inference time : 482.82698154449463ms\n",
      "Benchmarking Inference beit_large_patch16_224 \n",
      "beit_large_patch16_224 model average inference time : 22.189147472381592ms\n",
      "Benchmarking Inference tf_efficientnet_b7_ns \n",
      "tf_efficientnet_b7_ns model average inference time : 92.80160427093506ms\n",
      "Benchmarking Inference swin_large_patch4_window12_384 \n",
      "swin_large_patch4_window12_384 model average inference time : 54.970736503601074ms\n",
      "Benchmarking Inference swin_base_patch4_window12_384 \n",
      "swin_base_patch4_window12_384 model average inference time : 34.66608285903931ms\n",
      "Benchmarking Inference cait_m36_384 \n",
      "cait_m36_384 model average inference time : 207.59344577789307ms\n",
      "Benchmarking Inference dm_nfnet_f6 \n",
      "dm_nfnet_f6 model average inference time : 674.3886399269104ms\n",
      "Benchmarking Inference tf_efficientnetv2_l_in21ft1k \n",
      "tf_efficientnetv2_l_in21ft1k model average inference time : 71.21510028839111ms\n",
      "Benchmarking Inference vit_base_patch16_384 \n",
      "vit_base_patch16_384 model average inference time : 26.030404567718506ms\n",
      "Benchmarking Inference xcit_large_24_p8_384_dist \n",
      "xcit_large_24_p8_384_dist model average inference time : 171.45898818969727ms\n",
      "Benchmarking Inference cait_s36_384 \n",
      "cait_s36_384 model average inference time : 100.20755052566528ms\n",
      "Benchmarking Inference xcit_medium_24_p8_384_dist \n",
      "xcit_medium_24_p8_384_dist model average inference time : 103.04621696472168ms\n",
      "Benchmarking Inference swin_large_patch4_window7_224 \n",
      "swin_large_patch4_window7_224 model average inference time : 17.773497104644775ms\n",
      "Benchmarking Inference vit_large_r50_s32_384 \n",
      "vit_large_r50_s32_384 model average inference time : 30.787925720214844ms\n",
      "Benchmarking Inference tf_efficientnetv2_m_in21ft1k \n",
      "tf_efficientnetv2_m_in21ft1k model average inference time : 36.46842956542969ms\n",
      "Benchmarking Inference tf_efficientnet_b6_ns \n",
      "tf_efficientnet_b6_ns model average inference time : 53.60628128051758ms\n",
      "Benchmarking Inference xcit_small_24_p8_384_dist \n",
      "xcit_small_24_p8_384_dist model average inference time : 75.44042110443115ms\n",
      "Benchmarking Inference xcit_large_24_p16_384_dist \n",
      "xcit_large_24_p16_384_dist model average inference time : 50.514726638793945ms\n",
      "Benchmarking Inference tf_efficientnet_b5_ns \n",
      "tf_efficientnet_b5_ns model average inference time : 32.2252082824707ms\n",
      "Benchmarking Inference tf_efficientnet_b8_ap \n",
      "tf_efficientnet_b8_ap model average inference time : 137.45931386947632ms\n",
      "Benchmarking Inference tf_efficientnetv2_xl_in21ft1k \n",
      "tf_efficientnetv2_xl_in21ft1k model average inference time : 112.2532606124878ms\n",
      "Benchmarking Inference dm_nfnet_f4 \n",
      "dm_nfnet_f4 model average inference time : 673.0227756500244ms\n",
      "Benchmarking Inference xcit_small_12_p8_384_dist \n",
      "xcit_small_12_p8_384_dist model average inference time : 41.17788314819336ms\n",
      "Benchmarking Inference xcit_large_24_p8_224_dist \n",
      "xcit_large_24_p8_224_dist model average inference time : 69.23095703125ms\n",
      "Benchmarking Inference cait_s24_384 \n",
      "cait_s24_384 model average inference time : 67.38134145736694ms\n",
      "Benchmarking Inference dm_nfnet_f3 \n",
      "dm_nfnet_f3 model average inference time : 293.33019971847534ms\n",
      "Benchmarking Inference xcit_medium_24_p16_384_dist \n",
      "xcit_medium_24_p16_384_dist model average inference time : 31.06527328491211ms\n",
      "Benchmarking Inference dm_nfnet_f5 \n",
      "dm_nfnet_f5 model average inference time : 796.1416149139404ms\n",
      "Benchmarking Inference beit_base_patch16_224 \n",
      "beit_base_patch16_224 model average inference time : 7.706115245819092ms\n",
      "Benchmarking Inference deit_base_distilled_patch16_384 \n",
      "deit_base_distilled_patch16_384 model average inference time : 26.1637544631958ms\n",
      "Benchmarking Inference tf_efficientnet_b7_ap \n",
      "tf_efficientnet_b7_ap model average inference time : 92.97600269317627ms\n",
      "Benchmarking Inference tf_efficientnetv2_l \n",
      "tf_efficientnetv2_l model average inference time : 71.10381603240967ms\n",
      "Benchmarking Inference tf_efficientnet_b6_ap \n",
      "tf_efficientnet_b6_ap model average inference time : 53.76356601715088ms\n",
      "Benchmarking Inference tf_efficientnet_b8 \n",
      "tf_efficientnet_b8 model average inference time : 137.50638723373413ms\n",
      "Benchmarking Inference tf_efficientnet_b4_ns \n",
      "tf_efficientnet_b4_ns model average inference time : 17.170755863189697ms\n",
      "Benchmarking Inference vit_large_patch16_224 \n",
      "vit_large_patch16_224 model average inference time : 20.631911754608154ms\n",
      "Benchmarking Inference xcit_small_24_p16_384_dist \n",
      "xcit_small_24_p16_384_dist model average inference time : 21.862990856170654ms\n",
      "Benchmarking Inference xcit_medium_24_p8_224_dist \n",
      "xcit_medium_24_p8_224_dist model average inference time : 41.71958923339844ms\n",
      "Benchmarking Inference tf_efficientnetv2_m \n",
      "tf_efficientnetv2_m model average inference time : 36.42159700393677ms\n",
      "Benchmarking Inference xcit_small_24_p8_224_dist \n",
      "xcit_small_24_p8_224_dist model average inference time : 29.802353382110596ms\n",
      "Benchmarking Inference xcit_small_12_p16_384_dist \n",
      "xcit_small_12_p16_384_dist model average inference time : 12.899026870727539ms\n",
      "Benchmarking Inference swin_base_patch4_window7_224 \n",
      "swin_base_patch4_window7_224 model average inference time : 13.011953830718994ms\n",
      "Benchmarking Inference eca_nfnet_l2 \n",
      "eca_nfnet_l2 model average inference time : 72.88344383239746ms\n",
      "Benchmarking Inference cait_xs24_384 \n",
      "cait_xs24_384 model average inference time : 48.50192308425903ms\n",
      "Benchmarking Inference ig_resnext101_32x32d \n",
      "ig_resnext101_32x32d model average inference time : 133.60260248184204ms\n",
      "Benchmarking Inference ig_resnext101_32x48d \n",
      "ig_resnext101_32x48d model average inference time : 211.29178524017334ms\n",
      "Benchmarking Inference tf_efficientnet_b7 \n",
      "tf_efficientnet_b7 model average inference time : 92.60906219482422ms\n",
      "Benchmarking Inference ecaresnet269d \n",
      "ecaresnet269d model average inference time : 50.559325218200684ms\n",
      "Benchmarking Inference xcit_large_24_p16_224_dist \n",
      "xcit_large_24_p16_224_dist model average inference time : 19.935379028320312ms\n",
      "Benchmarking Inference resmlp_big_24_224_in22ft1k \n",
      "resmlp_big_24_224_in22ft1k model average inference time : 34.1888689994812ms\n",
      "Benchmarking Inference xcit_small_12_p8_224_dist \n",
      "xcit_small_12_p8_224_dist model average inference time : 16.16833209991455ms\n",
      "Benchmarking Inference efficientnetv2_rw_m \n",
      "efficientnetv2_rw_m model average inference time : 31.531519889831543ms\n",
      "Benchmarking Inference dm_nfnet_f2 \n",
      "dm_nfnet_f2 model average inference time : 186.10388040542603ms\n",
      "Benchmarking Inference tf_efficientnet_b5_ap \n",
      "tf_efficientnet_b5_ap model average inference time : 32.31218338012695ms\n",
      "Benchmarking Inference dm_nfnet_f1 \n",
      "dm_nfnet_f1 model average inference time : 110.46903133392334ms\n",
      "Benchmarking Inference tf_efficientnetv2_s_in21ft1k \n",
      "tf_efficientnetv2_s_in21ft1k model average inference time : 18.91585111618042ms\n",
      "Benchmarking Inference vit_base_patch16_224 \n",
      "vit_base_patch16_224 model average inference time : 7.194774150848389ms\n",
      "Benchmarking Inference resnetrs270 \n",
      "resnetrs270 model average inference time : 57.51713991165161ms\n",
      "Benchmarking Inference resnetrs420 \n",
      "resnetrs420 model average inference time : 122.52376556396484ms\n",
      "Benchmarking Inference vit_small_r26_s32_384 \n",
      "vit_small_r26_s32_384 model average inference time : 12.894129753112793ms\n",
      "Benchmarking Inference xcit_medium_24_p16_224_dist \n",
      "xcit_medium_24_p16_224_dist model average inference time : 18.943955898284912ms\n",
      "Benchmarking Inference ig_resnext101_32x16d \n",
      "ig_resnext101_32x16d model average inference time : 35.64459562301636ms\n",
      "Benchmarking Inference seresnet152d \n",
      "seresnet152d model average inference time : 32.0986533164978ms\n",
      "Benchmarking Inference vit_base_r50_s16_384 \n",
      "vit_base_r50_s16_384 model average inference time : 38.8896918296814ms\n",
      "Benchmarking Inference xcit_tiny_24_p8_384_dist \n",
      "xcit_tiny_24_p8_384_dist model average inference time : 38.72120141983032ms\n",
      "Benchmarking Inference resnetrs350 \n",
      "resnetrs350 model average inference time : 80.04353284835815ms\n",
      "Benchmarking Inference swsl_resnext101_32x8d \n",
      "swsl_resnext101_32x8d model average inference time : 19.377267360687256ms\n",
      "Benchmarking Inference tf_efficientnet_b6 \n",
      "tf_efficientnet_b6 model average inference time : 53.68501663208008ms\n",
      "Benchmarking Inference vit_base_patch16_224_miil \n",
      "vit_base_patch16_224_miil model average inference time : 6.8964385986328125ms\n",
      "Benchmarking Inference resnetv2_152x2_bitm \n",
      "resnetv2_152x2_bitm model average inference time : 126.72324419021606ms\n",
      "Benchmarking Inference regnety_160 \n",
      "regnety_160 model average inference time : 72.03325271606445ms\n",
      "Benchmarking Inference pit_b_distilled_224 \n",
      "pit_b_distilled_224 model average inference time : 8.208386898040771ms\n",
      "pass regnetz_d\n",
      "Benchmarking Inference eca_nfnet_l1 \n",
      "eca_nfnet_l1 model average inference time : 36.295228004455566ms\n",
      "Benchmarking Inference vit_small_patch16_384 \n",
      "vit_small_patch16_384 model average inference time : 11.50310754776001ms\n",
      "Benchmarking Inference resnetrs200 \n",
      "resnetrs200 model average inference time : 38.42800855636597ms\n",
      "Benchmarking Inference resnetv2_152x4_bitm \n",
      "resnetv2_152x4_bitm model average inference time : 443.33802461624146ms\n",
      "Benchmarking Inference xcit_small_24_p16_224_dist \n",
      "xcit_small_24_p16_224_dist model average inference time : 18.701508045196533ms\n",
      "Benchmarking Inference resnet200d \n",
      "resnet200d model average inference time : 30.455100536346436ms\n",
      "Benchmarking Inference resnest269e \n",
      "resnest269e model average inference time : 192.0150589942932ms\n",
      "Benchmarking Inference efficientnetv2_rw_s \n",
      "efficientnetv2_rw_s model average inference time : 18.94211769104004ms\n",
      "Benchmarking Inference crossvit_18_dagger_408 \n",
      "crossvit_18_dagger_408 model average inference time : 28.560023307800293ms\n",
      "Benchmarking Inference cait_s24_224 \n",
      "cait_s24_224 model average inference time : 13.865032196044922ms\n",
      "Benchmarking Inference resmlp_big_24_distilled_224 \n",
      "resmlp_big_24_distilled_224 model average inference time : 34.31056261062622ms\n",
      "Benchmarking Inference tf_efficientnet_b3_ns \n",
      "tf_efficientnet_b3_ns model average inference time : 13.225173950195312ms\n",
      "Benchmarking Inference resnetv2_101x3_bitm \n",
      "resnetv2_101x3_bitm model average inference time : 164.66094732284546ms\n",
      "Benchmarking Inference resnest200e \n",
      "resnest200e model average inference time : 88.76918315887451ms\n",
      "Benchmarking Inference vit_large_r50_s32_224 \n",
      "vit_large_r50_s32_224 model average inference time : 17.111563682556152ms\n",
      "Benchmarking Inference resnetv2_50x3_bitm \n",
      "resnetv2_50x3_bitm model average inference time : 95.24729013442993ms\n",
      "Benchmarking Inference tf_efficientnetv2_s \n",
      "tf_efficientnetv2_s model average inference time : 18.8226318359375ms\n",
      "Benchmarking Inference efficientnet_b4 \n",
      "efficientnet_b4 model average inference time : 16.326000690460205ms\n",
      "Benchmarking Inference tf_efficientnet_b4_ap \n",
      "tf_efficientnet_b4_ap model average inference time : 17.07735776901245ms\n",
      "Benchmarking Inference resnet152d \n",
      "resnet152d model average inference time : 23.476836681365967ms\n",
      "Benchmarking Inference tf_efficientnet_b5 \n",
      "tf_efficientnet_b5 model average inference time : 32.18653917312622ms\n",
      "Benchmarking Inference crossvit_15_dagger_408 \n",
      "crossvit_15_dagger_408 model average inference time : 21.523141860961914ms\n",
      "Benchmarking Inference xcit_small_12_p16_224_dist \n",
      "xcit_small_12_p16_224_dist model average inference time : 10.751307010650635ms\n",
      "Benchmarking Inference resnetrs152 \n",
      "resnetrs152 model average inference time : 29.93964433670044ms\n",
      "Benchmarking Inference deit_base_distilled_patch16_224 \n",
      "deit_base_distilled_patch16_224 model average inference time : 7.11979866027832ms\n",
      "Benchmarking Inference ig_resnext101_32x8d \n",
      "ig_resnext101_32x8d model average inference time : 19.309463500976562ms\n",
      "Benchmarking Inference xcit_large_24_p8_224 \n",
      "xcit_large_24_p8_224 model average inference time : 68.4595251083374ms\n",
      "Benchmarking Inference xcit_tiny_24_p16_384_dist \n",
      "xcit_tiny_24_p16_384_dist model average inference time : 19.728000164031982ms\n",
      "Benchmarking Inference cait_xxs36_384 \n",
      "cait_xxs36_384 model average inference time : 47.40362882614136ms\n",
      "Benchmarking Inference resnetv2_152x2_bit_teacher_384 \n",
      "resnetv2_152x2_bit_teacher_384 model average inference time : 93.72071504592896ms\n",
      "Benchmarking Inference dm_nfnet_f0 \n",
      "dm_nfnet_f0 model average inference time : 54.49422359466553ms\n",
      "Benchmarking Inference xcit_tiny_12_p8_384_dist \n",
      "xcit_tiny_12_p8_384_dist model average inference time : 21.0379695892334ms\n",
      "Benchmarking Inference swsl_resnext101_32x4d \n",
      "swsl_resnext101_32x4d model average inference time : 12.531745433807373ms\n",
      "Benchmarking Inference xcit_tiny_24_p8_224_dist \n",
      "xcit_tiny_24_p8_224_dist model average inference time : 18.32463264465332ms\n",
      "Benchmarking Inference nfnet_l0 \n",
      "nfnet_l0 model average inference time : 17.827935218811035ms\n",
      "Benchmarking Inference xcit_small_24_p8_224 \n",
      "xcit_small_24_p8_224 model average inference time : 29.85724687576294ms\n",
      "Benchmarking Inference eca_nfnet_l0 \n",
      "eca_nfnet_l0 model average inference time : 16.57299041748047ms\n",
      "Benchmarking Inference tf_efficientnet_b4 \n",
      "tf_efficientnet_b4 model average inference time : 17.05153465270996ms\n",
      "Benchmarking Inference resnet101d \n",
      "resnet101d model average inference time : 16.95774555206299ms\n",
      "Benchmarking Inference regnety_032 \n",
      "regnety_032 model average inference time : 14.156250953674316ms\n",
      "Benchmarking Inference twins_svt_large \n",
      "twins_svt_large model average inference time : 14.584264755249023ms\n",
      "Benchmarking Inference vit_base_patch32_384 \n",
      "vit_base_patch32_384 model average inference time : 7.528364658355713ms\n",
      "Benchmarking Inference twins_pcpvt_large \n",
      "twins_pcpvt_large model average inference time : 24.0313982963562ms\n",
      "pass regnetz_c\n",
      "Benchmarking Inference deit_base_patch16_384 \n",
      "deit_base_patch16_384 model average inference time : 25.787513256072998ms\n",
      "Benchmarking Inference xcit_small_12_p8_224 \n",
      "xcit_small_12_p8_224 model average inference time : 16.152489185333252ms\n",
      "Benchmarking Inference resnetv2_50x1_bit_distilled \n",
      "resnetv2_50x1_bit_distilled model average inference time : 7.867751121520996ms\n",
      "Benchmarking Inference tresnet_xl_448 \n",
      "pass tresnet_xl_448\n",
      "Benchmarking Inference tresnet_m \n",
      "pass tresnet_m\n",
      "Benchmarking Inference twins_pcpvt_base \n",
      "twins_pcpvt_base model average inference time : 16.90662384033203ms\n",
      "Benchmarking Inference gc_efficientnetv2_rw_t \n",
      "gc_efficientnetv2_rw_t model average inference time : 21.176109313964844ms\n",
      "Benchmarking Inference swin_small_patch4_window7_224 \n",
      "swin_small_patch4_window7_224 model average inference time : 12.731096744537354ms\n",
      "Benchmarking Inference resnetv2_101x1_bitm \n",
      "resnetv2_101x1_bitm model average inference time : 36.48170709609985ms\n",
      "Benchmarking Inference pnasnet5large \n",
      "pnasnet5large model average inference time : 40.56123971939087ms\n",
      "Benchmarking Inference efficientnetv2_rw_t \n",
      "efficientnetv2_rw_t model average inference time : 16.649351119995117ms\n",
      "Benchmarking Inference twins_svt_base \n",
      "twins_svt_base model average inference time : 13.426563739776611ms\n",
      "Benchmarking Inference xcit_medium_24_p8_224 \n",
      "xcit_medium_24_p8_224 model average inference time : 41.39742612838745ms\n",
      "Benchmarking Inference jx_nest_base \n",
      "jx_nest_base model average inference time : 13.91737699508667ms\n",
      "Benchmarking Inference swsl_resnext101_32x16d \n",
      "swsl_resnext101_32x16d model average inference time : 35.49072742462158ms\n",
      "Benchmarking Inference swsl_resnext50_32x4d \n",
      "swsl_resnext50_32x4d model average inference time : 6.893577575683594ms\n",
      "Benchmarking Inference levit_384 \n",
      "levit_384 model average inference time : 7.935302257537842ms\n",
      "Benchmarking Inference tf_efficientnet_b2_ns \n",
      "tf_efficientnet_b2_ns model average inference time : 11.278343200683594ms\n",
      "Benchmarking Inference ecaresnet50t \n",
      "ecaresnet50t model average inference time : 11.587045192718506ms\n",
      "Benchmarking Inference jx_nest_small \n",
      "jx_nest_small model average inference time : 10.779240131378174ms\n",
      "Benchmarking Inference resnetv2_152x2_bit_teacher \n",
      "resnetv2_152x2_bit_teacher model average inference time : 46.39243125915527ms\n",
      "Benchmarking Inference efficientnet_b3 \n",
      "efficientnet_b3 model average inference time : 12.699117660522461ms\n",
      "Benchmarking Inference resnet61q \n",
      "resnet61q model average inference time : 14.191174507141113ms\n",
      "Benchmarking Inference cait_xxs24_384 \n",
      "cait_xxs24_384 model average inference time : 32.010657787323ms\n",
      "Benchmarking Inference resnet51q \n",
      "resnet51q model average inference time : 13.165619373321533ms\n",
      "Benchmarking Inference xcit_tiny_24_p8_224 \n",
      "xcit_tiny_24_p8_224 model average inference time : 18.40524196624756ms\n",
      "Benchmarking Inference tresnet_l_448 \n",
      "pass tresnet_l_448\n",
      "Benchmarking Inference coat_lite_small \n",
      "coat_lite_small model average inference time : 12.97208547592163ms\n",
      "Benchmarking Inference nasnetalarge \n",
      "nasnetalarge model average inference time : 46.04579448699951ms\n",
      "Benchmarking Inference crossvit_18_dagger_240 \n",
      "crossvit_18_dagger_240 model average inference time : 12.208788394927979ms\n",
      "Benchmarking Inference crossvit_18_240 \n",
      "crossvit_18_240 model average inference time : 11.736171245574951ms\n",
      "Benchmarking Inference resnetv2_101 \n",
      "resnetv2_101 model average inference time : 10.5110764503479ms\n",
      "Benchmarking Inference ecaresnet101d \n",
      "ecaresnet101d model average inference time : 13.242623805999756ms\n",
      "Benchmarking Inference pit_s_distilled_224 \n",
      "pit_s_distilled_224 model average inference time : 5.834674835205078ms\n",
      "Benchmarking Inference resnest101e \n",
      "resnest101e model average inference time : 30.416202545166016ms\n",
      "Benchmarking Inference resnetrs101 \n",
      "resnetrs101 model average inference time : 19.872965812683105ms\n",
      "Benchmarking Inference mixer_b16_224_miil \n",
      "mixer_b16_224_miil model average inference time : 5.022103786468506ms\n",
      "Benchmarking Inference tresnet_xl \n",
      "pass tresnet_xl\n",
      "Benchmarking Inference xcit_tiny_12_p8_224_dist \n",
      "xcit_tiny_12_p8_224_dist model average inference time : 10.665295124053955ms\n",
      "Benchmarking Inference convit_base \n",
      "convit_base model average inference time : 10.28860092163086ms\n",
      "Benchmarking Inference xcit_tiny_12_p16_384_dist \n",
      "xcit_tiny_12_p16_384_dist model average inference time : 11.922416687011719ms\n",
      "Benchmarking Inference tf_efficientnet_b3_ap \n",
      "tf_efficientnet_b3_ap model average inference time : 13.231754302978516ms\n",
      "Benchmarking Inference visformer_small \n",
      "visformer_small model average inference time : 12.28888750076294ms\n",
      "Benchmarking Inference crossvit_15_dagger_240 \n",
      "crossvit_15_dagger_240 model average inference time : 11.585962772369385ms\n",
      "Benchmarking Inference xcit_small_24_p16_224 \n",
      "xcit_small_24_p16_224 model average inference time : 18.52921724319458ms\n",
      "Benchmarking Inference convit_small \n",
      "convit_small model average inference time : 7.213244438171387ms\n",
      "Benchmarking Inference crossvit_15_240 \n",
      "crossvit_15_240 model average inference time : 10.648703575134277ms\n",
      "Benchmarking Inference jx_nest_tiny \n",
      "jx_nest_tiny model average inference time : 7.1837568283081055ms\n",
      "Benchmarking Inference tf_efficientnetv2_b3 \n",
      "tf_efficientnetv2_b3 model average inference time : 15.122084617614746ms\n",
      "pass regnetz_b\n",
      "Benchmarking Inference xcit_small_12_p16_224 \n",
      "xcit_small_12_p16_224 model average inference time : 10.652329921722412ms\n",
      "Benchmarking Inference deit_small_distilled_patch16_224 \n",
      "deit_small_distilled_patch16_224 model average inference time : 5.348119735717773ms\n",
      "Benchmarking Inference resmlp_36_distilled_224 \n",
      "resmlp_36_distilled_224 model average inference time : 8.671507835388184ms\n",
      "Benchmarking Inference xcit_large_24_p16_224 \n",
      "xcit_large_24_p16_224 model average inference time : 20.437636375427246ms\n",
      "Benchmarking Inference xcit_medium_24_p16_224 \n",
      "xcit_medium_24_p16_224 model average inference time : 18.789818286895752ms\n",
      "Benchmarking Inference tnt_s_patch16_224 \n",
      "tnt_s_patch16_224 model average inference time : 11.689586639404297ms\n",
      "Benchmarking Inference convmixer_1536_20 \n",
      "pass convmixer_1536_20\n",
      "Benchmarking Inference rexnet_200 \n",
      "rexnet_200 model average inference time : 8.92477035522461ms\n",
      "Benchmarking Inference vit_small_patch16_224 \n",
      "vit_small_patch16_224 model average inference time : 5.119564533233643ms\n",
      "Benchmarking Inference ssl_resnext101_32x16d \n",
      "ssl_resnext101_32x16d model average inference time : 35.156073570251465ms\n",
      "Benchmarking Inference tf_efficientnet_b3 \n",
      "tf_efficientnet_b3 model average inference time : 13.069419860839844ms\n",
      "Benchmarking Inference vit_small_r26_s32_224 \n",
      "vit_small_r26_s32_224 model average inference time : 9.271328449249268ms\n",
      "Benchmarking Inference deit_base_patch16_224 \n",
      "deit_base_patch16_224 model average inference time : 7.06681489944458ms\n",
      "Benchmarking Inference tresnet_m_448 \n",
      "pass tresnet_m_448\n",
      "Benchmarking Inference coat_mini \n",
      "coat_mini model average inference time : 22.4007511138916ms\n",
      "Benchmarking Inference swsl_resnet50 \n",
      "swsl_resnet50 model average inference time : 5.813620090484619ms\n",
      "Benchmarking Inference tf_efficientnet_lite4 \n",
      "tf_efficientnet_lite4 model average inference time : 12.234175205230713ms\n",
      "Benchmarking Inference ssl_resnext101_32x8d \n",
      "ssl_resnext101_32x8d model average inference time : 19.14243459701538ms\n",
      "Benchmarking Inference tresnet_l \n",
      "pass tresnet_l\n",
      "Benchmarking Inference twins_svt_small \n",
      "twins_svt_small model average inference time : 10.650286674499512ms\n",
      "Benchmarking Inference crossvit_base_240 \n",
      "crossvit_base_240 model average inference time : 10.563080310821533ms\n",
      "Benchmarking Inference levit_256 \n",
      "levit_256 model average inference time : 7.837703227996826ms\n",
      "Benchmarking Inference seresnext50_32x4d \n",
      "seresnext50_32x4d model average inference time : 10.301995277404785ms\n",
      "Benchmarking Inference crossvit_small_240 \n",
      "crossvit_small_240 model average inference time : 9.6989107131958ms\n",
      "Benchmarking Inference pit_b_224 \n",
      "pit_b_224 model average inference time : 8.08917760848999ms\n",
      "Benchmarking Inference tf_efficientnet_b1_ns \n",
      "tf_efficientnet_b1_ns model average inference time : 10.472583770751953ms\n",
      "Benchmarking Inference swin_tiny_patch4_window7_224 \n",
      "swin_tiny_patch4_window7_224 model average inference time : 7.131474018096924ms\n",
      "Benchmarking Inference gernet_l \n",
      "gernet_l model average inference time : 13.107085227966309ms\n",
      "Benchmarking Inference wide_resnet50_2 \n",
      "wide_resnet50_2 model average inference time : 11.208875179290771ms\n",
      "Benchmarking Inference efficientnet_el \n",
      "efficientnet_el model average inference time : 10.83052396774292ms\n",
      "Benchmarking Inference twins_pcpvt_small \n",
      "twins_pcpvt_small model average inference time : 10.032284259796143ms\n",
      "Benchmarking Inference resmlp_24_distilled_224 \n",
      "resmlp_24_distilled_224 model average inference time : 5.817584991455078ms\n",
      "Benchmarking Inference nf_resnet50 \n",
      "nf_resnet50 model average inference time : 10.982763767242432ms\n",
      "Benchmarking Inference efficientnet_b3_pruned \n",
      "efficientnet_b3_pruned model average inference time : 12.468500137329102ms\n",
      "Benchmarking Inference sehalonet33ts \n",
      "sehalonet33ts model average inference time : 8.082001209259033ms\n",
      "Benchmarking Inference resnest50d_4s2x40d \n",
      "resnest50d_4s2x40d model average inference time : 22.917375564575195ms\n",
      "Benchmarking Inference repvgg_b3 \n",
      "repvgg_b3 model average inference time : 18.94476890563965ms\n",
      "Benchmarking Inference xcit_tiny_24_p16_224_dist \n",
      "xcit_tiny_24_p16_224_dist model average inference time : 18.10281753540039ms\n",
      "Benchmarking Inference ecaresnet50d \n",
      "ecaresnet50d model average inference time : 7.554936408996582ms\n",
      "Benchmarking Inference ssl_resnext101_32x4d \n",
      "ssl_resnext101_32x4d model average inference time : 12.887659072875977ms\n",
      "Benchmarking Inference gcresnet50t \n",
      "gcresnet50t model average inference time : 11.551768779754639ms\n",
      "Benchmarking Inference gluon_resnet152_v1s \n",
      "gluon_resnet152_v1s model average inference time : 14.83774185180664ms\n",
      "Benchmarking Inference haloregnetz_b \n",
      "haloregnetz_b model average inference time : 14.184448719024658ms\n",
      "Benchmarking Inference resnest50d_1s4x24d \n",
      "resnest50d_1s4x24d model average inference time : 14.150748252868652ms\n",
      "Benchmarking Inference resnetv2_50x1_bitm \n",
      "resnetv2_50x1_bitm model average inference time : 20.73434829711914ms\n",
      "Benchmarking Inference halonet50ts \n",
      "halonet50ts model average inference time : 9.944765567779541ms\n",
      "Benchmarking Inference lamhalobotnet50ts_256 \n",
      "lamhalobotnet50ts_256 model average inference time : 9.35840368270874ms\n",
      "Benchmarking Inference halo2botnet50ts_256 \n",
      "halo2botnet50ts_256 model average inference time : 10.049488544464111ms\n",
      "Benchmarking Inference repvgg_b3g4 \n",
      "repvgg_b3g4 model average inference time : 21.52801752090454ms\n",
      "Benchmarking Inference legacy_senet154 \n",
      "legacy_senet154 model average inference time : 35.19254446029663ms\n",
      "Benchmarking Inference gernet_m \n",
      "gernet_m model average inference time : 5.253360271453857ms\n",
      "Benchmarking Inference cait_xxs36_224 \n",
      "cait_xxs36_224 model average inference time : 20.466907024383545ms\n",
      "Benchmarking Inference pit_s_224 \n",
      "pit_s_224 model average inference time : 5.625371932983398ms\n",
      "Benchmarking Inference efficientnet_b2 \n",
      "efficientnet_b2 model average inference time : 10.981392860412598ms\n",
      "Benchmarking Inference vit_small_patch32_384 \n",
      "vit_small_patch32_384 model average inference time : 6.989421844482422ms\n",
      "Benchmarking Inference gluon_senet154 \n",
      "gluon_senet154 model average inference time : 34.722769260406494ms\n",
      "Benchmarking Inference resnest50d \n",
      "resnest50d model average inference time : 13.82352352142334ms\n",
      "Benchmarking Inference convmixer_768_32 \n",
      "pass convmixer_768_32\n",
      "Benchmarking Inference efficientnet_el_pruned \n",
      "efficientnet_el_pruned model average inference time : 10.81190824508667ms\n",
      "Benchmarking Inference ecaresnet101d_pruned \n",
      "ecaresnet101d_pruned model average inference time : 11.961290836334229ms\n",
      "Benchmarking Inference rexnet_150 \n",
      "rexnet_150 model average inference time : 8.78824234008789ms\n",
      "Benchmarking Inference cspdarknet53 \n",
      "cspdarknet53 model average inference time : 12.3502779006958ms\n",
      "Benchmarking Inference inception_v4 \n",
      "inception_v4 model average inference time : 19.56355571746826ms\n",
      "Benchmarking Inference inception_resnet_v2 \n",
      "inception_resnet_v2 model average inference time : 28.65966558456421ms\n",
      "Benchmarking Inference xcit_tiny_12_p8_224 \n",
      "xcit_tiny_12_p8_224 model average inference time : 10.405259132385254ms\n",
      "Benchmarking Inference ssl_resnext50_32x4d \n",
      "ssl_resnext50_32x4d model average inference time : 6.808748245239258ms\n",
      "Benchmarking Inference tf_efficientnet_el \n",
      "tf_efficientnet_el model average inference time : 11.06443166732788ms\n",
      "Benchmarking Inference lambda_resnet50ts \n",
      "lambda_resnet50ts model average inference time : 9.26401138305664ms\n",
      "Benchmarking Inference ecaresnetlight \n",
      "ecaresnetlight model average inference time : 7.200920581817627ms\n",
      "Benchmarking Inference gluon_resnet101_v1s \n",
      "gluon_resnet101_v1s model average inference time : 10.53018569946289ms\n",
      "Benchmarking Inference resnetv2_50 \n",
      "resnetv2_50 model average inference time : 5.956425666809082ms\n",
      "Benchmarking Inference gcresnext50ts \n",
      "gcresnext50ts model average inference time : 14.055733680725098ms\n",
      "Benchmarking Inference gluon_seresnext101_32x4d \n",
      "gluon_seresnext101_32x4d model average inference time : 20.21681308746338ms\n",
      "Benchmarking Inference seresnet33ts \n",
      "seresnet33ts model average inference time : 8.209333419799805ms\n",
      "Benchmarking Inference resnet50d \n",
      "resnet50d model average inference time : 6.151425838470459ms\n",
      "Benchmarking Inference tf_efficientnet_b2_ap \n",
      "tf_efficientnet_b2_ap model average inference time : 11.008226871490479ms\n",
      "Benchmarking Inference ecaresnet26t \n",
      "ecaresnet26t model average inference time : 7.7222394943237305ms\n",
      "Benchmarking Inference vit_base_patch32_224 \n",
      "vit_base_patch32_224 model average inference time : 5.376286506652832ms\n",
      "Benchmarking Inference gluon_seresnext101_64x4d \n",
      "gluon_seresnext101_64x4d model average inference time : 23.79403829574585ms\n",
      "Benchmarking Inference gluon_resnet152_v1d \n",
      "gluon_resnet152_v1d model average inference time : 14.89464521408081ms\n",
      "Benchmarking Inference vit_large_patch32_384 \n",
      "vit_large_patch32_384 model average inference time : 16.52360200881958ms\n",
      "Benchmarking Inference tf_efficientnetv2_b2 \n",
      "tf_efficientnetv2_b2 model average inference time : 12.000389099121094ms\n",
      "Benchmarking Inference tf_efficientnet_b2 \n",
      "tf_efficientnet_b2 model average inference time : 11.1348557472229ms\n",
      "Benchmarking Inference vit_base_patch16_sam_224 \n",
      "vit_base_patch16_sam_224 model average inference time : 7.086384296417236ms\n",
      "Benchmarking Inference repvgg_b2g4 \n",
      "repvgg_b2g4 model average inference time : 19.88717794418335ms\n",
      "Benchmarking Inference seresnet50 \n",
      "seresnet50 model average inference time : 9.21640396118164ms\n",
      "Benchmarking Inference gluon_resnet101_v1d \n",
      "gluon_resnet101_v1d model average inference time : 10.54732084274292ms\n",
      "Benchmarking Inference gcresnet33ts \n",
      "gcresnet33ts model average inference time : 8.985846042633057ms\n",
      "Benchmarking Inference mixnet_xl \n",
      "mixnet_xl model average inference time : 14.908204078674316ms\n",
      "Benchmarking Inference ens_adv_inception_resnet_v2 \n",
      "ens_adv_inception_resnet_v2 model average inference time : 28.62288236618042ms\n",
      "Benchmarking Inference cspresnext50 \n",
      "cspresnext50 model average inference time : 7.07719087600708ms\n",
      "Benchmarking Inference tf_efficientnet_lite3 \n",
      "tf_efficientnet_lite3 model average inference time : 7.652313709259033ms\n",
      "Benchmarking Inference gluon_resnext101_32x4d \n",
      "gluon_resnext101_32x4d model average inference time : 12.993168830871582ms\n",
      "Benchmarking Inference ese_vovnet39b \n",
      "ese_vovnet39b model average inference time : 6.879565715789795ms\n",
      "Benchmarking Inference legacy_seresnext101_32x4d \n",
      "legacy_seresnext101_32x4d model average inference time : 20.509698390960693ms\n",
      "Benchmarking Inference xcit_tiny_24_p16_224 \n",
      "xcit_tiny_24_p16_224 model average inference time : 18.535187244415283ms\n",
      "Benchmarking Inference eca_resnet33ts \n",
      "eca_resnet33ts model average inference time : 7.937483787536621ms\n",
      "Benchmarking Inference cspresnet50 \n",
      "cspresnet50 model average inference time : 7.427303791046143ms\n",
      "Benchmarking Inference regnety_320 \n",
      "regnety_320 model average inference time : 36.9970178604126ms\n",
      "Benchmarking Inference resnet50 \n",
      "resnet50 model average inference time : 5.866000652313232ms\n",
      "Benchmarking Inference gluon_resnext101_64x4d \n",
      "gluon_resnext101_64x4d model average inference time : 19.597172737121582ms\n",
      "Benchmarking Inference resmlp_big_24_224 \n",
      "resmlp_big_24_224 model average inference time : 34.005258083343506ms\n",
      "Benchmarking Inference xception71 \n",
      "xception71 model average inference time : 20.546371936798096ms\n",
      "Benchmarking Inference efficientnet_em \n",
      "efficientnet_em model average inference time : 6.081697940826416ms\n",
      "Benchmarking Inference deit_small_patch16_224 \n",
      "deit_small_patch16_224 model average inference time : 5.531489849090576ms\n",
      "Benchmarking Inference dpn107 \n",
      "dpn107 model average inference time : 25.118308067321777ms\n",
      "Benchmarking Inference pit_xs_distilled_224 \n",
      "pit_xs_distilled_224 model average inference time : 5.792324542999268ms\n",
      "Benchmarking Inference efficientnet_b2_pruned \n",
      "efficientnet_b2_pruned model average inference time : 10.361897945404053ms\n",
      "Benchmarking Inference resmlp_36_224 \n",
      "resmlp_36_224 model average inference time : 8.584911823272705ms\n",
      "Benchmarking Inference levit_192 \n",
      "levit_192 model average inference time : 7.919249534606934ms\n",
      "Benchmarking Inference gluon_resnet152_v1c \n",
      "gluon_resnet152_v1c model average inference time : 14.895241260528564ms\n",
      "Benchmarking Inference ecaresnet50d_pruned \n",
      "ecaresnet50d_pruned model average inference time : 6.768052577972412ms\n",
      "Benchmarking Inference resnext50d_32x4d \n",
      "resnext50d_32x4d model average inference time : 7.335834503173828ms\n",
      "Benchmarking Inference tf_efficientnetv2_b1 \n",
      "tf_efficientnetv2_b1 model average inference time : 11.071851253509521ms\n",
      "Benchmarking Inference regnety_120 \n",
      "regnety_120 model average inference time : 23.45367670059204ms\n",
      "Benchmarking Inference regnetx_320 \n",
      "regnetx_320 model average inference time : 36.357197761535645ms\n",
      "Benchmarking Inference nf_regnet_b1 \n",
      "nf_regnet_b1 model average inference time : 15.738637447357178ms\n",
      "Benchmarking Inference dpn92 \n",
      "dpn92 model average inference time : 12.499942779541016ms\n",
      "Benchmarking Inference rexnet_130 \n",
      "rexnet_130 model average inference time : 8.879663944244385ms\n",
      "Benchmarking Inference gluon_resnet152_v1b \n",
      "gluon_resnet152_v1b model average inference time : 14.885015487670898ms\n",
      "Benchmarking Inference resnetrs50 \n",
      "resnetrs50 model average inference time : 9.133179187774658ms\n",
      "Benchmarking Inference dpn131 \n",
      "dpn131 model average inference time : 22.948896884918213ms\n",
      "Benchmarking Inference dla102x2 \n",
      "dla102x2 model average inference time : 15.84101915359497ms\n",
      "Benchmarking Inference regnetx_160 \n",
      "regnetx_160 model average inference time : 26.643145084381104ms\n",
      "Benchmarking Inference gmlp_s16_224 \n",
      "gmlp_s16_224 model average inference time : 7.684731483459473ms\n",
      "Benchmarking Inference gluon_seresnext50_32x4d \n",
      "gluon_seresnext50_32x4d model average inference time : 10.582897663116455ms\n",
      "Benchmarking Inference botnet26t_256 \n",
      "botnet26t_256 model average inference time : 5.7482075691223145ms\n",
      "Benchmarking Inference skresnext50_32x4d \n",
      "skresnext50_32x4d model average inference time : 13.614575862884521ms\n",
      "Benchmarking Inference gluon_resnet101_v1c \n",
      "gluon_resnet101_v1c model average inference time : 10.626826286315918ms\n",
      "Benchmarking Inference dpn98 \n",
      "dpn98 model average inference time : 16.90117597579956ms\n",
      "Benchmarking Inference xception65 \n",
      "xception65 model average inference time : 15.829980373382568ms\n",
      "Benchmarking Inference lambda_resnet26t \n",
      "lambda_resnet26t model average inference time : 5.875599384307861ms\n",
      "Benchmarking Inference regnety_064 \n",
      "regnety_064 model average inference time : 15.875396728515625ms\n",
      "Benchmarking Inference dpn68b \n",
      "dpn68b model average inference time : 10.908501148223877ms\n",
      "Benchmarking Inference resnetblur50 \n",
      "resnetblur50 model average inference time : 6.055445671081543ms\n",
      "Benchmarking Inference resmlp_24_224 \n",
      "resmlp_24_224 model average inference time : 5.91921329498291ms\n",
      "Benchmarking Inference coat_lite_mini \n",
      "coat_lite_mini model average inference time : 7.606112957000732ms\n",
      "Benchmarking Inference resnet33ts \n",
      "resnet33ts model average inference time : 7.747480869293213ms\n",
      "Benchmarking Inference resnext50_32x4d \n",
      "resnext50_32x4d model average inference time : 6.930999755859375ms\n",
      "Benchmarking Inference regnety_080 \n",
      "regnety_080 model average inference time : 14.40291166305542ms\n",
      "Benchmarking Inference cait_xxs24_224 \n",
      "cait_xxs24_224 model average inference time : 14.687254428863525ms\n",
      "Benchmarking Inference halonet26t \n",
      "halonet26t model average inference time : 5.914363861083984ms\n",
      "Benchmarking Inference xcit_tiny_12_p16_224_dist \n",
      "xcit_tiny_12_p16_224_dist model average inference time : 10.848548412322998ms\n",
      "Benchmarking Inference resnext101_32x8d \n",
      "resnext101_32x8d model average inference time : 19.21564817428589ms\n",
      "Benchmarking Inference gluon_inception_v3 \n",
      "gluon_inception_v3 model average inference time : 10.67434549331665ms\n",
      "Benchmarking Inference resnet32ts \n",
      "resnet32ts model average inference time : 7.546877861022949ms\n",
      "Benchmarking Inference hrnet_w48 \n",
      "hrnet_w48 model average inference time : 35.19402027130127ms\n",
      "Benchmarking Inference regnetx_120 \n",
      "regnetx_120 model average inference time : 21.437790393829346ms\n",
      "Benchmarking Inference tf_efficientnet_b1_ap \n",
      "tf_efficientnet_b1_ap model average inference time : 10.644173622131348ms\n",
      "Benchmarking Inference xception \n",
      "xception model average inference time : 9.606974124908447ms\n",
      "Benchmarking Inference gluon_resnet101_v1b \n",
      "gluon_resnet101_v1b model average inference time : 10.23425579071045ms\n",
      "Benchmarking Inference eca_botnext26ts_256 \n",
      "eca_botnext26ts_256 model average inference time : 6.876101493835449ms\n",
      "Benchmarking Inference gluon_xception65 \n",
      "gluon_xception65 model average inference time : 15.715572834014893ms\n",
      "Benchmarking Inference hrnet_w64 \n",
      "hrnet_w64 model average inference time : 32.55429267883301ms\n",
      "Benchmarking Inference ssl_resnet50 \n",
      "ssl_resnet50 model average inference time : 5.702922344207764ms\n",
      "Benchmarking Inference res2net101_26w_4s \n",
      "res2net101_26w_4s model average inference time : 18.506522178649902ms\n",
      "Benchmarking Inference lambda_resnet26rpt_256 \n",
      "lambda_resnet26rpt_256 model average inference time : 6.532487869262695ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b1_8e \n",
      "tf_efficientnet_cc_b1_8e model average inference time : 12.824573516845703ms\n",
      "Benchmarking Inference xcit_nano_12_p8_384_dist \n",
      "xcit_nano_12_p8_384_dist model average inference time : 14.727818965911865ms\n",
      "Benchmarking Inference gluon_resnext50_32x4d \n",
      "gluon_resnext50_32x4d model average inference time : 6.938610076904297ms\n",
      "Benchmarking Inference tf_efficientnet_b0_ns \n",
      "tf_efficientnet_b0_ns model average inference time : 7.675967216491699ms\n",
      "Benchmarking Inference resnest26d \n",
      "resnest26d model average inference time : 9.267549514770508ms\n",
      "Benchmarking Inference coat_tiny \n",
      "coat_tiny model average inference time : 21.991052627563477ms\n",
      "Benchmarking Inference regnety_040 \n",
      "regnety_040 model average inference time : 12.630414962768555ms\n",
      "Benchmarking Inference eca_halonext26ts \n",
      "eca_halonext26ts model average inference time : 6.973214149475098ms\n",
      "Benchmarking Inference dla169 \n",
      "dla169 model average inference time : 16.798508167266846ms\n",
      "Benchmarking Inference legacy_seresnext50_32x4d \n",
      "legacy_seresnext50_32x4d model average inference time : 10.038816928863525ms\n",
      "Benchmarking Inference tf_efficientnet_b1 \n",
      "tf_efficientnet_b1 model average inference time : 10.78035593032837ms\n",
      "Benchmarking Inference hrnet_w44 \n",
      "hrnet_w44 model average inference time : 34.98673677444458ms\n",
      "Benchmarking Inference regnetx_080 \n",
      "regnetx_080 model average inference time : 16.292753219604492ms\n",
      "Benchmarking Inference gluon_resnet50_v1s \n",
      "gluon_resnet50_v1s model average inference time : 6.087207794189453ms\n",
      "Benchmarking Inference res2net50_26w_8s \n",
      "res2net50_26w_8s model average inference time : 16.367857456207275ms\n",
      "Benchmarking Inference dla60_res2next \n",
      "dla60_res2next model average inference time : 16.325759887695312ms\n",
      "Benchmarking Inference mixnet_l \n",
      "mixnet_l model average inference time : 12.301766872406006ms\n",
      "Benchmarking Inference levit_128 \n",
      "levit_128 model average inference time : 7.933347225189209ms\n",
      "Benchmarking Inference dla60_res2net \n",
      "dla60_res2net model average inference time : 10.874195098876953ms\n",
      "Benchmarking Inference vit_tiny_patch16_384 \n",
      "vit_tiny_patch16_384 model average inference time : 6.9220733642578125ms\n",
      "Benchmarking Inference tv_resnet152 \n",
      "tv_resnet152 model average inference time : 15.094912052154541ms\n",
      "Benchmarking Inference dla102x \n",
      "dla102x model average inference time : 12.951178550720215ms\n",
      "Benchmarking Inference gluon_resnet50_v1d \n",
      "gluon_resnet50_v1d model average inference time : 6.055865287780762ms\n",
      "Benchmarking Inference xception41 \n",
      "xception41 model average inference time : 11.543443202972412ms\n",
      "Benchmarking Inference regnetx_064 \n",
      "regnetx_064 model average inference time : 10.908219814300537ms\n",
      "Benchmarking Inference pit_xs_224 \n",
      "pit_xs_224 model average inference time : 5.7231831550598145ms\n",
      "Benchmarking Inference hrnet_w40 \n",
      "hrnet_w40 model average inference time : 32.60390758514404ms\n",
      "Benchmarking Inference repvgg_b2 \n",
      "repvgg_b2 model average inference time : 13.433892726898193ms\n",
      "Benchmarking Inference res2net50_26w_6s \n",
      "res2net50_26w_6s model average inference time : 12.873594760894775ms\n",
      "Benchmarking Inference resmlp_12_distilled_224 \n",
      "resmlp_12_distilled_224 model average inference time : 3.4597349166870117ms\n",
      "Benchmarking Inference legacy_seresnet152 \n",
      "legacy_seresnet152 model average inference time : 26.90204620361328ms\n",
      "Benchmarking Inference selecsls60b \n",
      "selecsls60b model average inference time : 6.84145450592041ms\n",
      "Benchmarking Inference hrnet_w32 \n",
      "hrnet_w32 model average inference time : 31.0402512550354ms\n",
      "Benchmarking Inference bat_resnext26ts \n",
      "bat_resnext26ts model average inference time : 12.601232528686523ms\n",
      "Benchmarking Inference tf_efficientnetv2_b0 \n",
      "tf_efficientnetv2_b0 model average inference time : 9.29147481918335ms\n",
      "Benchmarking Inference efficientnet_b1 \n",
      "efficientnet_b1 model average inference time : 10.691587924957275ms\n",
      "Benchmarking Inference regnetx_040 \n",
      "regnetx_040 model average inference time : 9.5054292678833ms\n",
      "Benchmarking Inference hrnet_w30 \n",
      "hrnet_w30 model average inference time : 32.41853475570679ms\n",
      "Benchmarking Inference efficientnet_es \n",
      "efficientnet_es model average inference time : 4.870438575744629ms\n",
      "Benchmarking Inference tf_mixnet_l \n",
      "tf_mixnet_l model average inference time : 12.193045616149902ms\n",
      "Benchmarking Inference wide_resnet101_2 \n",
      "wide_resnet101_2 model average inference time : 18.46719264984131ms\n",
      "Benchmarking Inference dla60x \n",
      "dla60x model average inference time : 7.684717178344727ms\n",
      "Benchmarking Inference legacy_seresnet101 \n",
      "legacy_seresnet101 model average inference time : 17.37694501876831ms\n",
      "Benchmarking Inference resnet26t \n",
      "resnet26t model average inference time : 5.499708652496338ms\n",
      "Benchmarking Inference tf_efficientnet_em \n",
      "tf_efficientnet_em model average inference time : 6.13384485244751ms\n",
      "Benchmarking Inference coat_lite_tiny \n",
      "coat_lite_tiny model average inference time : 7.582681179046631ms\n",
      "Benchmarking Inference efficientnet_b1_pruned \n",
      "efficientnet_b1_pruned model average inference time : 10.10892629623413ms\n",
      "Benchmarking Inference repvgg_b1 \n",
      "repvgg_b1 model average inference time : 10.291106700897217ms\n",
      "Benchmarking Inference res2net50_26w_4s \n",
      "res2net50_26w_4s model average inference time : 9.515554904937744ms\n",
      "Benchmarking Inference hardcorenas_f \n",
      "hardcorenas_f model average inference time : 7.830562591552734ms\n",
      "Benchmarking Inference res2net50_14w_8s \n",
      "res2net50_14w_8s model average inference time : 15.560951232910156ms\n",
      "Benchmarking Inference selecsls60 \n",
      "selecsls60 model average inference time : 6.938221454620361ms\n",
      "Benchmarking Inference res2next50 \n",
      "res2next50 model average inference time : 16.08792781829834ms\n",
      "Benchmarking Inference regnetx_032 \n",
      "regnetx_032 model average inference time : 9.0372633934021ms\n",
      "Benchmarking Inference gluon_resnet50_v1c \n",
      "gluon_resnet50_v1c model average inference time : 6.0350871086120605ms\n",
      "Benchmarking Inference dla102 \n",
      "dla102 model average inference time : 10.91986894607544ms\n",
      "Benchmarking Inference gcresnext26ts \n",
      "gcresnext26ts model average inference time : 7.534244060516357ms\n",
      "Benchmarking Inference rexnet_100 \n",
      "rexnet_100 model average inference time : 8.551814556121826ms\n",
      "Benchmarking Inference tf_inception_v3 \n",
      "tf_inception_v3 model average inference time : 10.817878246307373ms\n",
      "Benchmarking Inference seresnext26ts \n",
      "seresnext26ts model average inference time : 7.277858257293701ms\n",
      "Benchmarking Inference res2net50_48w_2s \n",
      "res2net50_48w_2s model average inference time : 6.6150736808776855ms\n",
      "Benchmarking Inference resnet34d \n",
      "resnet34d model average inference time : 4.357035160064697ms\n",
      "Benchmarking Inference tf_efficientnet_lite2 \n",
      "tf_efficientnet_lite2 model average inference time : 5.8763909339904785ms\n",
      "Benchmarking Inference xcit_tiny_12_p16_224 \n",
      "xcit_tiny_12_p16_224 model average inference time : 10.531399250030518ms\n",
      "Benchmarking Inference efficientnet_b0 \n",
      "efficientnet_b0 model average inference time : 7.71547794342041ms\n",
      "Benchmarking Inference crossvit_9_dagger_240 \n",
      "crossvit_9_dagger_240 model average inference time : 8.982396125793457ms\n",
      "Benchmarking Inference hardcorenas_e \n",
      "hardcorenas_e model average inference time : 7.651188373565674ms\n",
      "Benchmarking Inference gmixer_24_224 \n",
      "gmixer_24_224 model average inference time : 8.50656270980835ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b0_8e \n",
      "tf_efficientnet_cc_b0_8e model average inference time : 9.615633487701416ms\n",
      "Benchmarking Inference regnety_016 \n",
      "regnety_016 model average inference time : 13.364031314849854ms\n",
      "Benchmarking Inference tv_resnext50_32x4d \n",
      "tv_resnext50_32x4d model average inference time : 6.845822334289551ms\n",
      "Benchmarking Inference gluon_resnet50_v1b \n",
      "gluon_resnet50_v1b model average inference time : 5.973658561706543ms\n",
      "Benchmarking Inference densenet161 \n",
      "densenet161 model average inference time : 18.15948724746704ms\n",
      "Benchmarking Inference seresnext26t_32x4d \n",
      "seresnext26t_32x4d model average inference time : 5.853981971740723ms\n",
      "Benchmarking Inference mobilenetv2_120d \n",
      "mobilenetv2_120d model average inference time : 6.594960689544678ms\n",
      "Benchmarking Inference adv_inception_v3 \n",
      "adv_inception_v3 model average inference time : 10.414693355560303ms\n",
      "Benchmarking Inference tv_resnet101 \n",
      "tv_resnet101 model average inference time : 10.301275253295898ms\n",
      "Benchmarking Inference inception_v3 \n",
      "inception_v3 model average inference time : 10.332717895507812ms\n",
      "Benchmarking Inference hardcorenas_d \n",
      "hardcorenas_d model average inference time : 7.835903167724609ms\n",
      "Benchmarking Inference dla60 \n",
      "dla60 model average inference time : 6.874604225158691ms\n",
      "Benchmarking Inference xcit_nano_12_p8_224_dist \n",
      "xcit_nano_12_p8_224_dist model average inference time : 10.589027404785156ms\n",
      "Benchmarking Inference seresnext26d_32x4d \n",
      "seresnext26d_32x4d model average inference time : 5.94174861907959ms\n",
      "Benchmarking Inference repvgg_b1g4 \n",
      "repvgg_b1g4 model average inference time : 15.80167293548584ms\n",
      "Benchmarking Inference eca_resnext26ts \n",
      "eca_resnext26ts model average inference time : 6.937901973724365ms\n",
      "Benchmarking Inference convmixer_1024_20_ks9_p14 \n",
      "pass convmixer_1024_20_ks9_p14\n",
      "Benchmarking Inference legacy_seresnet50 \n",
      "legacy_seresnet50 model average inference time : 8.896877765655518ms\n",
      "Benchmarking Inference tf_efficientnet_b0_ap \n",
      "tf_efficientnet_b0_ap model average inference time : 7.774972915649414ms\n",
      "Benchmarking Inference skresnet34 \n",
      "skresnet34 model average inference time : 11.584069728851318ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b0_4e \n",
      "tf_efficientnet_cc_b0_4e model average inference time : 9.464902877807617ms\n",
      "Benchmarking Inference resmlp_12_224 \n",
      "resmlp_12_224 model average inference time : 3.5370802879333496ms\n",
      "Benchmarking Inference mobilenetv3_large_100_miil \n",
      "mobilenetv3_large_100_miil model average inference time : 6.127316951751709ms\n",
      "Benchmarking Inference densenet201 \n",
      "densenet201 model average inference time : 23.181421756744385ms\n",
      "Benchmarking Inference gernet_s \n",
      "gernet_s model average inference time : 5.058321952819824ms\n",
      "Benchmarking Inference legacy_seresnext26_32x4d \n",
      "legacy_seresnext26_32x4d model average inference time : 5.573861598968506ms\n",
      "Benchmarking Inference mixnet_m \n",
      "mixnet_m model average inference time : 11.969778537750244ms\n",
      "Benchmarking Inference tf_efficientnet_b0 \n",
      "tf_efficientnet_b0 model average inference time : 7.811639308929443ms\n",
      "Benchmarking Inference hrnet_w18 \n",
      "hrnet_w18 model average inference time : 30.66925287246704ms\n",
      "Benchmarking Inference densenetblur121d \n",
      "densenetblur121d model average inference time : 13.623583316802979ms\n",
      "Benchmarking Inference selecsls42b \n",
      "selecsls42b model average inference time : 5.443534851074219ms\n",
      "Benchmarking Inference resnext26ts \n",
      "resnext26ts model average inference time : 6.736466884613037ms\n",
      "Benchmarking Inference tf_efficientnet_lite1 \n",
      "tf_efficientnet_lite1 model average inference time : 5.798652172088623ms\n",
      "Benchmarking Inference hardcorenas_c \n",
      "hardcorenas_c model average inference time : 6.024746894836426ms\n",
      "Benchmarking Inference regnetx_016 \n",
      "regnetx_016 model average inference time : 7.071018218994141ms\n",
      "Benchmarking Inference mobilenetv2_140 \n",
      "mobilenetv2_140 model average inference time : 4.40061092376709ms\n",
      "Benchmarking Inference tf_mixnet_m \n",
      "tf_mixnet_m model average inference time : 12.423973083496094ms\n",
      "Benchmarking Inference xcit_nano_12_p16_384_dist \n",
      "xcit_nano_12_p16_384_dist model average inference time : 12.061982154846191ms\n",
      "Benchmarking Inference dpn68 \n",
      "dpn68 model average inference time : 9.955165386199951ms\n",
      "Benchmarking Inference tf_efficientnet_es \n",
      "tf_efficientnet_es model average inference time : 4.856016635894775ms\n",
      "Benchmarking Inference ese_vovnet19b_dw \n",
      "ese_vovnet19b_dw model average inference time : 4.253544807434082ms\n",
      "Benchmarking Inference levit_128s \n",
      "levit_128s model average inference time : 6.265995502471924ms\n",
      "Benchmarking Inference resnet26d \n",
      "resnet26d model average inference time : 3.8224124908447266ms\n",
      "Benchmarking Inference repvgg_a2 \n",
      "repvgg_a2 model average inference time : 5.8386993408203125ms\n",
      "Benchmarking Inference tv_resnet50 \n",
      "tv_resnet50 model average inference time : 5.7837748527526855ms\n",
      "Benchmarking Inference hardcorenas_b \n",
      "hardcorenas_b model average inference time : 5.311298370361328ms\n",
      "Benchmarking Inference densenet121 \n",
      "densenet121 model average inference time : 13.615849018096924ms\n",
      "Benchmarking Inference vit_tiny_r_s16_p8_384 \n",
      "vit_tiny_r_s16_p8_384 model average inference time : 6.8675947189331055ms\n",
      "Benchmarking Inference densenet169 \n",
      "densenet169 model average inference time : 18.92897605895996ms\n",
      "Benchmarking Inference mixnet_s \n",
      "mixnet_s model average inference time : 9.72402811050415ms\n",
      "Benchmarking Inference vit_small_patch32_224 \n",
      "vit_small_patch32_224 model average inference time : 5.379784107208252ms\n",
      "Benchmarking Inference regnety_008 \n",
      "regnety_008 model average inference time : 7.877047061920166ms\n",
      "Benchmarking Inference efficientnet_lite0 \n",
      "efficientnet_lite0 model average inference time : 4.536440372467041ms\n",
      "Benchmarking Inference resnest14d \n",
      "resnest14d model average inference time : 6.846880912780762ms\n",
      "Benchmarking Inference hardcorenas_a \n",
      "hardcorenas_a model average inference time : 4.780862331390381ms\n",
      "Benchmarking Inference efficientnet_es_pruned \n",
      "efficientnet_es_pruned model average inference time : 4.655544757843018ms\n",
      "Benchmarking Inference mobilenetv3_rw \n",
      "mobilenetv3_rw model average inference time : 5.929827690124512ms\n",
      "Benchmarking Inference semnasnet_100 \n",
      "semnasnet_100 model average inference time : 5.908637046813965ms\n",
      "Benchmarking Inference mobilenetv3_large_100 \n",
      "mobilenetv3_large_100 model average inference time : 5.859463214874268ms\n",
      "Benchmarking Inference resnet34 \n",
      "resnet34 model average inference time : 4.129607677459717ms\n",
      "Benchmarking Inference mobilenetv2_110d \n",
      "mobilenetv2_110d model average inference time : 5.588924884796143ms\n",
      "Benchmarking Inference vit_tiny_patch16_224 \n",
      "vit_tiny_patch16_224 model average inference time : 5.516154766082764ms\n",
      "Benchmarking Inference tf_mixnet_s \n",
      "tf_mixnet_s model average inference time : 10.012834072113037ms\n",
      "Benchmarking Inference repvgg_b0 \n",
      "repvgg_b0 model average inference time : 6.786749362945557ms\n",
      "Benchmarking Inference deit_tiny_distilled_patch16_224 \n",
      "deit_tiny_distilled_patch16_224 model average inference time : 5.5579423904418945ms\n",
      "Benchmarking Inference mixer_b16_224 \n",
      "mixer_b16_224 model average inference time : 4.947319030761719ms\n",
      "Benchmarking Inference pit_ti_distilled_224 \n",
      "pit_ti_distilled_224 model average inference time : 5.8206987380981445ms\n",
      "Benchmarking Inference hrnet_w18_small_v2 \n",
      "hrnet_w18_small_v2 model average inference time : 16.512372493743896ms\n",
      "Benchmarking Inference tf_efficientnet_lite0 \n",
      "tf_efficientnet_lite0 model average inference time : 4.607882499694824ms\n",
      "Benchmarking Inference resnet26 \n",
      "resnet26 model average inference time : 3.6391830444335938ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_100 \n",
      "tf_mobilenetv3_large_100 model average inference time : 6.069750785827637ms\n",
      "Benchmarking Inference tv_densenet121 \n",
      "tv_densenet121 model average inference time : 13.906161785125732ms\n",
      "Benchmarking Inference regnety_006 \n",
      "regnety_006 model average inference time : 8.466055393218994ms\n",
      "Benchmarking Inference dla34 \n",
      "dla34 model average inference time : 4.545648097991943ms\n",
      "Benchmarking Inference xcit_nano_12_p8_224 \n",
      "xcit_nano_12_p8_224 model average inference time : 10.769472122192383ms\n",
      "Benchmarking Inference crossvit_9_240 \n",
      "crossvit_9_240 model average inference time : 8.07368516921997ms\n",
      "Benchmarking Inference fbnetc_100 \n",
      "fbnetc_100 model average inference time : 5.538060665130615ms\n",
      "Benchmarking Inference legacy_seresnet34 \n",
      "legacy_seresnet34 model average inference time : 7.063846588134766ms\n",
      "Benchmarking Inference regnetx_008 \n",
      "regnetx_008 model average inference time : 5.988619327545166ms\n",
      "Benchmarking Inference gluon_resnet34_v1b \n",
      "gluon_resnet34_v1b model average inference time : 4.21140193939209ms\n",
      "Benchmarking Inference mnasnet_100 \n",
      "mnasnet_100 model average inference time : 4.459197521209717ms\n",
      "Benchmarking Inference vgg19_bn \n",
      "vgg19_bn model average inference time : 12.287020683288574ms\n",
      "Benchmarking Inference convit_tiny \n",
      "convit_tiny model average inference time : 7.187743186950684ms\n",
      "Benchmarking Inference crossvit_tiny_240 \n",
      "crossvit_tiny_240 model average inference time : 9.558379650115967ms\n",
      "Benchmarking Inference spnasnet_100 \n",
      "spnasnet_100 model average inference time : 5.14542818069458ms\n",
      "Benchmarking Inference ghostnet_100 \n",
      "ghostnet_100 model average inference time : 8.943958282470703ms\n",
      "Benchmarking Inference regnety_004 \n",
      "regnety_004 model average inference time : 10.081777572631836ms\n",
      "Benchmarking Inference skresnet18 \n",
      "skresnet18 model average inference time : 6.504323482513428ms\n",
      "Benchmarking Inference regnetx_006 \n",
      "regnetx_006 model average inference time : 5.666806697845459ms\n",
      "Benchmarking Inference pit_ti_224 \n",
      "pit_ti_224 model average inference time : 5.444982051849365ms\n",
      "Benchmarking Inference swsl_resnet18 \n",
      "swsl_resnet18 model average inference time : 3.0446243286132812ms\n",
      "Benchmarking Inference vgg16_bn \n",
      "vgg16_bn model average inference time : 10.70775032043457ms\n",
      "Benchmarking Inference resnet18d \n",
      "resnet18d model average inference time : 3.114156723022461ms\n",
      "Benchmarking Inference tv_resnet34 \n",
      "tv_resnet34 model average inference time : 4.152665138244629ms\n",
      "Benchmarking Inference mobilenetv2_100 \n",
      "mobilenetv2_100 model average inference time : 4.405169486999512ms\n",
      "Benchmarking Inference xcit_nano_12_p16_224_dist \n",
      "xcit_nano_12_p16_224_dist model average inference time : 10.719523429870605ms\n",
      "Benchmarking Inference vit_base_patch32_sam_224 \n",
      "vit_base_patch32_sam_224 model average inference time : 5.497896671295166ms\n",
      "Benchmarking Inference ssl_resnet18 \n",
      "ssl_resnet18 model average inference time : 2.874293327331543ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_075 \n",
      "tf_mobilenetv3_large_075 model average inference time : 6.034748554229736ms\n",
      "Benchmarking Inference deit_tiny_patch16_224 \n",
      "deit_tiny_patch16_224 model average inference time : 5.433828830718994ms\n",
      "Benchmarking Inference hrnet_w18_small \n",
      "hrnet_w18_small model average inference time : 9.587922096252441ms\n",
      "Benchmarking Inference vgg19 \n",
      "vgg19 model average inference time : 11.49423360824585ms\n",
      "Benchmarking Inference regnetx_004 \n",
      "regnetx_004 model average inference time : 9.168562889099121ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_minimal_100 \n",
      "tf_mobilenetv3_large_minimal_100 model average inference time : 4.529573917388916ms\n",
      "Benchmarking Inference legacy_seresnet18 \n",
      "legacy_seresnet18 model average inference time : 4.25100564956665ms\n",
      "Benchmarking Inference vgg16 \n",
      "vgg16 model average inference time : 9.980151653289795ms\n",
      "Benchmarking Inference vit_tiny_r_s16_p8_224 \n",
      "vit_tiny_r_s16_p8_224 model average inference time : 5.7746124267578125ms\n",
      "Benchmarking Inference vgg13_bn \n",
      "vgg13_bn model average inference time : 9.128279685974121ms\n",
      "Benchmarking Inference gluon_resnet18_v1b \n",
      "gluon_resnet18_v1b model average inference time : 2.7234983444213867ms\n",
      "Benchmarking Inference vgg11_bn \n",
      "vgg11_bn model average inference time : 7.460498809814453ms\n",
      "Benchmarking Inference xcit_nano_12_p16_224 \n",
      "xcit_nano_12_p16_224 model average inference time : 10.70732831954956ms\n",
      "Benchmarking Inference regnety_002 \n",
      "regnety_002 model average inference time : 8.627853393554688ms\n",
      "Benchmarking Inference mixer_l16_224 \n",
      "mixer_l16_224 model average inference time : 15.586493015289307ms\n",
      "Benchmarking Inference resnet18 \n",
      "resnet18 model average inference time : 2.734816074371338ms\n",
      "Benchmarking Inference vgg13 \n",
      "vgg13 model average inference time : 8.471179008483887ms\n",
      "Benchmarking Inference vgg11 \n",
      "vgg11 model average inference time : 7.014648914337158ms\n",
      "Benchmarking Inference regnetx_002 \n",
      "regnetx_002 model average inference time : 5.994873046875ms\n",
      "Benchmarking Inference dla60x_c \n",
      "dla60x_c model average inference time : 6.110951900482178ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_100 \n",
      "tf_mobilenetv3_small_100 model average inference time : 5.060420036315918ms\n",
      "Benchmarking Inference dla46x_c \n",
      "dla46x_c model average inference time : 4.974346160888672ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_075 \n",
      "tf_mobilenetv3_small_075 model average inference time : 5.441930294036865ms\n",
      "Benchmarking Inference dla46_c \n",
      "dla46_c model average inference time : 5.222153663635254ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_minimal_100 \n",
      "tf_mobilenetv3_small_minimal_100 model average inference time : 3.5568642616271973ms\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beit_large_patch16_512': {'fp32': 187.82024145126343,\n",
       "  'top1': 90.695,\n",
       "  'imsize': 512},\n",
       " 'beit_large_patch16_384': {'fp32': 78.99953365325928,\n",
       "  'top1': 90.601,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnet_l2_ns': {'fp32': 605.894718170166,\n",
       "  'top1': 90.572,\n",
       "  'imsize': 800},\n",
       " 'tf_efficientnet_l2_ns_475': {'fp32': 255.02083778381348,\n",
       "  'top1': 90.527,\n",
       "  'imsize': 475},\n",
       " 'beit_base_patch16_384': {'fp32': 30.691065788269043,\n",
       "  'top1': 90.388,\n",
       "  'imsize': 384},\n",
       " 'vit_large_patch16_384': {'fp32': 67.07225799560547,\n",
       "  'top1': 90.202,\n",
       "  'imsize': 384},\n",
       " 'cait_m48_448': {'fp32': 482.82698154449463, 'top1': 90.194, 'imsize': 448},\n",
       " 'beit_large_patch16_224': {'fp32': 22.189147472381592,\n",
       "  'top1': 90.157,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b7_ns': {'fp32': 92.80160427093506,\n",
       "  'top1': 90.134,\n",
       "  'imsize': 600},\n",
       " 'swin_large_patch4_window12_384': {'fp32': 54.970736503601074,\n",
       "  'top1': 90.066,\n",
       "  'imsize': 384},\n",
       " 'swin_base_patch4_window12_384': {'fp32': 34.66608285903931,\n",
       "  'top1': 90.063,\n",
       "  'imsize': 384},\n",
       " 'cait_m36_384': {'fp32': 207.59344577789307, 'top1': 90.046, 'imsize': 384},\n",
       " 'dm_nfnet_f6': {'fp32': 674.3886399269104, 'top1': 90.025, 'imsize': 576},\n",
       " 'tf_efficientnetv2_l_in21ft1k': {'fp32': 71.21510028839111,\n",
       "  'top1': 89.999,\n",
       "  'imsize': 480},\n",
       " 'vit_base_patch16_384': {'fp32': 26.030404567718506,\n",
       "  'top1': 89.965,\n",
       "  'imsize': 384},\n",
       " 'xcit_large_24_p8_384_dist': {'fp32': 171.45898818969727,\n",
       "  'top1': 89.893,\n",
       "  'imsize': 384},\n",
       " 'cait_s36_384': {'fp32': 100.20755052566528, 'top1': 89.837, 'imsize': 384},\n",
       " 'xcit_medium_24_p8_384_dist': {'fp32': 103.04621696472168,\n",
       "  'top1': 89.805,\n",
       "  'imsize': 384},\n",
       " 'swin_large_patch4_window7_224': {'fp32': 17.773497104644775,\n",
       "  'top1': 89.796,\n",
       "  'imsize': 224},\n",
       " 'vit_large_r50_s32_384': {'fp32': 30.787925720214844,\n",
       "  'top1': 89.79,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnetv2_m_in21ft1k': {'fp32': 36.46842956542969,\n",
       "  'top1': 89.777,\n",
       "  'imsize': 480},\n",
       " 'tf_efficientnet_b6_ns': {'fp32': 53.60628128051758,\n",
       "  'top1': 89.76,\n",
       "  'imsize': 528},\n",
       " 'xcit_small_24_p8_384_dist': {'fp32': 75.44042110443115,\n",
       "  'top1': 89.737,\n",
       "  'imsize': 384},\n",
       " 'xcit_large_24_p16_384_dist': {'fp32': 50.514726638793945,\n",
       "  'top1': 89.66,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnet_b5_ns': {'fp32': 32.2252082824707,\n",
       "  'top1': 89.658,\n",
       "  'imsize': 456},\n",
       " 'tf_efficientnet_b8_ap': {'fp32': 137.45931386947632,\n",
       "  'top1': 89.589,\n",
       "  'imsize': 672},\n",
       " 'tf_efficientnetv2_xl_in21ft1k': {'fp32': 112.2532606124878,\n",
       "  'top1': 89.566,\n",
       "  'imsize': 512},\n",
       " 'dm_nfnet_f4': {'fp32': 673.0227756500244, 'top1': 89.538, 'imsize': 512},\n",
       " 'xcit_small_12_p8_384_dist': {'fp32': 41.17788314819336,\n",
       "  'top1': 89.525,\n",
       "  'imsize': 384},\n",
       " 'xcit_large_24_p8_224_dist': {'fp32': 69.23095703125,\n",
       "  'top1': 89.519,\n",
       "  'imsize': 224},\n",
       " 'cait_s24_384': {'fp32': 67.38134145736694, 'top1': 89.5, 'imsize': 384},\n",
       " 'dm_nfnet_f3': {'fp32': 293.33019971847534, 'top1': 89.478, 'imsize': 416},\n",
       " 'xcit_medium_24_p16_384_dist': {'fp32': 31.06527328491211,\n",
       "  'top1': 89.476,\n",
       "  'imsize': 384},\n",
       " 'dm_nfnet_f5': {'fp32': 796.1416149139404, 'top1': 89.451, 'imsize': 544},\n",
       " 'beit_base_patch16_224': {'fp32': 7.706115245819092,\n",
       "  'top1': 89.438,\n",
       "  'imsize': 224},\n",
       " 'deit_base_distilled_patch16_384': {'fp32': 26.1637544631958,\n",
       "  'top1': 89.431,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnet_b7_ap': {'fp32': 92.97600269317627,\n",
       "  'top1': 89.419,\n",
       "  'imsize': 600},\n",
       " 'tf_efficientnetv2_l': {'fp32': 71.10381603240967,\n",
       "  'top1': 89.361,\n",
       "  'imsize': 480},\n",
       " 'tf_efficientnet_b6_ap': {'fp32': 53.76356601715088,\n",
       "  'top1': 89.338,\n",
       "  'imsize': 528},\n",
       " 'tf_efficientnet_b8': {'fp32': 137.50638723373413,\n",
       "  'top1': 89.338,\n",
       "  'imsize': 672},\n",
       " 'tf_efficientnet_b4_ns': {'fp32': 17.170755863189697,\n",
       "  'top1': 89.323,\n",
       "  'imsize': 380},\n",
       " 'vit_large_patch16_224': {'fp32': 20.631911754608154,\n",
       "  'top1': 89.308,\n",
       "  'imsize': 224},\n",
       " 'xcit_small_24_p16_384_dist': {'fp32': 21.862990856170654,\n",
       "  'top1': 89.305,\n",
       "  'imsize': 384},\n",
       " 'xcit_medium_24_p8_224_dist': {'fp32': 41.71958923339844,\n",
       "  'top1': 89.286,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnetv2_m': {'fp32': 36.42159700393677,\n",
       "  'top1': 89.284,\n",
       "  'imsize': 480},\n",
       " 'xcit_small_24_p8_224_dist': {'fp32': 29.802353382110596,\n",
       "  'top1': 89.207,\n",
       "  'imsize': 224},\n",
       " 'xcit_small_12_p16_384_dist': {'fp32': 12.899026870727539,\n",
       "  'top1': 89.203,\n",
       "  'imsize': 384},\n",
       " 'swin_base_patch4_window7_224': {'fp32': 13.011953830718994,\n",
       "  'top1': 89.19,\n",
       "  'imsize': 224},\n",
       " 'eca_nfnet_l2': {'fp32': 72.88344383239746, 'top1': 89.158, 'imsize': 384},\n",
       " 'cait_xs24_384': {'fp32': 48.50192308425903, 'top1': 89.143, 'imsize': 384},\n",
       " 'ig_resnext101_32x32d': {'fp32': 133.60260248184204,\n",
       "  'top1': 89.109,\n",
       "  'imsize': 224},\n",
       " 'ig_resnext101_32x48d': {'fp32': 211.29178524017334,\n",
       "  'top1': 89.107,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b7': {'fp32': 92.60906219482422,\n",
       "  'top1': 89.086,\n",
       "  'imsize': 600},\n",
       " 'ecaresnet269d': {'fp32': 50.559325218200684, 'top1': 89.075, 'imsize': 352},\n",
       " 'xcit_large_24_p16_224_dist': {'fp32': 19.935379028320312,\n",
       "  'top1': 89.045,\n",
       "  'imsize': 224},\n",
       " 'resmlp_big_24_224_in22ft1k': {'fp32': 34.1888689994812,\n",
       "  'top1': 89.019,\n",
       "  'imsize': 224},\n",
       " 'xcit_small_12_p8_224_dist': {'fp32': 16.16833209991455,\n",
       "  'top1': 89.007,\n",
       "  'imsize': 224},\n",
       " 'efficientnetv2_rw_m': {'fp32': 31.531519889831543,\n",
       "  'top1': 88.994,\n",
       "  'imsize': 416},\n",
       " 'dm_nfnet_f2': {'fp32': 186.10388040542603, 'top1': 88.985, 'imsize': 352},\n",
       " 'tf_efficientnet_b5_ap': {'fp32': 32.31218338012695,\n",
       "  'top1': 88.936,\n",
       "  'imsize': 456},\n",
       " 'dm_nfnet_f1': {'fp32': 110.46903133392334, 'top1': 88.915, 'imsize': 320},\n",
       " 'tf_efficientnetv2_s_in21ft1k': {'fp32': 18.91585111618042,\n",
       "  'top1': 88.889,\n",
       "  'imsize': 384},\n",
       " 'vit_base_patch16_224': {'fp32': 7.194774150848389,\n",
       "  'top1': 88.857,\n",
       "  'imsize': 224},\n",
       " 'resnetrs270': {'fp32': 57.51713991165161, 'top1': 88.836, 'imsize': 352},\n",
       " 'resnetrs420': {'fp32': 122.52376556396484, 'top1': 88.832, 'imsize': 416},\n",
       " 'vit_small_r26_s32_384': {'fp32': 12.894129753112793,\n",
       "  'top1': 88.814,\n",
       "  'imsize': 384},\n",
       " 'xcit_medium_24_p16_224_dist': {'fp32': 18.943955898284912,\n",
       "  'top1': 88.806,\n",
       "  'imsize': 224},\n",
       " 'ig_resnext101_32x16d': {'fp32': 35.64459562301636,\n",
       "  'top1': 88.804,\n",
       "  'imsize': 224},\n",
       " 'seresnet152d': {'fp32': 32.0986533164978, 'top1': 88.804, 'imsize': 320},\n",
       " 'vit_base_r50_s16_384': {'fp32': 38.8896918296814,\n",
       "  'top1': 88.804,\n",
       "  'imsize': 384},\n",
       " 'xcit_tiny_24_p8_384_dist': {'fp32': 38.72120141983032,\n",
       "  'top1': 88.784,\n",
       "  'imsize': 384},\n",
       " 'resnetrs350': {'fp32': 80.04353284835815, 'top1': 88.757, 'imsize': 384},\n",
       " 'swsl_resnext101_32x8d': {'fp32': 19.377267360687256,\n",
       "  'top1': 88.757,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b6': {'fp32': 53.68501663208008,\n",
       "  'top1': 88.757,\n",
       "  'imsize': 528},\n",
       " 'vit_base_patch16_224_miil': {'fp32': 6.8964385986328125,\n",
       "  'top1': 88.748,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_152x2_bitm': {'fp32': 126.72324419021606,\n",
       "  'top1': 88.708,\n",
       "  'imsize': 448},\n",
       " 'regnety_160': {'fp32': 72.03325271606445, 'top1': 88.697, 'imsize': 288},\n",
       " 'pit_b_distilled_224': {'fp32': 8.208386898040771,\n",
       "  'top1': 88.678,\n",
       "  'imsize': 224},\n",
       " 'eca_nfnet_l1': {'fp32': 36.295228004455566, 'top1': 88.633, 'imsize': 320},\n",
       " 'vit_small_patch16_384': {'fp32': 11.50310754776001,\n",
       "  'top1': 88.624,\n",
       "  'imsize': 384},\n",
       " 'resnetrs200': {'fp32': 38.42800855636597, 'top1': 88.597, 'imsize': 320},\n",
       " 'resnetv2_152x4_bitm': {'fp32': 443.33802461624146,\n",
       "  'top1': 88.552,\n",
       "  'imsize': 480},\n",
       " 'xcit_small_24_p16_224_dist': {'fp32': 18.701508045196533,\n",
       "  'top1': 88.535,\n",
       "  'imsize': 224},\n",
       " 'resnet200d': {'fp32': 30.455100536346436, 'top1': 88.533, 'imsize': 320},\n",
       " 'resnest269e': {'fp32': 192.0150589942932, 'top1': 88.526, 'imsize': 416},\n",
       " 'efficientnetv2_rw_s': {'fp32': 18.94211769104004,\n",
       "  'top1': 88.484,\n",
       "  'imsize': 384},\n",
       " 'crossvit_18_dagger_408': {'fp32': 28.560023307800293,\n",
       "  'top1': 88.477,\n",
       "  'imsize': 408},\n",
       " 'cait_s24_224': {'fp32': 13.865032196044922, 'top1': 88.451, 'imsize': 224},\n",
       " 'resmlp_big_24_distilled_224': {'fp32': 34.31056261062622,\n",
       "  'top1': 88.447,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b3_ns': {'fp32': 13.225173950195312,\n",
       "  'top1': 88.441,\n",
       "  'imsize': 300},\n",
       " 'resnetv2_101x3_bitm': {'fp32': 164.66094732284546,\n",
       "  'top1': 88.43,\n",
       "  'imsize': 448},\n",
       " 'resnest200e': {'fp32': 88.76918315887451, 'top1': 88.424, 'imsize': 320},\n",
       " 'vit_large_r50_s32_224': {'fp32': 17.111563682556152,\n",
       "  'top1': 88.424,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_50x3_bitm': {'fp32': 95.24729013442993,\n",
       "  'top1': 88.415,\n",
       "  'imsize': 448},\n",
       " 'tf_efficientnetv2_s': {'fp32': 18.8226318359375,\n",
       "  'top1': 88.396,\n",
       "  'imsize': 384},\n",
       " 'efficientnet_b4': {'fp32': 16.326000690460205,\n",
       "  'top1': 88.366,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnet_b4_ap': {'fp32': 17.07735776901245,\n",
       "  'top1': 88.351,\n",
       "  'imsize': 380},\n",
       " 'resnet152d': {'fp32': 23.476836681365967, 'top1': 88.347, 'imsize': 320},\n",
       " 'tf_efficientnet_b5': {'fp32': 32.18653917312622,\n",
       "  'top1': 88.315,\n",
       "  'imsize': 456},\n",
       " 'crossvit_15_dagger_408': {'fp32': 21.523141860961914,\n",
       "  'top1': 88.298,\n",
       "  'imsize': 408},\n",
       " 'xcit_small_12_p16_224_dist': {'fp32': 10.751307010650635,\n",
       "  'top1': 88.251,\n",
       "  'imsize': 224},\n",
       " 'resnetrs152': {'fp32': 29.93964433670044, 'top1': 88.246, 'imsize': 320},\n",
       " 'deit_base_distilled_patch16_224': {'fp32': 7.11979866027832,\n",
       "  'top1': 88.217,\n",
       "  'imsize': 224},\n",
       " 'ig_resnext101_32x8d': {'fp32': 19.309463500976562,\n",
       "  'top1': 88.161,\n",
       "  'imsize': 224},\n",
       " 'xcit_large_24_p8_224': {'fp32': 68.4595251083374,\n",
       "  'top1': 88.161,\n",
       "  'imsize': 224},\n",
       " 'xcit_tiny_24_p16_384_dist': {'fp32': 19.728000164031982,\n",
       "  'top1': 88.161,\n",
       "  'imsize': 384},\n",
       " 'cait_xxs36_384': {'fp32': 47.40362882614136, 'top1': 88.142, 'imsize': 384},\n",
       " 'resnetv2_152x2_bit_teacher_384': {'fp32': 93.72071504592896,\n",
       "  'top1': 88.142,\n",
       "  'imsize': 384},\n",
       " 'dm_nfnet_f0': {'fp32': 54.49422359466553, 'top1': 88.135, 'imsize': 256},\n",
       " 'xcit_tiny_12_p8_384_dist': {'fp32': 21.0379695892334,\n",
       "  'top1': 88.093,\n",
       "  'imsize': 384},\n",
       " 'swsl_resnext101_32x4d': {'fp32': 12.531745433807373,\n",
       "  'top1': 88.086,\n",
       "  'imsize': 224},\n",
       " 'xcit_tiny_24_p8_224_dist': {'fp32': 18.32463264465332,\n",
       "  'top1': 88.048,\n",
       "  'imsize': 224},\n",
       " 'nfnet_l0': {'fp32': 17.827935218811035, 'top1': 87.98, 'imsize': 288},\n",
       " 'xcit_small_24_p8_224': {'fp32': 29.85724687576294,\n",
       "  'top1': 87.975,\n",
       "  'imsize': 224},\n",
       " 'eca_nfnet_l0': {'fp32': 16.57299041748047, 'top1': 87.973, 'imsize': 288},\n",
       " 'tf_efficientnet_b4': {'fp32': 17.05153465270996,\n",
       "  'top1': 87.963,\n",
       "  'imsize': 380},\n",
       " 'resnet101d': {'fp32': 16.95774555206299, 'top1': 87.945, 'imsize': 320},\n",
       " 'regnety_032': {'fp32': 14.156250953674316, 'top1': 87.926, 'imsize': 288},\n",
       " 'twins_svt_large': {'fp32': 14.584264755249023,\n",
       "  'top1': 87.907,\n",
       "  'imsize': 224},\n",
       " 'vit_base_patch32_384': {'fp32': 7.528364658355713,\n",
       "  'top1': 87.898,\n",
       "  'imsize': 384},\n",
       " 'twins_pcpvt_large': {'fp32': 24.0313982963562,\n",
       "  'top1': 87.879,\n",
       "  'imsize': 224},\n",
       " 'deit_base_patch16_384': {'fp32': 25.787513256072998,\n",
       "  'top1': 87.852,\n",
       "  'imsize': 384},\n",
       " 'xcit_small_12_p8_224': {'fp32': 16.152489185333252,\n",
       "  'top1': 87.832,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_50x1_bit_distilled': {'fp32': 7.867751121520996,\n",
       "  'top1': 87.802,\n",
       "  'imsize': 224},\n",
       " 'twins_pcpvt_base': {'fp32': 16.90662384033203,\n",
       "  'top1': 87.728,\n",
       "  'imsize': 224},\n",
       " 'gc_efficientnetv2_rw_t': {'fp32': 21.176109313964844,\n",
       "  'top1': 87.717,\n",
       "  'imsize': 288},\n",
       " 'swin_small_patch4_window7_224': {'fp32': 12.731096744537354,\n",
       "  'top1': 87.678,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_101x1_bitm': {'fp32': 36.48170709609985,\n",
       "  'top1': 87.67,\n",
       "  'imsize': 448},\n",
       " 'pnasnet5large': {'fp32': 40.56123971939087, 'top1': 87.657, 'imsize': 331},\n",
       " 'efficientnetv2_rw_t': {'fp32': 16.649351119995117,\n",
       "  'top1': 87.653,\n",
       "  'imsize': 288},\n",
       " 'twins_svt_base': {'fp32': 13.426563739776611, 'top1': 87.629, 'imsize': 224},\n",
       " 'xcit_medium_24_p8_224': {'fp32': 41.39742612838745,\n",
       "  'top1': 87.619,\n",
       "  'imsize': 224},\n",
       " 'jx_nest_base': {'fp32': 13.91737699508667, 'top1': 87.602, 'imsize': 224},\n",
       " 'swsl_resnext101_32x16d': {'fp32': 35.49072742462158,\n",
       "  'top1': 87.595,\n",
       "  'imsize': 224},\n",
       " 'swsl_resnext50_32x4d': {'fp32': 6.893577575683594,\n",
       "  'top1': 87.593,\n",
       "  'imsize': 224},\n",
       " 'levit_384': {'fp32': 7.935302257537842, 'top1': 87.559, 'imsize': 224},\n",
       " 'tf_efficientnet_b2_ns': {'fp32': 11.278343200683594,\n",
       "  'top1': 87.559,\n",
       "  'imsize': 260},\n",
       " 'ecaresnet50t': {'fp32': 11.587045192718506, 'top1': 87.546, 'imsize': 320},\n",
       " 'jx_nest_small': {'fp32': 10.779240131378174, 'top1': 87.495, 'imsize': 224},\n",
       " 'resnetv2_152x2_bit_teacher': {'fp32': 46.39243125915527,\n",
       "  'top1': 87.491,\n",
       "  'imsize': 224},\n",
       " 'efficientnet_b3': {'fp32': 12.699117660522461,\n",
       "  'top1': 87.452,\n",
       "  'imsize': 320},\n",
       " 'resnet61q': {'fp32': 14.191174507141113, 'top1': 87.433, 'imsize': 288},\n",
       " 'cait_xxs24_384': {'fp32': 32.010657787323, 'top1': 87.399, 'imsize': 384},\n",
       " 'resnet51q': {'fp32': 13.165619373321533, 'top1': 87.388, 'imsize': 288},\n",
       " 'xcit_tiny_24_p8_224': {'fp32': 18.40524196624756,\n",
       "  'top1': 87.375,\n",
       "  'imsize': 224},\n",
       " 'coat_lite_small': {'fp32': 12.97208547592163, 'top1': 87.365, 'imsize': 224},\n",
       " 'nasnetalarge': {'fp32': 46.04579448699951, 'top1': 87.352, 'imsize': 331},\n",
       " 'crossvit_18_dagger_240': {'fp32': 12.208788394927979,\n",
       "  'top1': 87.335,\n",
       "  'imsize': 240},\n",
       " 'crossvit_18_240': {'fp32': 11.736171245574951,\n",
       "  'top1': 87.307,\n",
       "  'imsize': 240},\n",
       " 'resnetv2_101': {'fp32': 10.5110764503479, 'top1': 87.296, 'imsize': 224},\n",
       " 'ecaresnet101d': {'fp32': 13.242623805999756, 'top1': 87.281, 'imsize': 224},\n",
       " 'pit_s_distilled_224': {'fp32': 5.834674835205078,\n",
       "  'top1': 87.264,\n",
       "  'imsize': 224},\n",
       " 'resnest101e': {'fp32': 30.416202545166016, 'top1': 87.262, 'imsize': 256},\n",
       " 'resnetrs101': {'fp32': 19.872965812683105, 'top1': 87.243, 'imsize': 288},\n",
       " 'mixer_b16_224_miil': {'fp32': 5.022103786468506,\n",
       "  'top1': 87.23,\n",
       "  'imsize': 224},\n",
       " 'xcit_tiny_12_p8_224_dist': {'fp32': 10.665295124053955,\n",
       "  'top1': 87.224,\n",
       "  'imsize': 224},\n",
       " 'convit_base': {'fp32': 10.28860092163086, 'top1': 87.205, 'imsize': 224},\n",
       " 'xcit_tiny_12_p16_384_dist': {'fp32': 11.922416687011719,\n",
       "  'top1': 87.198,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnet_b3_ap': {'fp32': 13.231754302978516,\n",
       "  'top1': 87.198,\n",
       "  'imsize': 300},\n",
       " 'visformer_small': {'fp32': 12.28888750076294, 'top1': 87.185, 'imsize': 224},\n",
       " 'crossvit_15_dagger_240': {'fp32': 11.585962772369385,\n",
       "  'top1': 87.153,\n",
       "  'imsize': 240},\n",
       " 'xcit_small_24_p16_224': {'fp32': 18.52921724319458,\n",
       "  'top1': 87.136,\n",
       "  'imsize': 224},\n",
       " 'convit_small': {'fp32': 7.213244438171387, 'top1': 87.044, 'imsize': 224},\n",
       " 'crossvit_15_240': {'fp32': 10.648703575134277,\n",
       "  'top1': 87.038,\n",
       "  'imsize': 240},\n",
       " 'jx_nest_tiny': {'fp32': 7.1837568283081055, 'top1': 87.014, 'imsize': 224},\n",
       " 'tf_efficientnetv2_b3': {'fp32': 15.122084617614746,\n",
       "  'top1': 87.014,\n",
       "  'imsize': 300},\n",
       " 'xcit_small_12_p16_224': {'fp32': 10.652329921722412,\n",
       "  'top1': 87.0,\n",
       "  'imsize': 224},\n",
       " 'deit_small_distilled_patch16_224': {'fp32': 5.348119735717773,\n",
       "  'top1': 86.993,\n",
       "  'imsize': 224},\n",
       " 'resmlp_36_distilled_224': {'fp32': 8.671507835388184,\n",
       "  'top1': 86.987,\n",
       "  'imsize': 224},\n",
       " 'xcit_large_24_p16_224': {'fp32': 20.437636375427246,\n",
       "  'top1': 86.961,\n",
       "  'imsize': 224},\n",
       " 'xcit_medium_24_p16_224': {'fp32': 18.789818286895752,\n",
       "  'top1': 86.94,\n",
       "  'imsize': 224},\n",
       " 'tnt_s_patch16_224': {'fp32': 11.689586639404297,\n",
       "  'top1': 86.901,\n",
       "  'imsize': 224},\n",
       " 'rexnet_200': {'fp32': 8.92477035522461, 'top1': 86.854, 'imsize': 224},\n",
       " 'vit_small_patch16_224': {'fp32': 5.119564533233643,\n",
       "  'top1': 86.852,\n",
       "  'imsize': 224},\n",
       " 'ssl_resnext101_32x16d': {'fp32': 35.156073570251465,\n",
       "  'top1': 86.85,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b3': {'fp32': 13.069419860839844,\n",
       "  'top1': 86.842,\n",
       "  'imsize': 300},\n",
       " 'vit_small_r26_s32_224': {'fp32': 9.271328449249268,\n",
       "  'top1': 86.84,\n",
       "  'imsize': 224},\n",
       " 'deit_base_patch16_224': {'fp32': 7.06681489944458,\n",
       "  'top1': 86.827,\n",
       "  'imsize': 224},\n",
       " 'coat_mini': {'fp32': 22.4007511138916, 'top1': 86.81, 'imsize': 224},\n",
       " 'swsl_resnet50': {'fp32': 5.813620090484619, 'top1': 86.801, 'imsize': 224},\n",
       " 'tf_efficientnet_lite4': {'fp32': 12.234175205230713,\n",
       "  'top1': 86.799,\n",
       "  'imsize': 380},\n",
       " 'ssl_resnext101_32x8d': {'fp32': 19.14243459701538,\n",
       "  'top1': 86.797,\n",
       "  'imsize': 224},\n",
       " 'twins_svt_small': {'fp32': 10.650286674499512,\n",
       "  'top1': 86.754,\n",
       "  'imsize': 224},\n",
       " 'crossvit_base_240': {'fp32': 10.563080310821533,\n",
       "  'top1': 86.735,\n",
       "  'imsize': 240},\n",
       " 'levit_256': {'fp32': 7.837703227996826, 'top1': 86.733, 'imsize': 224},\n",
       " 'seresnext50_32x4d': {'fp32': 10.301995277404785,\n",
       "  'top1': 86.705,\n",
       "  'imsize': 224},\n",
       " 'crossvit_small_240': {'fp32': 9.6989107131958,\n",
       "  'top1': 86.705,\n",
       "  'imsize': 240},\n",
       " 'pit_b_224': {'fp32': 8.08917760848999, 'top1': 86.69, 'imsize': 224},\n",
       " 'tf_efficientnet_b1_ns': {'fp32': 10.472583770751953,\n",
       "  'top1': 86.681,\n",
       "  'imsize': 240},\n",
       " 'swin_tiny_patch4_window7_224': {'fp32': 7.131474018096924,\n",
       "  'top1': 86.671,\n",
       "  'imsize': 224},\n",
       " 'gernet_l': {'fp32': 13.107085227966309, 'top1': 86.652, 'imsize': 256},\n",
       " 'wide_resnet50_2': {'fp32': 11.208875179290771,\n",
       "  'top1': 86.647,\n",
       "  'imsize': 224},\n",
       " 'efficientnet_el': {'fp32': 10.83052396774292, 'top1': 86.622, 'imsize': 300},\n",
       " 'twins_pcpvt_small': {'fp32': 10.032284259796143,\n",
       "  'top1': 86.609,\n",
       "  'imsize': 224},\n",
       " 'resmlp_24_distilled_224': {'fp32': 5.817584991455078,\n",
       "  'top1': 86.607,\n",
       "  'imsize': 224},\n",
       " 'nf_resnet50': {'fp32': 10.982763767242432, 'top1': 86.598, 'imsize': 288},\n",
       " 'efficientnet_b3_pruned': {'fp32': 12.468500137329102,\n",
       "  'top1': 86.585,\n",
       "  'imsize': 300},\n",
       " 'sehalonet33ts': {'fp32': 8.082001209259033, 'top1': 86.585, 'imsize': 256},\n",
       " 'resnest50d_4s2x40d': {'fp32': 22.917375564575195,\n",
       "  'top1': 86.581,\n",
       "  'imsize': 224},\n",
       " 'repvgg_b3': {'fp32': 18.94476890563965, 'top1': 86.57, 'imsize': 224},\n",
       " 'xcit_tiny_24_p16_224_dist': {'fp32': 18.10281753540039,\n",
       "  'top1': 86.543,\n",
       "  'imsize': 224},\n",
       " 'ecaresnet50d': {'fp32': 7.554936408996582, 'top1': 86.479, 'imsize': 224},\n",
       " 'ssl_resnext101_32x4d': {'fp32': 12.887659072875977,\n",
       "  'top1': 86.474,\n",
       "  'imsize': 224},\n",
       " 'gcresnet50t': {'fp32': 11.551768779754639, 'top1': 86.459, 'imsize': 256},\n",
       " 'gluon_resnet152_v1s': {'fp32': 14.83774185180664,\n",
       "  'top1': 86.453,\n",
       "  'imsize': 224},\n",
       " 'haloregnetz_b': {'fp32': 14.184448719024658, 'top1': 86.449, 'imsize': 224},\n",
       " 'resnest50d_1s4x24d': {'fp32': 14.150748252868652,\n",
       "  'top1': 86.44,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_50x1_bitm': {'fp32': 20.73434829711914,\n",
       "  'top1': 86.44,\n",
       "  'imsize': 448},\n",
       " 'halonet50ts': {'fp32': 9.944765567779541, 'top1': 86.391, 'imsize': 256},\n",
       " 'lamhalobotnet50ts_256': {'fp32': 9.35840368270874,\n",
       "  'top1': 86.391,\n",
       "  'imsize': 256},\n",
       " 'halo2botnet50ts_256': {'fp32': 10.049488544464111,\n",
       "  'top1': 86.372,\n",
       "  'imsize': 256},\n",
       " 'repvgg_b3g4': {'fp32': 21.52801752090454, 'top1': 86.359, 'imsize': 224},\n",
       " 'legacy_senet154': {'fp32': 35.19254446029663, 'top1': 86.334, 'imsize': 224},\n",
       " 'gernet_m': {'fp32': 5.253360271453857, 'top1': 86.325, 'imsize': 224},\n",
       " 'cait_xxs36_224': {'fp32': 20.466907024383545, 'top1': 86.321, 'imsize': 224},\n",
       " 'pit_s_224': {'fp32': 5.625371932983398, 'top1': 86.319, 'imsize': 224},\n",
       " 'efficientnet_b2': {'fp32': 10.981392860412598, 'top1': 86.31, 'imsize': 288},\n",
       " 'vit_small_patch32_384': {'fp32': 6.989421844482422,\n",
       "  'top1': 86.304,\n",
       "  'imsize': 384},\n",
       " 'gluon_senet154': {'fp32': 34.722769260406494, 'top1': 86.274, 'imsize': 224},\n",
       " 'resnest50d': {'fp32': 13.82352352142334, 'top1': 86.231, 'imsize': 224},\n",
       " 'efficientnet_el_pruned': {'fp32': 10.81190824508667,\n",
       "  'top1': 86.188,\n",
       "  'imsize': 300},\n",
       " 'ecaresnet101d_pruned': {'fp32': 11.961290836334229,\n",
       "  'top1': 86.182,\n",
       "  'imsize': 224},\n",
       " 'rexnet_150': {'fp32': 8.78824234008789, 'top1': 86.165, 'imsize': 224},\n",
       " 'cspdarknet53': {'fp32': 12.3502779006958, 'top1': 86.152, 'imsize': 256},\n",
       " 'inception_v4': {'fp32': 19.56355571746826, 'top1': 86.152, 'imsize': 299},\n",
       " 'inception_resnet_v2': {'fp32': 28.65966558456421,\n",
       "  'top1': 86.12,\n",
       "  'imsize': 299},\n",
       " 'xcit_tiny_12_p8_224': {'fp32': 10.405259132385254,\n",
       "  'top1': 86.118,\n",
       "  'imsize': 224},\n",
       " 'ssl_resnext50_32x4d': {'fp32': 6.808748245239258,\n",
       "  'top1': 86.075,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_el': {'fp32': 11.06443166732788,\n",
       "  'top1': 86.071,\n",
       "  'imsize': 300},\n",
       " 'lambda_resnet50ts': {'fp32': 9.26401138305664,\n",
       "  'top1': 86.052,\n",
       "  'imsize': 256},\n",
       " 'ecaresnetlight': {'fp32': 7.200920581817627, 'top1': 86.045, 'imsize': 224},\n",
       " 'gluon_resnet101_v1s': {'fp32': 10.53018569946289,\n",
       "  'top1': 86.037,\n",
       "  'imsize': 224},\n",
       " 'resnetv2_50': {'fp32': 5.956425666809082, 'top1': 86.02, 'imsize': 224},\n",
       " 'gcresnext50ts': {'fp32': 14.055733680725098, 'top1': 86.009, 'imsize': 256},\n",
       " 'gluon_seresnext101_32x4d': {'fp32': 20.21681308746338,\n",
       "  'top1': 86.007,\n",
       "  'imsize': 224},\n",
       " 'seresnet33ts': {'fp32': 8.209333419799805, 'top1': 86.005, 'imsize': 256},\n",
       " 'resnet50d': {'fp32': 6.151425838470459, 'top1': 85.994, 'imsize': 224},\n",
       " 'tf_efficientnet_b2_ap': {'fp32': 11.008226871490479,\n",
       "  'top1': 85.977,\n",
       "  'imsize': 260},\n",
       " 'ecaresnet26t': {'fp32': 7.7222394943237305, 'top1': 85.964, 'imsize': 320},\n",
       " 'vit_base_patch32_224': {'fp32': 5.376286506652832,\n",
       "  'top1': 85.96,\n",
       "  'imsize': 224},\n",
       " 'gluon_seresnext101_64x4d': {'fp32': 23.79403829574585,\n",
       "  'top1': 85.951,\n",
       "  'imsize': 224},\n",
       " 'gluon_resnet152_v1d': {'fp32': 14.89464521408081,\n",
       "  'top1': 85.906,\n",
       "  'imsize': 224},\n",
       " 'vit_large_patch32_384': {'fp32': 16.52360200881958,\n",
       "  'top1': 85.902,\n",
       "  'imsize': 384},\n",
       " 'tf_efficientnetv2_b2': {'fp32': 12.000389099121094,\n",
       "  'top1': 85.9,\n",
       "  'imsize': 260},\n",
       " 'tf_efficientnet_b2': {'fp32': 11.1348557472229,\n",
       "  'top1': 85.881,\n",
       "  'imsize': 260},\n",
       " 'vit_base_patch16_sam_224': {'fp32': 7.086384296417236,\n",
       "  'top1': 85.879,\n",
       "  'imsize': 224},\n",
       " 'repvgg_b2g4': {'fp32': 19.88717794418335, 'top1': 85.857, 'imsize': 224},\n",
       " 'seresnet50': {'fp32': 9.21640396118164, 'top1': 85.83, 'imsize': 224},\n",
       " 'gluon_resnet101_v1d': {'fp32': 10.54732084274292,\n",
       "  'top1': 85.827,\n",
       "  'imsize': 224},\n",
       " 'gcresnet33ts': {'fp32': 8.985846042633057, 'top1': 85.804, 'imsize': 256},\n",
       " 'mixnet_xl': {'fp32': 14.908204078674316, 'top1': 85.785, 'imsize': 224},\n",
       " 'ens_adv_inception_resnet_v2': {'fp32': 28.62288236618042,\n",
       "  'top1': 85.781,\n",
       "  'imsize': 299},\n",
       " 'cspresnext50': {'fp32': 7.07719087600708, 'top1': 85.763, 'imsize': 224},\n",
       " 'tf_efficientnet_lite3': {'fp32': 7.652313709259033,\n",
       "  'top1': 85.759,\n",
       "  'imsize': 300},\n",
       " 'gluon_resnext101_32x4d': {'fp32': 12.993168830871582,\n",
       "  'top1': 85.744,\n",
       "  'imsize': 224},\n",
       " 'ese_vovnet39b': {'fp32': 6.879565715789795, 'top1': 85.742, 'imsize': 224},\n",
       " 'legacy_seresnext101_32x4d': {'fp32': 20.509698390960693,\n",
       "  'top1': 85.738,\n",
       "  'imsize': 224},\n",
       " 'xcit_tiny_24_p16_224': {'fp32': 18.535187244415283,\n",
       "  'top1': 85.736,\n",
       "  'imsize': 224},\n",
       " 'eca_resnet33ts': {'fp32': 7.937483787536621, 'top1': 85.736, 'imsize': 256},\n",
       " 'cspresnet50': {'fp32': 7.427303791046143, 'top1': 85.725, 'imsize': 256},\n",
       " 'regnety_320': {'fp32': 36.9970178604126, 'top1': 85.723, 'imsize': 224},\n",
       " 'resnet50': {'fp32': 5.866000652313232, 'top1': 85.704, 'imsize': 224},\n",
       " 'gluon_resnext101_64x4d': {'fp32': 19.597172737121582,\n",
       "  'top1': 85.704,\n",
       "  'imsize': 224},\n",
       " 'resmlp_big_24_224': {'fp32': 34.005258083343506,\n",
       "  'top1': 85.697,\n",
       "  'imsize': 224},\n",
       " 'xception71': {'fp32': 20.546371936798096, 'top1': 85.693, 'imsize': 299},\n",
       " 'efficientnet_em': {'fp32': 6.081697940826416, 'top1': 85.691, 'imsize': 240},\n",
       " 'deit_small_patch16_224': {'fp32': 5.531489849090576,\n",
       "  'top1': 85.663,\n",
       "  'imsize': 224},\n",
       " 'dpn107': {'fp32': 25.118308067321777, 'top1': 85.65, 'imsize': 224},\n",
       " 'pit_xs_distilled_224': {'fp32': 5.792324542999268,\n",
       "  'top1': 85.644,\n",
       "  'imsize': 224},\n",
       " 'efficientnet_b2_pruned': {'fp32': 10.361897945404053,\n",
       "  'top1': 85.637,\n",
       "  'imsize': 260},\n",
       " 'resmlp_36_224': {'fp32': 8.584911823272705, 'top1': 85.623, 'imsize': 224},\n",
       " 'levit_192': {'fp32': 7.919249534606934, 'top1': 85.586, 'imsize': 224},\n",
       " 'gluon_resnet152_v1c': {'fp32': 14.895241260528564,\n",
       "  'top1': 85.576,\n",
       "  'imsize': 224},\n",
       " 'ecaresnet50d_pruned': {'fp32': 6.768052577972412,\n",
       "  'top1': 85.573,\n",
       "  'imsize': 224},\n",
       " 'resnext50d_32x4d': {'fp32': 7.335834503173828,\n",
       "  'top1': 85.561,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnetv2_b1': {'fp32': 11.071851253509521,\n",
       "  'top1': 85.556,\n",
       "  'imsize': 240},\n",
       " 'regnety_120': {'fp32': 23.45367670059204, 'top1': 85.541, 'imsize': 224},\n",
       " 'regnetx_320': {'fp32': 36.357197761535645, 'top1': 85.516, 'imsize': 224},\n",
       " 'nf_regnet_b1': {'fp32': 15.738637447357178, 'top1': 85.496, 'imsize': 288},\n",
       " 'dpn92': {'fp32': 12.499942779541016, 'top1': 85.484, 'imsize': 224},\n",
       " 'rexnet_130': {'fp32': 8.879663944244385, 'top1': 85.465, 'imsize': 224},\n",
       " 'gluon_resnet152_v1b': {'fp32': 14.885015487670898,\n",
       "  'top1': 85.458,\n",
       "  'imsize': 224},\n",
       " 'resnetrs50': {'fp32': 9.133179187774658, 'top1': 85.433, 'imsize': 224},\n",
       " 'dpn131': {'fp32': 22.948896884918213, 'top1': 85.411, 'imsize': 224},\n",
       " 'dla102x2': {'fp32': 15.84101915359497, 'top1': 85.383, 'imsize': 224},\n",
       " 'regnetx_160': {'fp32': 26.643145084381104, 'top1': 85.364, 'imsize': 224},\n",
       " 'gmlp_s16_224': {'fp32': 7.684731483459473, 'top1': 85.349, 'imsize': 224},\n",
       " 'gluon_seresnext50_32x4d': {'fp32': 10.582897663116455,\n",
       "  'top1': 85.343,\n",
       "  'imsize': 224},\n",
       " 'botnet26t_256': {'fp32': 5.7482075691223145, 'top1': 85.334, 'imsize': 256},\n",
       " 'skresnext50_32x4d': {'fp32': 13.614575862884521,\n",
       "  'top1': 85.315,\n",
       "  'imsize': 224},\n",
       " 'gluon_resnet101_v1c': {'fp32': 10.626826286315918,\n",
       "  'top1': 85.311,\n",
       "  'imsize': 224},\n",
       " 'dpn98': {'fp32': 16.90117597579956, 'top1': 85.309, 'imsize': 224},\n",
       " 'xception65': {'fp32': 15.829980373382568, 'top1': 85.304, 'imsize': 299},\n",
       " 'lambda_resnet26t': {'fp32': 5.875599384307861, 'top1': 85.3, 'imsize': 256},\n",
       " 'regnety_064': {'fp32': 15.875396728515625, 'top1': 85.287, 'imsize': 224},\n",
       " 'dpn68b': {'fp32': 10.908501148223877, 'top1': 85.285, 'imsize': 224},\n",
       " 'resnetblur50': {'fp32': 6.055445671081543, 'top1': 85.277, 'imsize': 224},\n",
       " 'resmlp_24_224': {'fp32': 5.91921329498291, 'top1': 85.275, 'imsize': 224},\n",
       " 'coat_lite_mini': {'fp32': 7.606112957000732, 'top1': 85.249, 'imsize': 224},\n",
       " 'resnet33ts': {'fp32': 7.747480869293213, 'top1': 85.242, 'imsize': 256},\n",
       " 'resnext50_32x4d': {'fp32': 6.930999755859375, 'top1': 85.232, 'imsize': 224},\n",
       " 'regnety_080': {'fp32': 14.40291166305542, 'top1': 85.232, 'imsize': 224},\n",
       " 'cait_xxs24_224': {'fp32': 14.687254428863525, 'top1': 85.221, 'imsize': 224},\n",
       " 'halonet26t': {'fp32': 5.914363861083984, 'top1': 85.213, 'imsize': 256},\n",
       " 'xcit_tiny_12_p16_224_dist': {'fp32': 10.848548412322998,\n",
       "  'top1': 85.206,\n",
       "  'imsize': 224},\n",
       " 'resnext101_32x8d': {'fp32': 19.21564817428589,\n",
       "  'top1': 85.187,\n",
       "  'imsize': 224},\n",
       " 'gluon_inception_v3': {'fp32': 10.67434549331665,\n",
       "  'top1': 85.183,\n",
       "  'imsize': 299},\n",
       " 'resnet32ts': {'fp32': 7.546877861022949, 'top1': 85.174, 'imsize': 256},\n",
       " 'hrnet_w48': {'fp32': 35.19402027130127, 'top1': 85.155, 'imsize': 224},\n",
       " 'regnetx_120': {'fp32': 21.437790393829346, 'top1': 85.138, 'imsize': 224},\n",
       " 'tf_efficientnet_b1_ap': {'fp32': 10.644173622131348,\n",
       "  'top1': 85.129,\n",
       "  'imsize': 240},\n",
       " 'xception': {'fp32': 9.606974124908447, 'top1': 85.129, 'imsize': 299},\n",
       " 'gluon_resnet101_v1b': {'fp32': 10.23425579071045,\n",
       "  'top1': 85.129,\n",
       "  'imsize': 224},\n",
       " 'eca_botnext26ts_256': {'fp32': 6.876101493835449,\n",
       "  'top1': 85.127,\n",
       "  'imsize': 256},\n",
       " 'gluon_xception65': {'fp32': 15.715572834014893,\n",
       "  'top1': 85.123,\n",
       "  'imsize': 299},\n",
       " 'hrnet_w64': {'fp32': 32.55429267883301, 'top1': 85.117, 'imsize': 224},\n",
       " 'ssl_resnet50': {'fp32': 5.702922344207764, 'top1': 85.104, 'imsize': 224},\n",
       " 'res2net101_26w_4s': {'fp32': 18.506522178649902,\n",
       "  'top1': 85.089,\n",
       "  'imsize': 224},\n",
       " 'lambda_resnet26rpt_256': {'fp32': 6.532487869262695,\n",
       "  'top1': 85.084,\n",
       "  'imsize': 256},\n",
       " 'tf_efficientnet_cc_b1_8e': {'fp32': 12.824573516845703,\n",
       "  'top1': 85.072,\n",
       "  'imsize': 240},\n",
       " 'xcit_nano_12_p8_384_dist': {'fp32': 14.727818965911865,\n",
       "  'top1': 85.029,\n",
       "  'imsize': 384},\n",
       " 'gluon_resnext50_32x4d': {'fp32': 6.938610076904297,\n",
       "  'top1': 85.01,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b0_ns': {'fp32': 7.675967216491699,\n",
       "  'top1': 85.003,\n",
       "  'imsize': 224},\n",
       " 'resnest26d': {'fp32': 9.267549514770508, 'top1': 84.997, 'imsize': 224},\n",
       " 'coat_tiny': {'fp32': 21.991052627563477, 'top1': 84.969, 'imsize': 224},\n",
       " 'regnety_040': {'fp32': 12.630414962768555, 'top1': 84.948, 'imsize': 224},\n",
       " 'eca_halonext26ts': {'fp32': 6.973214149475098,\n",
       "  'top1': 84.918,\n",
       "  'imsize': 256},\n",
       " 'dla169': {'fp32': 16.798508167266846, 'top1': 84.914, 'imsize': 224},\n",
       " 'legacy_seresnext50_32x4d': {'fp32': 10.038816928863525,\n",
       "  'top1': 84.909,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b1': {'fp32': 10.78035593032837,\n",
       "  'top1': 84.907,\n",
       "  'imsize': 240},\n",
       " 'hrnet_w44': {'fp32': 34.98673677444458, 'top1': 84.886, 'imsize': 224},\n",
       " 'regnetx_080': {'fp32': 16.292753219604492, 'top1': 84.875, 'imsize': 224},\n",
       " 'gluon_resnet50_v1s': {'fp32': 6.087207794189453,\n",
       "  'top1': 84.852,\n",
       "  'imsize': 224},\n",
       " 'res2net50_26w_8s': {'fp32': 16.367857456207275,\n",
       "  'top1': 84.843,\n",
       "  'imsize': 224},\n",
       " 'dla60_res2next': {'fp32': 16.325759887695312, 'top1': 84.828, 'imsize': 224},\n",
       " 'mixnet_l': {'fp32': 12.301766872406006, 'top1': 84.826, 'imsize': 224},\n",
       " 'levit_128': {'fp32': 7.933347225189209, 'top1': 84.822, 'imsize': 224},\n",
       " 'dla60_res2net': {'fp32': 10.874195098876953, 'top1': 84.82, 'imsize': 224},\n",
       " 'vit_tiny_patch16_384': {'fp32': 6.9220733642578125,\n",
       "  'top1': 84.82,\n",
       "  'imsize': 384},\n",
       " 'tv_resnet152': {'fp32': 15.094912052154541, 'top1': 84.818, 'imsize': 224},\n",
       " 'dla102x': {'fp32': 12.951178550720215, 'top1': 84.813, 'imsize': 224},\n",
       " 'gluon_resnet50_v1d': {'fp32': 6.055865287780762,\n",
       "  'top1': 84.811,\n",
       "  'imsize': 224},\n",
       " 'xception41': {'fp32': 11.543443202972412, 'top1': 84.809, 'imsize': 299},\n",
       " 'regnetx_064': {'fp32': 10.908219814300537, 'top1': 84.783, 'imsize': 224},\n",
       " 'pit_xs_224': {'fp32': 5.7231831550598145, 'top1': 84.783, 'imsize': 224},\n",
       " 'hrnet_w40': {'fp32': 32.60390758514404, 'top1': 84.745, 'imsize': 224},\n",
       " 'repvgg_b2': {'fp32': 13.433892726898193, 'top1': 84.726, 'imsize': 224},\n",
       " 'res2net50_26w_6s': {'fp32': 12.873594760894775,\n",
       "  'top1': 84.724,\n",
       "  'imsize': 224},\n",
       " 'resmlp_12_distilled_224': {'fp32': 3.4597349166870117,\n",
       "  'top1': 84.707,\n",
       "  'imsize': 224},\n",
       " 'legacy_seresnet152': {'fp32': 26.90204620361328,\n",
       "  'top1': 84.696,\n",
       "  'imsize': 224},\n",
       " 'selecsls60b': {'fp32': 6.84145450592041, 'top1': 84.655, 'imsize': 224},\n",
       " 'hrnet_w32': {'fp32': 31.0402512550354, 'top1': 84.653, 'imsize': 224},\n",
       " 'bat_resnext26ts': {'fp32': 12.601232528686523, 'top1': 84.64, 'imsize': 256},\n",
       " 'tf_efficientnetv2_b0': {'fp32': 9.29147481918335,\n",
       "  'top1': 84.625,\n",
       "  'imsize': 224},\n",
       " 'efficientnet_b1': {'fp32': 10.691587924957275,\n",
       "  'top1': 84.615,\n",
       "  'imsize': 256},\n",
       " 'regnetx_040': {'fp32': 9.5054292678833, 'top1': 84.6, 'imsize': 224},\n",
       " 'hrnet_w30': {'fp32': 32.41853475570679, 'top1': 84.591, 'imsize': 224},\n",
       " 'efficientnet_es': {'fp32': 4.870438575744629, 'top1': 84.591, 'imsize': 224},\n",
       " 'tf_mixnet_l': {'fp32': 12.193045616149902, 'top1': 84.559, 'imsize': 224},\n",
       " 'wide_resnet101_2': {'fp32': 18.46719264984131,\n",
       "  'top1': 84.555,\n",
       "  'imsize': 224},\n",
       " 'dla60x': {'fp32': 7.684717178344727, 'top1': 84.529, 'imsize': 224},\n",
       " 'legacy_seresnet101': {'fp32': 17.37694501876831,\n",
       "  'top1': 84.502,\n",
       "  'imsize': 224},\n",
       " 'resnet26t': {'fp32': 5.499708652496338, 'top1': 84.465, 'imsize': 256},\n",
       " 'tf_efficientnet_em': {'fp32': 6.13384485244751,\n",
       "  'top1': 84.463,\n",
       "  'imsize': 240},\n",
       " 'coat_lite_tiny': {'fp32': 7.582681179046631, 'top1': 84.457, 'imsize': 224},\n",
       " 'efficientnet_b1_pruned': {'fp32': 10.10892629623413,\n",
       "  'top1': 84.399,\n",
       "  'imsize': 240},\n",
       " 'repvgg_b1': {'fp32': 10.291106700897217, 'top1': 84.399, 'imsize': 224},\n",
       " 'res2net50_26w_4s': {'fp32': 9.515554904937744,\n",
       "  'top1': 84.371,\n",
       "  'imsize': 224},\n",
       " 'hardcorenas_f': {'fp32': 7.830562591552734, 'top1': 84.322, 'imsize': 224},\n",
       " 'res2net50_14w_8s': {'fp32': 15.560951232910156,\n",
       "  'top1': 84.307,\n",
       "  'imsize': 224},\n",
       " 'selecsls60': {'fp32': 6.938221454620361, 'top1': 84.282, 'imsize': 224},\n",
       " 'res2next50': {'fp32': 16.08792781829834, 'top1': 84.23, 'imsize': 224},\n",
       " 'regnetx_032': {'fp32': 9.0372633934021, 'top1': 84.23, 'imsize': 224},\n",
       " 'gluon_resnet50_v1c': {'fp32': 6.0350871086120605,\n",
       "  'top1': 84.209,\n",
       "  'imsize': 224},\n",
       " 'dla102': {'fp32': 10.91986894607544, 'top1': 84.192, 'imsize': 224},\n",
       " 'gcresnext26ts': {'fp32': 7.534244060516357, 'top1': 84.181, 'imsize': 256},\n",
       " 'rexnet_100': {'fp32': 8.551814556121826, 'top1': 84.173, 'imsize': 224},\n",
       " 'tf_inception_v3': {'fp32': 10.817878246307373,\n",
       "  'top1': 84.128,\n",
       "  'imsize': 299},\n",
       " 'seresnext26ts': {'fp32': 7.277858257293701, 'top1': 84.124, 'imsize': 256},\n",
       " 'res2net50_48w_2s': {'fp32': 6.6150736808776855,\n",
       "  'top1': 84.121,\n",
       "  'imsize': 224},\n",
       " 'resnet34d': {'fp32': 4.357035160064697, 'top1': 84.104, 'imsize': 224},\n",
       " 'tf_efficientnet_lite2': {'fp32': 5.8763909339904785,\n",
       "  'top1': 84.092,\n",
       "  'imsize': 260},\n",
       " 'xcit_tiny_12_p16_224': {'fp32': 10.531399250030518,\n",
       "  'top1': 84.083,\n",
       "  'imsize': 224},\n",
       " 'efficientnet_b0': {'fp32': 7.71547794342041, 'top1': 84.034, 'imsize': 224},\n",
       " 'crossvit_9_dagger_240': {'fp32': 8.982396125793457,\n",
       "  'top1': 84.03,\n",
       "  'imsize': 240},\n",
       " 'hardcorenas_e': {'fp32': 7.651188373565674, 'top1': 83.972, 'imsize': 224},\n",
       " 'gmixer_24_224': {'fp32': 8.50656270980835, 'top1': 83.97, 'imsize': 224},\n",
       " 'tf_efficientnet_cc_b0_8e': {'fp32': 9.615633487701416,\n",
       "  'top1': 83.97,\n",
       "  'imsize': 224},\n",
       " 'regnety_016': {'fp32': 13.364031314849854, 'top1': 83.955, 'imsize': 224},\n",
       " 'tv_resnext50_32x4d': {'fp32': 6.845822334289551,\n",
       "  'top1': 83.955,\n",
       "  'imsize': 224},\n",
       " 'gluon_resnet50_v1b': {'fp32': 5.973658561706543,\n",
       "  'top1': 83.942,\n",
       "  'imsize': 224},\n",
       " 'densenet161': {'fp32': 18.15948724746704, 'top1': 83.9, 'imsize': 224},\n",
       " 'seresnext26t_32x4d': {'fp32': 5.853981971740723,\n",
       "  'top1': 83.887,\n",
       "  'imsize': 224},\n",
       " 'mobilenetv2_120d': {'fp32': 6.594960689544678,\n",
       "  'top1': 83.887,\n",
       "  'imsize': 224},\n",
       " 'adv_inception_v3': {'fp32': 10.414693355560303,\n",
       "  'top1': 83.876,\n",
       "  'imsize': 299},\n",
       " 'tv_resnet101': {'fp32': 10.301275253295898, 'top1': 83.855, 'imsize': 224},\n",
       " 'inception_v3': {'fp32': 10.332717895507812, 'top1': 83.771, 'imsize': 299},\n",
       " 'hardcorenas_d': {'fp32': 7.835903167724609, 'top1': 83.763, 'imsize': 224},\n",
       " 'dla60': {'fp32': 6.874604225158691, 'top1': 83.735, 'imsize': 224},\n",
       " 'xcit_nano_12_p8_224_dist': {'fp32': 10.589027404785156,\n",
       "  'top1': 83.733,\n",
       "  'imsize': 224},\n",
       " 'seresnext26d_32x4d': {'fp32': 5.94174861907959,\n",
       "  'top1': 83.724,\n",
       "  'imsize': 224},\n",
       " 'repvgg_b1g4': {'fp32': 15.80167293548584, 'top1': 83.695, 'imsize': 224},\n",
       " 'eca_resnext26ts': {'fp32': 6.937901973724365, 'top1': 83.692, 'imsize': 256},\n",
       " 'legacy_seresnet50': {'fp32': 8.896877765655518,\n",
       "  'top1': 83.671,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_b0_ap': {'fp32': 7.774972915649414,\n",
       "  'top1': 83.66,\n",
       "  'imsize': 224},\n",
       " 'skresnet34': {'fp32': 11.584069728851318, 'top1': 83.65, 'imsize': 224},\n",
       " 'tf_efficientnet_cc_b0_4e': {'fp32': 9.464902877807617,\n",
       "  'top1': 83.639,\n",
       "  'imsize': 224},\n",
       " 'resmlp_12_224': {'fp32': 3.5370802879333496, 'top1': 83.573, 'imsize': 224},\n",
       " 'mobilenetv3_large_100_miil': {'fp32': 6.127316951751709,\n",
       "  'top1': 83.549,\n",
       "  'imsize': 224},\n",
       " 'densenet201': {'fp32': 23.181421756744385, 'top1': 83.547, 'imsize': 224},\n",
       " 'gernet_s': {'fp32': 5.058321952819824, 'top1': 83.522, 'imsize': 224},\n",
       " 'legacy_seresnext26_32x4d': {'fp32': 5.573861598968506,\n",
       "  'top1': 83.515,\n",
       "  'imsize': 224},\n",
       " 'mixnet_m': {'fp32': 11.969778537750244, 'top1': 83.513, 'imsize': 224},\n",
       " 'tf_efficientnet_b0': {'fp32': 7.811639308929443,\n",
       "  'top1': 83.513,\n",
       "  'imsize': 224},\n",
       " 'hrnet_w18': {'fp32': 30.66925287246704, 'top1': 83.5, 'imsize': 224},\n",
       " 'densenetblur121d': {'fp32': 13.623583316802979,\n",
       "  'top1': 83.475,\n",
       "  'imsize': 224},\n",
       " 'selecsls42b': {'fp32': 5.443534851074219, 'top1': 83.46, 'imsize': 224},\n",
       " 'resnext26ts': {'fp32': 6.736466884613037, 'top1': 83.457, 'imsize': 256},\n",
       " 'tf_efficientnet_lite1': {'fp32': 5.798652172088623,\n",
       "  'top1': 83.355,\n",
       "  'imsize': 240},\n",
       " 'hardcorenas_c': {'fp32': 6.024746894836426, 'top1': 83.336, 'imsize': 224},\n",
       " 'regnetx_016': {'fp32': 7.071018218994141, 'top1': 83.186, 'imsize': 224},\n",
       " 'mobilenetv2_140': {'fp32': 4.40061092376709, 'top1': 83.176, 'imsize': 224},\n",
       " 'tf_mixnet_m': {'fp32': 12.423973083496094, 'top1': 83.174, 'imsize': 224},\n",
       " 'xcit_nano_12_p16_384_dist': {'fp32': 12.061982154846191,\n",
       "  'top1': 83.174,\n",
       "  'imsize': 384},\n",
       " 'dpn68': {'fp32': 9.955165386199951, 'top1': 83.171, 'imsize': 224},\n",
       " 'tf_efficientnet_es': {'fp32': 4.856016635894775,\n",
       "  'top1': 83.167,\n",
       "  'imsize': 224},\n",
       " 'ese_vovnet19b_dw': {'fp32': 4.253544807434082,\n",
       "  'top1': 83.114,\n",
       "  'imsize': 224},\n",
       " 'levit_128s': {'fp32': 6.265995502471924, 'top1': 83.065, 'imsize': 224},\n",
       " 'resnet26d': {'fp32': 3.8224124908447266, 'top1': 83.043, 'imsize': 224},\n",
       " 'repvgg_a2': {'fp32': 5.8386993408203125, 'top1': 82.999, 'imsize': 224},\n",
       " 'tv_resnet50': {'fp32': 5.7837748527526855, 'top1': 82.954, 'imsize': 224},\n",
       " 'hardcorenas_b': {'fp32': 5.311298370361328, 'top1': 82.877, 'imsize': 224},\n",
       " 'densenet121': {'fp32': 13.615849018096924, 'top1': 82.815, 'imsize': 224},\n",
       " 'vit_tiny_r_s16_p8_384': {'fp32': 6.8675947189331055,\n",
       "  'top1': 82.693,\n",
       "  'imsize': 384},\n",
       " 'densenet169': {'fp32': 18.92897605895996, 'top1': 82.661, 'imsize': 224},\n",
       " 'mixnet_s': {'fp32': 9.72402811050415, 'top1': 82.525, 'imsize': 224},\n",
       " 'vit_small_patch32_224': {'fp32': 5.379784107208252,\n",
       "  'top1': 82.51,\n",
       "  'imsize': 224},\n",
       " 'regnety_008': {'fp32': 7.877047061920166, 'top1': 82.478, 'imsize': 224},\n",
       " 'efficientnet_lite0': {'fp32': 4.536440372467041,\n",
       "  'top1': 82.388,\n",
       "  'imsize': 224},\n",
       " 'resnest14d': {'fp32': 6.846880912780762, 'top1': 82.362, 'imsize': 224},\n",
       " 'hardcorenas_a': {'fp32': 4.780862331390381, 'top1': 82.305, 'imsize': 224},\n",
       " 'efficientnet_es_pruned': {'fp32': 4.655544757843018,\n",
       "  'top1': 82.279,\n",
       "  'imsize': 224},\n",
       " 'mobilenetv3_rw': {'fp32': 5.929827690124512, 'top1': 82.268, 'imsize': 224},\n",
       " 'semnasnet_100': {'fp32': 5.908637046813965, 'top1': 82.253, 'imsize': 224},\n",
       " 'mobilenetv3_large_100': {'fp32': 5.859463214874268,\n",
       "  'top1': 82.177,\n",
       "  'imsize': 224},\n",
       " 'resnet34': {'fp32': 4.129607677459717, 'top1': 82.125, 'imsize': 224},\n",
       " 'mobilenetv2_110d': {'fp32': 5.588924884796143,\n",
       "  'top1': 82.076,\n",
       "  'imsize': 224},\n",
       " 'vit_tiny_patch16_224': {'fp32': 5.516154766082764,\n",
       "  'top1': 82.044,\n",
       "  'imsize': 224},\n",
       " 'tf_mixnet_s': {'fp32': 10.012834072113037, 'top1': 82.04, 'imsize': 224},\n",
       " 'repvgg_b0': {'fp32': 6.786749362945557, 'top1': 82.006, 'imsize': 224},\n",
       " 'deit_tiny_distilled_patch16_224': {'fp32': 5.5579423904418945,\n",
       "  'top1': 82.001,\n",
       "  'imsize': 224},\n",
       " 'mixer_b16_224': {'fp32': 4.947319030761719, 'top1': 81.997, 'imsize': 224},\n",
       " 'pit_ti_distilled_224': {'fp32': 5.8206987380981445,\n",
       "  'top1': 81.972,\n",
       "  'imsize': 224},\n",
       " 'hrnet_w18_small_v2': {'fp32': 16.512372493743896,\n",
       "  'top1': 81.959,\n",
       "  'imsize': 224},\n",
       " 'tf_efficientnet_lite0': {'fp32': 4.607882499694824,\n",
       "  'top1': 81.95,\n",
       "  'imsize': 224},\n",
       " 'resnet26': {'fp32': 3.6391830444335938, 'top1': 81.942, 'imsize': 224},\n",
       " 'tf_mobilenetv3_large_100': {'fp32': 6.069750785827637,\n",
       "  'top1': 81.841,\n",
       "  'imsize': 224},\n",
       " 'tv_densenet121': {'fp32': 13.906161785125732, 'top1': 81.728, 'imsize': 224},\n",
       " 'regnety_006': {'fp32': 8.466055393218994, 'top1': 81.703, 'imsize': 224},\n",
       " 'dla34': {'fp32': 4.545648097991943, 'top1': 81.643, 'imsize': 224},\n",
       " 'xcit_nano_12_p8_224': {'fp32': 10.769472122192383,\n",
       "  'top1': 81.641,\n",
       "  'imsize': 224},\n",
       " 'crossvit_9_240': {'fp32': 8.07368516921997, 'top1': 81.63, 'imsize': 240},\n",
       " 'fbnetc_100': {'fp32': 5.538060665130615, 'top1': 81.555, 'imsize': 224},\n",
       " 'legacy_seresnet34': {'fp32': 7.063846588134766,\n",
       "  'top1': 81.532,\n",
       "  'imsize': 224},\n",
       " 'regnetx_008': {'fp32': 5.988619327545166, 'top1': 81.508, 'imsize': 224},\n",
       " 'gluon_resnet34_v1b': {'fp32': 4.21140193939209,\n",
       "  'top1': 81.489,\n",
       "  'imsize': 224},\n",
       " 'mnasnet_100': {'fp32': 4.459197521209717, 'top1': 81.472, 'imsize': 224},\n",
       " 'vgg19_bn': {'fp32': 12.287020683288574, 'top1': 81.451, 'imsize': 224},\n",
       " 'convit_tiny': {'fp32': 7.187743186950684, 'top1': 81.115, 'imsize': 224},\n",
       " 'crossvit_tiny_240': {'fp32': 9.558379650115967, 'top1': 81.1, 'imsize': 240},\n",
       " 'spnasnet_100': {'fp32': 5.14542818069458, 'top1': 80.866, 'imsize': 224},\n",
       " 'ghostnet_100': {'fp32': 8.943958282470703, 'top1': 80.699, 'imsize': 224},\n",
       " 'regnety_004': {'fp32': 10.081777572631836, 'top1': 80.648, 'imsize': 224},\n",
       " 'skresnet18': {'fp32': 6.504323482513428, 'top1': 80.624, 'imsize': 224},\n",
       " 'regnetx_006': {'fp32': 5.666806697845459, 'top1': 80.616, 'imsize': 224},\n",
       " 'pit_ti_224': {'fp32': 5.444982051849365, 'top1': 80.597, 'imsize': 224},\n",
       " 'swsl_resnet18': {'fp32': 3.0446243286132812, 'top1': 80.562, 'imsize': 224},\n",
       " 'vgg16_bn': {'fp32': 10.70775032043457, 'top1': 80.535, 'imsize': 224},\n",
       " 'resnet18d': {'fp32': 3.114156723022461, 'top1': 80.387, 'imsize': 224},\n",
       " 'tv_resnet34': {'fp32': 4.152665138244629, 'top1': 80.377, 'imsize': 224},\n",
       " 'mobilenetv2_100': {'fp32': 4.405169486999512, 'top1': 80.257, 'imsize': 224},\n",
       " 'xcit_nano_12_p16_224_dist': {'fp32': 10.719523429870605,\n",
       "  'top1': 80.225,\n",
       "  'imsize': 224},\n",
       " 'vit_base_patch32_sam_224': {'fp32': 5.497896671295166,\n",
       "  'top1': 80.212,\n",
       "  'imsize': 224},\n",
       " 'ssl_resnet18': {'fp32': 2.874293327331543, 'top1': 80.114, 'imsize': 224},\n",
       " 'tf_mobilenetv3_large_075': {'fp32': 6.034748554229736,\n",
       "  'top1': 80.088,\n",
       "  'imsize': 224},\n",
       " 'deit_tiny_patch16_224': {'fp32': 5.433828830718994,\n",
       "  'top1': 80.009,\n",
       "  'imsize': 224},\n",
       " 'hrnet_w18_small': {'fp32': 9.587922096252441, 'top1': 79.544, 'imsize': 224},\n",
       " 'vgg19': {'fp32': 11.49423360824585, 'top1': 79.484, 'imsize': 224},\n",
       " 'regnetx_004': {'fp32': 9.168562889099121, 'top1': 79.424, 'imsize': 224},\n",
       " 'tf_mobilenetv3_large_minimal_100': {'fp32': 4.529573917388916,\n",
       "  'top1': 79.232,\n",
       "  'imsize': 224},\n",
       " 'legacy_seresnet18': {'fp32': 4.25100564956665,\n",
       "  'top1': 79.151,\n",
       "  'imsize': 224},\n",
       " 'vgg16': {'fp32': 9.980151653289795, 'top1': 79.031, 'imsize': 224},\n",
       " 'vit_tiny_r_s16_p8_224': {'fp32': 5.7746124267578125,\n",
       "  'top1': 78.997,\n",
       "  'imsize': 224},\n",
       " 'vgg13_bn': {'fp32': 9.128279685974121, 'top1': 78.987, 'imsize': 224},\n",
       " 'gluon_resnet18_v1b': {'fp32': 2.7234983444213867,\n",
       "  'top1': 78.376,\n",
       "  'imsize': 224},\n",
       " 'vgg11_bn': {'fp32': 7.460498809814453, 'top1': 77.926, 'imsize': 224},\n",
       " 'xcit_nano_12_p16_224': {'fp32': 10.70732831954956,\n",
       "  'top1': 77.909,\n",
       "  'imsize': 224},\n",
       " 'regnety_002': {'fp32': 8.627853393554688, 'top1': 77.417, 'imsize': 224},\n",
       " 'mixer_l16_224': {'fp32': 15.586493015289307, 'top1': 77.294, 'imsize': 224},\n",
       " 'resnet18': {'fp32': 2.734816074371338, 'top1': 77.276, 'imsize': 224},\n",
       " 'vgg13': {'fp32': 8.471179008483887, 'top1': 77.234, 'imsize': 224},\n",
       " 'vgg11': {'fp32': 7.014648914337158, 'top1': 76.397, 'imsize': 224},\n",
       " 'regnetx_002': {'fp32': 5.994873046875, 'top1': 76.102, 'imsize': 224},\n",
       " 'dla60x_c': {'fp32': 6.110951900482178, 'top1': 75.656, 'imsize': 224},\n",
       " 'tf_mobilenetv3_small_100': {'fp32': 5.060420036315918,\n",
       "  'top1': 74.736,\n",
       "  'imsize': 224},\n",
       " 'dla46x_c': {'fp32': 4.974346160888672, 'top1': 73.645, 'imsize': 224},\n",
       " 'tf_mobilenetv3_small_075': {'fp32': 5.441930294036865,\n",
       "  'top1': 72.816,\n",
       "  'imsize': 224},\n",
       " 'dla46_c': {'fp32': 5.222153663635254, 'top1': 72.607, 'imsize': 224},\n",
       " 'tf_mobilenetv3_small_minimal_100': {'fp32': 3.5568642616271973,\n",
       "  'top1': 70.107,\n",
       "  'imsize': 224}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modellist = df_models[\"model\"]\n",
    "benchmark = {}\n",
    "\n",
    "# inference float precision\n",
    "for i,modelname in tqdm(enumerate((modellist))):\n",
    "    imsize = int(df_models[df_models[\"model\"]==modelname][\"img_size\"])\n",
    "    try:\n",
    "        benchmark = inference_imsize(modelname, benchmark, imsize)\n",
    "    except:\n",
    "        print(\"pass {}\".format(modelname))\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(benchmark).T\n",
    "df_results\n",
    "df_results.to_csv(\"results_fp32_imsizeall.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
