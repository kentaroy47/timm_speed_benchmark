{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "import torch.utils.benchmark as benchmark\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WARM_UP = 10\n",
    "BATCH_SIZE = 4\n",
    "NUM_TEST = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul  3 10:59:47 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 455.45.01    Driver Version: 455.45.01    CUDA Version: 11.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  RTX A6000           On   | 00000000:09:00.0 Off |                  Off |\r\n",
      "| 30%   49C    P0    82W / 250W |     41MiB / 48682MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A      1256      G   /usr/lib/xorg/Xorg                 24MiB |\r\n",
      "|    0   N/A  N/A      1384      G   /usr/bin/gnome-shell               12MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>top1</th>\n",
       "      <th>top1_err</th>\n",
       "      <th>top5</th>\n",
       "      <th>top5_err</th>\n",
       "      <th>param_count</th>\n",
       "      <th>img_size</th>\n",
       "      <th>cropt_pct</th>\n",
       "      <th>interpolation</th>\n",
       "      <th>top1_diff</th>\n",
       "      <th>top5_diff</th>\n",
       "      <th>rank_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tf_efficientnet_l2_ns</td>\n",
       "      <td>90.563</td>\n",
       "      <td>9.437</td>\n",
       "      <td>98.779</td>\n",
       "      <td>1.221</td>\n",
       "      <td>480.31</td>\n",
       "      <td>800</td>\n",
       "      <td>0.960</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>2.211</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tf_efficientnet_l2_ns_475</td>\n",
       "      <td>90.537</td>\n",
       "      <td>9.463</td>\n",
       "      <td>98.710</td>\n",
       "      <td>1.290</td>\n",
       "      <td>480.31</td>\n",
       "      <td>475</td>\n",
       "      <td>0.936</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>2.303</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cait_m48_448</td>\n",
       "      <td>90.196</td>\n",
       "      <td>9.804</td>\n",
       "      <td>98.484</td>\n",
       "      <td>1.516</td>\n",
       "      <td>356.46</td>\n",
       "      <td>448</td>\n",
       "      <td>1.000</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>3.712</td>\n",
       "      <td>0.730</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vit_large_patch16_384</td>\n",
       "      <td>90.196</td>\n",
       "      <td>9.804</td>\n",
       "      <td>98.661</td>\n",
       "      <td>1.339</td>\n",
       "      <td>304.72</td>\n",
       "      <td>384</td>\n",
       "      <td>1.000</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>3.116</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tf_efficientnet_b7_ns</td>\n",
       "      <td>90.100</td>\n",
       "      <td>9.900</td>\n",
       "      <td>98.614</td>\n",
       "      <td>1.386</td>\n",
       "      <td>66.35</td>\n",
       "      <td>600</td>\n",
       "      <td>0.949</td>\n",
       "      <td>bicubic</td>\n",
       "      <td>3.260</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model    top1  top1_err    top5  top5_err  param_count  \\\n",
       "0      tf_efficientnet_l2_ns  90.563     9.437  98.779     1.221       480.31   \n",
       "1  tf_efficientnet_l2_ns_475  90.537     9.463  98.710     1.290       480.31   \n",
       "2               cait_m48_448  90.196     9.804  98.484     1.516       356.46   \n",
       "3      vit_large_patch16_384  90.196     9.804  98.661     1.339       304.72   \n",
       "4      tf_efficientnet_b7_ns  90.100     9.900  98.614     1.386        66.35   \n",
       "\n",
       "   img_size  cropt_pct interpolation  top1_diff  top5_diff  rank_diff  \n",
       "0       800      0.960       bicubic      2.211      0.129          0  \n",
       "1       475      0.936       bicubic      2.303      0.164          0  \n",
       "2       448      1.000       bicubic      3.712      0.730          3  \n",
       "3       384      1.000       bicubic      3.116      0.361          0  \n",
       "4       600      0.949       bicubic      3.260      0.520          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models = pd.read_csv(\"results-imagenet-real.csv\")\n",
    "# use models with img size 224\n",
    "modellist = df_models[df_models[\"img_size\"]==224][\"model\"]\n",
    "df_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataset(Dataset):\n",
    "    def __init__(self,  length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn( 3, 224, 224,length)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[:,:,:,index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "rand_loader = DataLoader(dataset=RandomDataset(BATCH_SIZE*(WARM_UP + NUM_TEST)),\n",
    "                         batch_size=BATCH_SIZE, shuffle=False,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ryujaehun/pytorch-gpu-benchmark/blob/master/benchmark_models.py\n",
    "def inference(modelname, benchmark, half=False):\n",
    "    with torch.no_grad():\n",
    "        model = timm.create_model(modelname,)\n",
    "        model=model.to('cuda')\n",
    "        model.eval()\n",
    "        precision = \"float\"\n",
    "        durations = []\n",
    "        print(f'Benchmarking Inference {modelname} ')\n",
    "        for step,img in enumerate(rand_loader):\n",
    "            img=getattr(img,precision)()\n",
    "            torch.cuda.synchronize()\n",
    "            start = time.time()\n",
    "            model(img.to('cuda'))\n",
    "            torch.cuda.synchronize()\n",
    "            end = time.time()\n",
    "            if step >= WARM_UP:\n",
    "                durations.append((end - start)*1000)\n",
    "        print(f'{modelname} model average inference time : {sum(durations)/len(durations)}ms')\n",
    "        \n",
    "        if half:\n",
    "            durations_half = []\n",
    "            print(f'Benchmarking Inference half precision type {modelname} ')\n",
    "            model.half()\n",
    "            precision = \"half\"\n",
    "            for step,img in enumerate(rand_loader):\n",
    "                img=getattr(img,precision)()\n",
    "                torch.cuda.synchronize()\n",
    "                start = time.time()\n",
    "                model(img.to('cuda'))\n",
    "                torch.cuda.synchronize()\n",
    "                end = time.time()\n",
    "                if step >= WARM_UP:\n",
    "                    durations_half.append((end - start)*1000)\n",
    "            print(f'{modelname} half model average inference time : {sum(durations_half)/len(durations_half)}ms')\n",
    "            \n",
    "        if half:\n",
    "            benchmark[modelname] = {\"fp32\": np.mean(durations), \"fp16\": np.mean(durations_half), \"top1\": df_models[df_models[\"model\"]==modelname][\"top1\"]}\n",
    "        else:\n",
    "            benchmark[modelname] = {\"fp32\": np.mean(durations), \"top1\": float(df_models[df_models[\"model\"]==modelname][\"top1\"])}\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7babcbca5c6d4682bded1164a00a183e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference swin_large_patch4_window7_224 \n",
      "swin_large_patch4_window7_224 model average inference time : 19.50279474258423ms\n",
      "Benchmarking Inference vit_large_patch16_224 \n",
      "vit_large_patch16_224 model average inference time : 24.370009899139404ms\n",
      "Benchmarking Inference swin_base_patch4_window7_224 \n",
      "swin_base_patch4_window7_224 model average inference time : 15.764214992523193ms\n",
      "Benchmarking Inference ig_resnext101_32x48d \n",
      "ig_resnext101_32x48d model average inference time : 360.5432891845703ms\n",
      "Benchmarking Inference ig_resnext101_32x32d \n",
      "ig_resnext101_32x32d model average inference time : 241.9998860359192ms\n",
      "Benchmarking Inference resmlp_big_24_224_in22ft1k \n",
      "resmlp_big_24_224_in22ft1k model average inference time : 36.22174024581909ms\n",
      "Benchmarking Inference vit_base_patch16_224 \n",
      "vit_base_patch16_224 model average inference time : 8.107953071594238ms\n",
      "Benchmarking Inference ig_resnext101_32x16d \n",
      "ig_resnext101_32x16d model average inference time : 119.11271810531616ms\n",
      "Benchmarking Inference swsl_resnext101_32x8d \n",
      "swsl_resnext101_32x8d model average inference time : 63.61705303192139ms\n",
      "Benchmarking Inference vit_base_patch16_224_miil \n",
      "vit_base_patch16_224_miil model average inference time : 7.891795635223389ms\n",
      "Benchmarking Inference pit_b_distilled_224 \n",
      "pit_b_distilled_224 model average inference time : 23.16471815109253ms\n",
      "Benchmarking Inference cait_s24_224 \n",
      "cait_s24_224 model average inference time : 17.449767589569092ms\n",
      "Benchmarking Inference resmlp_big_24_distilled_224 \n",
      "resmlp_big_24_distilled_224 model average inference time : 36.24388933181763ms\n",
      "Benchmarking Inference vit_large_r50_s32_224 \n",
      "vit_large_r50_s32_224 model average inference time : 25.66894292831421ms\n",
      "Benchmarking Inference deit_base_distilled_patch16_224 \n",
      "deit_base_distilled_patch16_224 model average inference time : 8.191089630126953ms\n",
      "Benchmarking Inference ig_resnext101_32x8d \n",
      "ig_resnext101_32x8d model average inference time : 63.493099212646484ms\n",
      "Benchmarking Inference swsl_resnext101_32x4d \n",
      "swsl_resnext101_32x4d model average inference time : 44.973342418670654ms\n",
      "Benchmarking Inference twins_svt_large \n",
      "twins_svt_large model average inference time : 17.34797954559326ms\n",
      "Benchmarking Inference twins_pcpvt_large \n",
      "twins_pcpvt_large model average inference time : 32.705254554748535ms\n",
      "Benchmarking Inference resnetv2_50x1_bit_distilled \n",
      "resnetv2_50x1_bit_distilled model average inference time : 15.836045742034912ms\n",
      "Benchmarking Inference tresnet_m \n",
      "pass tresnet_m\n",
      "Benchmarking Inference twins_pcpvt_base \n",
      "twins_pcpvt_base model average inference time : 22.684860229492188ms\n",
      "Benchmarking Inference swin_small_patch4_window7_224 \n",
      "swin_small_patch4_window7_224 model average inference time : 15.812485218048096ms\n",
      "Benchmarking Inference twins_svt_base \n",
      "twins_svt_base model average inference time : 17.661550045013428ms\n",
      "Benchmarking Inference swsl_resnext101_32x16d \n",
      "swsl_resnext101_32x16d model average inference time : 119.64479446411133ms\n",
      "Benchmarking Inference swsl_resnext50_32x4d \n",
      "swsl_resnext50_32x4d model average inference time : 23.29725980758667ms\n",
      "Benchmarking Inference levit_384 \n",
      "levit_384 model average inference time : 9.478154182434082ms\n",
      "Benchmarking Inference resnetv2_152x2_bit_teacher \n",
      "resnetv2_152x2_bit_teacher model average inference time : 67.82337665557861ms\n",
      "Benchmarking Inference coat_lite_small \n",
      "coat_lite_small model average inference time : 21.04684591293335ms\n",
      "Benchmarking Inference ecaresnet101d \n",
      "ecaresnet101d model average inference time : 30.606515407562256ms\n",
      "Benchmarking Inference pit_s_distilled_224 \n",
      "pit_s_distilled_224 model average inference time : 16.29002809524536ms\n",
      "Benchmarking Inference mixer_b16_224_miil \n",
      "mixer_b16_224_miil model average inference time : 5.9320807456970215ms\n",
      "Benchmarking Inference tresnet_xl \n",
      "pass tresnet_xl\n",
      "Benchmarking Inference convit_base \n",
      "convit_base model average inference time : 12.074966430664062ms\n",
      "Benchmarking Inference visformer_small \n",
      "visformer_small model average inference time : 14.938292503356934ms\n",
      "Benchmarking Inference convit_small \n",
      "convit_small model average inference time : 8.7324857711792ms\n",
      "Benchmarking Inference deit_small_distilled_patch16_224 \n",
      "deit_small_distilled_patch16_224 model average inference time : 6.4098310470581055ms\n",
      "Benchmarking Inference resmlp_36_distilled_224 \n",
      "resmlp_36_distilled_224 model average inference time : 10.808858871459961ms\n",
      "Benchmarking Inference tnt_s_patch16_224 \n",
      "tnt_s_patch16_224 model average inference time : 14.40457820892334ms\n",
      "Benchmarking Inference vit_small_patch16_224 \n",
      "vit_small_patch16_224 model average inference time : 6.377596855163574ms\n",
      "Benchmarking Inference vit_small_r26_s32_224 \n",
      "vit_small_r26_s32_224 model average inference time : 14.331820011138916ms\n",
      "Benchmarking Inference ssl_resnext101_32x16d \n",
      "ssl_resnext101_32x16d model average inference time : 119.6251392364502ms\n",
      "Benchmarking Inference rexnet_200 \n",
      "rexnet_200 model average inference time : 15.437161922454834ms\n",
      "Benchmarking Inference deit_base_patch16_224 \n",
      "deit_base_patch16_224 model average inference time : 8.144140243530273ms\n",
      "Benchmarking Inference ssl_resnext101_32x8d \n",
      "ssl_resnext101_32x8d model average inference time : 63.55698823928833ms\n",
      "Benchmarking Inference swsl_resnet50 \n",
      "swsl_resnet50 model average inference time : 13.167252540588379ms\n",
      "Benchmarking Inference coat_mini \n",
      "coat_mini model average inference time : 35.6980037689209ms\n",
      "Benchmarking Inference tresnet_l \n",
      "pass tresnet_l\n",
      "Benchmarking Inference twins_svt_small \n",
      "twins_svt_small model average inference time : 13.224685192108154ms\n",
      "Benchmarking Inference levit_256 \n",
      "levit_256 model average inference time : 9.803543090820312ms\n",
      "Benchmarking Inference seresnext50_32x4d \n",
      "seresnext50_32x4d model average inference time : 29.789512157440186ms\n",
      "Benchmarking Inference pit_b_224 \n",
      "pit_b_224 model average inference time : 23.014636039733887ms\n",
      "Benchmarking Inference swin_tiny_patch4_window7_224 \n",
      "swin_tiny_patch4_window7_224 model average inference time : 8.665573596954346ms\n",
      "Benchmarking Inference wide_resnet50_2 \n",
      "wide_resnet50_2 model average inference time : 16.90601348876953ms\n",
      "Benchmarking Inference resmlp_24_distilled_224 \n",
      "resmlp_24_distilled_224 model average inference time : 7.271509170532227ms\n",
      "Benchmarking Inference twins_pcpvt_small \n",
      "twins_pcpvt_small model average inference time : 13.856451511383057ms\n",
      "Benchmarking Inference resnest50d_4s2x40d \n",
      "resnest50d_4s2x40d model average inference time : 23.885343074798584ms\n",
      "Benchmarking Inference repvgg_b3 \n",
      "repvgg_b3 model average inference time : 28.389830589294434ms\n",
      "Benchmarking Inference ssl_resnext101_32x4d \n",
      "ssl_resnext101_32x4d model average inference time : 44.833362102508545ms\n",
      "Benchmarking Inference ecaresnet50d \n",
      "ecaresnet50d model average inference time : 16.176774501800537ms\n",
      "Benchmarking Inference gluon_resnet152_v1s \n",
      "gluon_resnet152_v1s model average inference time : 35.96315622329712ms\n",
      "Benchmarking Inference resnest50d_1s4x24d \n",
      "resnest50d_1s4x24d model average inference time : 22.619028091430664ms\n",
      "Benchmarking Inference repvgg_b3g4 \n",
      "repvgg_b3g4 model average inference time : 27.560269832611084ms\n",
      "Benchmarking Inference legacy_senet154 \n",
      "legacy_senet154 model average inference time : 118.40935707092285ms\n",
      "Benchmarking Inference cait_xxs36_224 \n",
      "cait_xxs36_224 model average inference time : 25.236077308654785ms\n",
      "Benchmarking Inference gernet_m \n",
      "gernet_m model average inference time : 10.314347743988037ms\n",
      "Benchmarking Inference pit_s_224 \n",
      "pit_s_224 model average inference time : 15.984313488006592ms\n",
      "Benchmarking Inference gluon_senet154 \n",
      "gluon_senet154 model average inference time : 118.77516746520996ms\n",
      "Benchmarking Inference resnest50d \n",
      "resnest50d model average inference time : 22.304112911224365ms\n",
      "Benchmarking Inference ecaresnet101d_pruned \n",
      "ecaresnet101d_pruned model average inference time : 30.75754404067993ms\n",
      "Benchmarking Inference rexnet_150 \n",
      "rexnet_150 model average inference time : 15.177664756774902ms\n",
      "Benchmarking Inference ssl_resnext50_32x4d \n",
      "ssl_resnext50_32x4d model average inference time : 23.491158485412598ms\n",
      "Benchmarking Inference gluon_resnet101_v1s \n",
      "gluon_resnet101_v1s model average inference time : 24.85081672668457ms\n",
      "Benchmarking Inference ecaresnetlight \n",
      "ecaresnetlight model average inference time : 15.680818557739258ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking Inference gluon_seresnext101_32x4d \n",
      "gluon_seresnext101_32x4d model average inference time : 58.40898513793945ms\n",
      "Benchmarking Inference resnet50d \n",
      "resnet50d model average inference time : 13.604111671447754ms\n",
      "Benchmarking Inference gluon_seresnext101_64x4d \n",
      "gluon_seresnext101_64x4d model average inference time : 80.38221836090088ms\n",
      "Benchmarking Inference vit_base_patch32_224 \n",
      "vit_base_patch32_224 model average inference time : 6.309616565704346ms\n",
      "Benchmarking Inference gluon_resnet152_v1d \n",
      "gluon_resnet152_v1d model average inference time : 36.075589656829834ms\n",
      "Benchmarking Inference seresnet50 \n",
      "seresnet50 model average inference time : 19.72234010696411ms\n",
      "Benchmarking Inference repvgg_b2g4 \n",
      "repvgg_b2g4 model average inference time : 23.099920749664307ms\n",
      "Benchmarking Inference gluon_resnet101_v1d \n",
      "gluon_resnet101_v1d model average inference time : 24.865880012512207ms\n",
      "Benchmarking Inference resnet50 \n",
      "resnet50 model average inference time : 13.070471286773682ms\n",
      "Benchmarking Inference mixnet_xl \n",
      "mixnet_xl model average inference time : 30.19455909729004ms\n",
      "Benchmarking Inference ese_vovnet39b \n",
      "ese_vovnet39b model average inference time : 14.699952602386475ms\n",
      "Benchmarking Inference gluon_resnext101_32x4d \n",
      "gluon_resnext101_32x4d model average inference time : 44.82148885726929ms\n",
      "Benchmarking Inference legacy_seresnext101_32x4d \n",
      "legacy_seresnext101_32x4d model average inference time : 58.50147008895874ms\n",
      "Benchmarking Inference cspresnext50 \n",
      "cspresnext50 model average inference time : 24.12332057952881ms\n",
      "Benchmarking Inference regnety_320 \n",
      "regnety_320 model average inference time : 60.529518127441406ms\n",
      "Benchmarking Inference resmlp_big_24_224 \n",
      "resmlp_big_24_224 model average inference time : 36.21501922607422ms\n",
      "Benchmarking Inference gluon_resnext101_64x4d \n",
      "gluon_resnext101_64x4d model average inference time : 72.99256563186646ms\n",
      "Benchmarking Inference deit_small_patch16_224 \n",
      "deit_small_patch16_224 model average inference time : 6.3588714599609375ms\n",
      "Benchmarking Inference pit_xs_distilled_224 \n",
      "pit_xs_distilled_224 model average inference time : 13.260557651519775ms\n",
      "Benchmarking Inference dpn107 \n",
      "dpn107 model average inference time : 68.58819723129272ms\n",
      "Benchmarking Inference resmlp_36_224 \n",
      "resmlp_36_224 model average inference time : 10.426931381225586ms\n",
      "Benchmarking Inference levit_192 \n",
      "levit_192 model average inference time : 9.473047256469727ms\n",
      "Benchmarking Inference gluon_resnet152_v1c \n",
      "gluon_resnet152_v1c model average inference time : 36.065311431884766ms\n",
      "Benchmarking Inference ecaresnet50d_pruned \n",
      "ecaresnet50d_pruned model average inference time : 16.34434461593628ms\n",
      "Benchmarking Inference resnext50d_32x4d \n",
      "resnext50d_32x4d model average inference time : 23.9900541305542ms\n",
      "Benchmarking Inference regnety_120 \n",
      "regnety_120 model average inference time : 35.074260234832764ms\n",
      "Benchmarking Inference regnetx_320 \n",
      "regnetx_320 model average inference time : 59.012954235076904ms\n",
      "Benchmarking Inference dpn92 \n",
      "dpn92 model average inference time : 43.23657512664795ms\n",
      "Benchmarking Inference gluon_resnet152_v1b \n",
      "gluon_resnet152_v1b model average inference time : 35.65824270248413ms\n",
      "Benchmarking Inference rexnet_130 \n",
      "rexnet_130 model average inference time : 15.647735595703125ms\n",
      "Benchmarking Inference resnetrs50 \n",
      "resnetrs50 model average inference time : 20.421524047851562ms\n",
      "Benchmarking Inference dpn131 \n",
      "dpn131 model average inference time : 68.24190616607666ms\n",
      "Benchmarking Inference regnetx_160 \n",
      "regnetx_160 model average inference time : 37.669923305511475ms\n",
      "Benchmarking Inference dla102x2 \n",
      "dla102x2 model average inference time : 62.16656684875488ms\n",
      "Benchmarking Inference gluon_seresnext50_32x4d \n",
      "gluon_seresnext50_32x4d model average inference time : 29.890780448913574ms\n",
      "Benchmarking Inference skresnext50_32x4d \n",
      "skresnext50_32x4d model average inference time : 35.31296253204346ms\n",
      "Benchmarking Inference dpn98 \n",
      "dpn98 model average inference time : 51.88017129898071ms\n",
      "Benchmarking Inference gluon_resnet101_v1c \n",
      "gluon_resnet101_v1c model average inference time : 24.825599193572998ms\n",
      "Benchmarking Inference dpn68b \n",
      "dpn68b model average inference time : 35.486135482788086ms\n",
      "Benchmarking Inference regnety_064 \n",
      "regnety_064 model average inference time : 33.992931842803955ms\n",
      "Benchmarking Inference resnetblur50 \n",
      "resnetblur50 model average inference time : 13.288507461547852ms\n",
      "Benchmarking Inference resmlp_24_224 \n",
      "resmlp_24_224 model average inference time : 7.358105182647705ms\n",
      "Benchmarking Inference coat_lite_mini \n",
      "coat_lite_mini model average inference time : 11.34040117263794ms\n",
      "Benchmarking Inference regnety_080 \n",
      "regnety_080 model average inference time : 30.2477765083313ms\n",
      "Benchmarking Inference cait_xxs24_224 \n",
      "cait_xxs24_224 model average inference time : 17.572786808013916ms\n",
      "Benchmarking Inference resnext50_32x4d \n",
      "resnext50_32x4d model average inference time : 23.5636568069458ms\n",
      "Benchmarking Inference resnext101_32x8d \n",
      "resnext101_32x8d model average inference time : 63.528075218200684ms\n",
      "Benchmarking Inference hrnet_w48 \n",
      "hrnet_w48 model average inference time : 77.2935438156128ms\n",
      "Benchmarking Inference gluon_resnet101_v1b \n",
      "gluon_resnet101_v1b model average inference time : 24.276750087738037ms\n",
      "Benchmarking Inference regnetx_120 \n",
      "regnetx_120 model average inference time : 31.98323965072632ms\n",
      "Benchmarking Inference hrnet_w64 \n",
      "hrnet_w64 model average inference time : 77.98977136611938ms\n",
      "Benchmarking Inference ssl_resnet50 \n",
      "ssl_resnet50 model average inference time : 13.312861919403076ms\n",
      "Benchmarking Inference res2net101_26w_4s \n",
      "res2net101_26w_4s model average inference time : 42.01146602630615ms\n",
      "Benchmarking Inference res2net50_26w_8s \n",
      "res2net50_26w_8s model average inference time : 37.28018045425415ms\n",
      "Benchmarking Inference resnest26d \n",
      "resnest26d model average inference time : 12.431516647338867ms\n",
      "Benchmarking Inference gluon_resnext50_32x4d \n",
      "gluon_resnext50_32x4d model average inference time : 23.481574058532715ms\n",
      "Benchmarking Inference tf_efficientnet_b0_ns \n",
      "tf_efficientnet_b0_ns model average inference time : 15.606083869934082ms\n",
      "Benchmarking Inference coat_tiny \n",
      "coat_tiny model average inference time : 35.102314949035645ms\n",
      "Benchmarking Inference regnety_040 \n",
      "regnety_040 model average inference time : 29.593660831451416ms\n",
      "Benchmarking Inference dla169 \n",
      "dla169 model average inference time : 39.44899559020996ms\n",
      "Benchmarking Inference legacy_seresnext50_32x4d \n",
      "legacy_seresnext50_32x4d model average inference time : 29.708619117736816ms\n",
      "Benchmarking Inference hrnet_w44 \n",
      "hrnet_w44 model average inference time : 77.65289783477783ms\n",
      "Benchmarking Inference gluon_resnet50_v1s \n",
      "gluon_resnet50_v1s model average inference time : 13.720438480377197ms\n",
      "Benchmarking Inference regnetx_080 \n",
      "regnetx_080 model average inference time : 29.13945436477661ms\n",
      "Benchmarking Inference levit_128 \n",
      "levit_128 model average inference time : 9.578113555908203ms\n",
      "Benchmarking Inference gluon_resnet50_v1d \n",
      "gluon_resnet50_v1d model average inference time : 13.55842113494873ms\n",
      "Benchmarking Inference dla60_res2next \n",
      "dla60_res2next model average inference time : 30.626158714294434ms\n",
      "Benchmarking Inference mixnet_l \n",
      "mixnet_l model average inference time : 24.36124563217163ms\n",
      "Benchmarking Inference tv_resnet152 \n",
      "tv_resnet152 model average inference time : 35.635008811950684ms\n",
      "Benchmarking Inference dla60_res2net \n",
      "dla60_res2net model average inference time : 24.18288230895996ms\n",
      "Benchmarking Inference dla102x \n",
      "dla102x model average inference time : 42.28411912918091ms\n",
      "Benchmarking Inference pit_xs_224 \n",
      "pit_xs_224 model average inference time : 13.126370906829834ms\n",
      "Benchmarking Inference regnetx_064 \n",
      "regnetx_064 model average inference time : 23.689093589782715ms\n",
      "Benchmarking Inference hrnet_w40 \n",
      "hrnet_w40 model average inference time : 77.58050441741943ms\n",
      "Benchmarking Inference res2net50_26w_6s \n",
      "res2net50_26w_6s model average inference time : 29.149439334869385ms\n",
      "Benchmarking Inference repvgg_b2 \n",
      "repvgg_b2 model average inference time : 23.35519313812256ms\n",
      "Benchmarking Inference resmlp_12_distilled_224 \n",
      "resmlp_12_distilled_224 model average inference time : 4.45798397064209ms\n",
      "Benchmarking Inference legacy_seresnet152 \n",
      "legacy_seresnet152 model average inference time : 56.19556903839111ms\n",
      "Benchmarking Inference selecsls60b \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selecsls60b model average inference time : 15.792901515960693ms\n",
      "Benchmarking Inference hrnet_w32 \n",
      "hrnet_w32 model average inference time : 77.26882696151733ms\n",
      "Benchmarking Inference tf_efficientnetv2_b0 \n",
      "tf_efficientnetv2_b0 model average inference time : 17.512075901031494ms\n",
      "Benchmarking Inference regnetx_040 \n",
      "regnetx_040 model average inference time : 24.476487636566162ms\n",
      "Benchmarking Inference efficientnet_es \n",
      "efficientnet_es model average inference time : 9.59014892578125ms\n",
      "Benchmarking Inference hrnet_w30 \n",
      "hrnet_w30 model average inference time : 77.46355295181274ms\n",
      "Benchmarking Inference tf_mixnet_l \n",
      "tf_mixnet_l model average inference time : 24.727728366851807ms\n",
      "Benchmarking Inference wide_resnet101_2 \n",
      "wide_resnet101_2 model average inference time : 31.62684440612793ms\n",
      "Benchmarking Inference dla60x \n",
      "dla60x model average inference time : 25.395286083221436ms\n",
      "Benchmarking Inference legacy_seresnet101 \n",
      "legacy_seresnet101 model average inference time : 37.76135444641113ms\n",
      "Benchmarking Inference coat_lite_tiny \n",
      "coat_lite_tiny model average inference time : 11.470646858215332ms\n",
      "Benchmarking Inference repvgg_b1 \n",
      "repvgg_b1 model average inference time : 17.914841175079346ms\n",
      "Benchmarking Inference res2net50_26w_4s \n",
      "res2net50_26w_4s model average inference time : 21.461904048919678ms\n",
      "Benchmarking Inference hardcorenas_f \n",
      "hardcorenas_f model average inference time : 15.929255485534668ms\n",
      "Benchmarking Inference res2net50_14w_8s \n",
      "res2net50_14w_8s model average inference time : 37.06977367401123ms\n",
      "Benchmarking Inference selecsls60 \n",
      "selecsls60 model average inference time : 15.906856060028076ms\n",
      "Benchmarking Inference regnetx_032 \n",
      "regnetx_032 model average inference time : 23.281080722808838ms\n",
      "Benchmarking Inference res2next50 \n",
      "res2next50 model average inference time : 27.80407190322876ms\n",
      "Benchmarking Inference gluon_resnet50_v1c \n",
      "gluon_resnet50_v1c model average inference time : 13.52034330368042ms\n",
      "Benchmarking Inference dla102 \n",
      "dla102 model average inference time : 25.134928226470947ms\n",
      "Benchmarking Inference rexnet_100 \n",
      "rexnet_100 model average inference time : 15.358355045318604ms\n",
      "Benchmarking Inference res2net50_48w_2s \n",
      "res2net50_48w_2s model average inference time : 13.810060024261475ms\n",
      "Benchmarking Inference resnet34d \n",
      "resnet34d model average inference time : 11.96746826171875ms\n",
      "Benchmarking Inference efficientnet_b0 \n",
      "efficientnet_b0 model average inference time : 15.176019668579102ms\n",
      "Benchmarking Inference gmixer_24_224 \n",
      "gmixer_24_224 model average inference time : 10.632157325744629ms\n",
      "Benchmarking Inference hardcorenas_e \n",
      "hardcorenas_e model average inference time : 16.08830213546753ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b0_8e \n",
      "tf_efficientnet_cc_b0_8e model average inference time : 17.074263095855713ms\n",
      "Benchmarking Inference tv_resnext50_32x4d \n",
      "tv_resnext50_32x4d model average inference time : 23.499579429626465ms\n",
      "Benchmarking Inference regnety_016 \n",
      "regnety_016 model average inference time : 37.729036808013916ms\n",
      "Benchmarking Inference gluon_resnet50_v1b \n",
      "gluon_resnet50_v1b model average inference time : 13.301715850830078ms\n",
      "Benchmarking Inference densenet161 \n",
      "densenet161 model average inference time : 39.50547695159912ms\n",
      "Benchmarking Inference mobilenetv2_120d \n",
      "mobilenetv2_120d model average inference time : 13.552076816558838ms\n",
      "Benchmarking Inference seresnext26t_32x4d \n",
      "seresnext26t_32x4d model average inference time : 16.388742923736572ms\n",
      "Benchmarking Inference tv_resnet101 \n",
      "tv_resnet101 model average inference time : 24.250290393829346ms\n",
      "Benchmarking Inference hardcorenas_d \n",
      "hardcorenas_d model average inference time : 16.87415599822998ms\n",
      "Benchmarking Inference seresnext26d_32x4d \n",
      "seresnext26d_32x4d model average inference time : 16.512179374694824ms\n",
      "Benchmarking Inference dla60 \n",
      "dla60 model average inference time : 15.62697172164917ms\n",
      "Benchmarking Inference repvgg_b1g4 \n",
      "repvgg_b1g4 model average inference time : 19.112842082977295ms\n",
      "Benchmarking Inference legacy_seresnet50 \n",
      "legacy_seresnet50 model average inference time : 19.561116695404053ms\n",
      "Benchmarking Inference tf_efficientnet_b0_ap \n",
      "tf_efficientnet_b0_ap model average inference time : 15.479509830474854ms\n",
      "Benchmarking Inference skresnet34 \n",
      "skresnet34 model average inference time : 22.282590866088867ms\n",
      "Benchmarking Inference tf_efficientnet_cc_b0_4e \n",
      "tf_efficientnet_cc_b0_4e model average inference time : 17.265737056732178ms\n",
      "Benchmarking Inference resmlp_12_224 \n",
      "resmlp_12_224 model average inference time : 4.0805745124816895ms\n",
      "Benchmarking Inference densenet201 \n",
      "densenet201 model average inference time : 49.51512336730957ms\n",
      "Benchmarking Inference mobilenetv3_large_100_miil \n",
      "mobilenetv3_large_100_miil model average inference time : 11.62226676940918ms\n",
      "Benchmarking Inference gernet_s \n",
      "gernet_s model average inference time : 10.602884292602539ms\n",
      "Benchmarking Inference legacy_seresnext26_32x4d \n",
      "legacy_seresnext26_32x4d model average inference time : 16.013472080230713ms\n",
      "Benchmarking Inference mixnet_m \n",
      "mixnet_m model average inference time : 24.340946674346924ms\n",
      "Benchmarking Inference tf_efficientnet_b0 \n",
      "tf_efficientnet_b0 model average inference time : 15.629713535308838ms\n",
      "Benchmarking Inference hrnet_w18 \n",
      "hrnet_w18 model average inference time : 77.63300657272339ms\n",
      "Benchmarking Inference densenetblur121d \n",
      "densenetblur121d model average inference time : 30.213792324066162ms\n",
      "Benchmarking Inference selecsls42b \n",
      "selecsls42b model average inference time : 12.251818180084229ms\n",
      "Benchmarking Inference hardcorenas_c \n",
      "hardcorenas_c model average inference time : 12.28823184967041ms\n",
      "Benchmarking Inference regnetx_016 \n",
      "regnetx_016 model average inference time : 19.21266794204712ms\n",
      "Benchmarking Inference mobilenetv2_140 \n",
      "mobilenetv2_140 model average inference time : 9.146544933319092ms\n",
      "Benchmarking Inference dpn68 \n",
      "dpn68 model average inference time : 32.48085021972656ms\n",
      "Benchmarking Inference tf_efficientnet_es \n",
      "tf_efficientnet_es model average inference time : 9.651808738708496ms\n",
      "Benchmarking Inference tf_mixnet_m \n",
      "tf_mixnet_m model average inference time : 24.638941287994385ms\n",
      "Benchmarking Inference ese_vovnet19b_dw \n",
      "ese_vovnet19b_dw model average inference time : 7.170546054840088ms\n",
      "Benchmarking Inference levit_128s \n",
      "levit_128s model average inference time : 7.92184591293335ms\n",
      "Benchmarking Inference resnet26d \n",
      "resnet26d model average inference time : 8.071653842926025ms\n",
      "Benchmarking Inference repvgg_a2 \n",
      "repvgg_a2 model average inference time : 12.158229351043701ms\n",
      "Benchmarking Inference tv_resnet50 \n",
      "tv_resnet50 model average inference time : 13.246650695800781ms\n",
      "Benchmarking Inference hardcorenas_b \n",
      "hardcorenas_b model average inference time : 11.440660953521729ms\n",
      "Benchmarking Inference densenet121 \n",
      "densenet121 model average inference time : 29.496641159057617ms\n",
      "Benchmarking Inference densenet169 \n",
      "densenet169 model average inference time : 41.30248785018921ms\n",
      "Benchmarking Inference mixnet_s \n",
      "mixnet_s model average inference time : 20.33100128173828ms\n",
      "Benchmarking Inference vit_small_patch32_224 \n",
      "vit_small_patch32_224 model average inference time : 6.230607032775879ms\n",
      "Benchmarking Inference regnety_008 \n",
      "regnety_008 model average inference time : 22.214641571044922ms\n",
      "Benchmarking Inference efficientnet_lite0 \n",
      "efficientnet_lite0 model average inference time : 8.655755519866943ms\n",
      "Benchmarking Inference resnest14d \n",
      "resnest14d model average inference time : 7.397334575653076ms\n",
      "Benchmarking Inference hardcorenas_a \n",
      "hardcorenas_a model average inference time : 9.995191097259521ms\n",
      "Benchmarking Inference efficientnet_es_pruned \n",
      "efficientnet_es_pruned model average inference time : 9.494497776031494ms\n",
      "Benchmarking Inference mobilenetv3_rw \n",
      "mobilenetv3_rw model average inference time : 11.660823822021484ms\n",
      "Benchmarking Inference semnasnet_100 \n",
      "semnasnet_100 model average inference time : 12.158796787261963ms\n",
      "Benchmarking Inference mobilenetv3_large_100 \n",
      "mobilenetv3_large_100 model average inference time : 11.767716407775879ms\n",
      "Benchmarking Inference resnet34 \n",
      "resnet34 model average inference time : 11.384499073028564ms\n",
      "Benchmarking Inference mobilenetv2_110d \n",
      "mobilenetv2_110d model average inference time : 11.63078784942627ms\n",
      "Benchmarking Inference vit_tiny_patch16_224 \n",
      "vit_tiny_patch16_224 model average inference time : 6.354000568389893ms\n",
      "Benchmarking Inference tf_mixnet_s \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_mixnet_s model average inference time : 20.533647537231445ms\n",
      "Benchmarking Inference repvgg_b0 \n",
      "repvgg_b0 model average inference time : 14.523680210113525ms\n",
      "Benchmarking Inference deit_tiny_distilled_patch16_224 \n",
      "deit_tiny_distilled_patch16_224 model average inference time : 6.505832672119141ms\n",
      "Benchmarking Inference mixer_b16_224 \n",
      "mixer_b16_224 model average inference time : 6.005053520202637ms\n",
      "Benchmarking Inference pit_ti_distilled_224 \n",
      "pit_ti_distilled_224 model average inference time : 11.327447891235352ms\n",
      "Benchmarking Inference hrnet_w18_small_v2 \n",
      "hrnet_w18_small_v2 model average inference time : 39.86715793609619ms\n",
      "Benchmarking Inference tf_efficientnet_lite0 \n",
      "tf_efficientnet_lite0 model average inference time : 8.792951107025146ms\n",
      "Benchmarking Inference resnet26 \n",
      "resnet26 model average inference time : 7.5565314292907715ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_100 \n",
      "tf_mobilenetv3_large_100 model average inference time : 11.876115798950195ms\n",
      "Benchmarking Inference tv_densenet121 \n",
      "tv_densenet121 model average inference time : 29.64106559753418ms\n",
      "Benchmarking Inference regnety_006 \n",
      "regnety_006 model average inference time : 23.668363094329834ms\n",
      "Benchmarking Inference dla34 \n",
      "dla34 model average inference time : 10.90489149093628ms\n",
      "Benchmarking Inference fbnetc_100 \n",
      "fbnetc_100 model average inference time : 11.348040103912354ms\n",
      "Benchmarking Inference legacy_seresnet34 \n",
      "legacy_seresnet34 model average inference time : 16.76248788833618ms\n",
      "Benchmarking Inference gluon_resnet34_v1b \n",
      "gluon_resnet34_v1b model average inference time : 11.525590419769287ms\n",
      "Benchmarking Inference regnetx_008 \n",
      "regnetx_008 model average inference time : 19.472036361694336ms\n",
      "Benchmarking Inference mnasnet_100 \n",
      "mnasnet_100 model average inference time : 9.160943031311035ms\n",
      "Benchmarking Inference vgg19_bn \n",
      "vgg19_bn model average inference time : 21.426701545715332ms\n",
      "Benchmarking Inference convit_tiny \n",
      "convit_tiny model average inference time : 8.790421485900879ms\n",
      "Benchmarking Inference spnasnet_100 \n",
      "spnasnet_100 model average inference time : 11.016905307769775ms\n",
      "Benchmarking Inference ghostnet_100 \n",
      "ghostnet_100 model average inference time : 15.661108493804932ms\n",
      "Benchmarking Inference regnety_004 \n",
      "regnety_004 model average inference time : 29.266657829284668ms\n",
      "Benchmarking Inference skresnet18 \n",
      "skresnet18 model average inference time : 12.066454887390137ms\n",
      "Benchmarking Inference regnetx_006 \n",
      "regnetx_006 model average inference time : 16.617286205291748ms\n",
      "Benchmarking Inference pit_ti_224 \n",
      "pit_ti_224 model average inference time : 11.03642225265503ms\n",
      "Benchmarking Inference swsl_resnet18 \n",
      "swsl_resnet18 model average inference time : 6.566486358642578ms\n",
      "Benchmarking Inference vgg16_bn \n",
      "vgg16_bn model average inference time : 18.267951011657715ms\n",
      "Benchmarking Inference tv_resnet34 \n",
      "tv_resnet34 model average inference time : 11.512017250061035ms\n",
      "Benchmarking Inference resnet18d \n",
      "resnet18d model average inference time : 6.952710151672363ms\n",
      "Benchmarking Inference mobilenetv2_100 \n",
      "mobilenetv2_100 model average inference time : 9.301655292510986ms\n",
      "Benchmarking Inference ssl_resnet18 \n",
      "ssl_resnet18 model average inference time : 6.413772106170654ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_075 \n",
      "tf_mobilenetv3_large_075 model average inference time : 11.914403438568115ms\n",
      "Benchmarking Inference deit_tiny_patch16_224 \n",
      "deit_tiny_patch16_224 model average inference time : 6.480603218078613ms\n",
      "Benchmarking Inference hrnet_w18_small \n",
      "hrnet_w18_small model average inference time : 22.388195991516113ms\n",
      "Benchmarking Inference vgg19 \n",
      "vgg19 model average inference time : 20.636448860168457ms\n",
      "Benchmarking Inference regnetx_004 \n",
      "regnetx_004 model average inference time : 23.54163646697998ms\n",
      "Benchmarking Inference tf_mobilenetv3_large_minimal_100 \n",
      "tf_mobilenetv3_large_minimal_100 model average inference time : 8.509268760681152ms\n",
      "Benchmarking Inference legacy_seresnet18 \n",
      "legacy_seresnet18 model average inference time : 9.242548942565918ms\n",
      "Benchmarking Inference vgg16 \n",
      "vgg16 model average inference time : 17.58795976638794ms\n",
      "Benchmarking Inference vgg13_bn \n",
      "vgg13_bn model average inference time : 15.115864276885986ms\n",
      "Benchmarking Inference vit_tiny_r_s16_p8_224 \n",
      "vit_tiny_r_s16_p8_224 model average inference time : 6.765804290771484ms\n",
      "Benchmarking Inference gluon_resnet18_v1b \n",
      "gluon_resnet18_v1b model average inference time : 6.550438404083252ms\n",
      "Benchmarking Inference vgg11_bn \n",
      "vgg11_bn model average inference time : 11.503260135650635ms\n",
      "Benchmarking Inference regnety_002 \n",
      "regnety_002 model average inference time : 23.753905296325684ms\n",
      "Benchmarking Inference mixer_l16_224 \n",
      "mixer_l16_224 model average inference time : 18.644118309020996ms\n",
      "Benchmarking Inference resnet18 \n",
      "resnet18 model average inference time : 6.402738094329834ms\n",
      "Benchmarking Inference vgg13 \n",
      "vgg13 model average inference time : 14.562349319458008ms\n",
      "Benchmarking Inference vgg11 \n",
      "vgg11 model average inference time : 11.132502555847168ms\n",
      "Benchmarking Inference regnetx_002 \n",
      "regnetx_002 model average inference time : 18.17647933959961ms\n",
      "Benchmarking Inference dla60x_c \n",
      "dla60x_c model average inference time : 24.133601188659668ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_100 \n",
      "tf_mobilenetv3_small_100 model average inference time : 10.3680419921875ms\n",
      "Benchmarking Inference dla46x_c \n",
      "dla46x_c model average inference time : 18.569304943084717ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_075 \n",
      "tf_mobilenetv3_small_075 model average inference time : 10.742824077606201ms\n",
      "Benchmarking Inference dla46_c \n",
      "dla46_c model average inference time : 11.950483322143555ms\n",
      "Benchmarking Inference tf_mobilenetv3_small_minimal_100 \n",
      "tf_mobilenetv3_small_minimal_100 model average inference time : 6.80619478225708ms\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'swin_large_patch4_window7_224': {'fp32': 19.50279474258423, 'top1': 89.796},\n",
       " 'vit_large_patch16_224': {'fp32': 24.370009899139404, 'top1': 89.314},\n",
       " 'swin_base_patch4_window7_224': {'fp32': 15.764214992523193, 'top1': 89.145},\n",
       " 'ig_resnext101_32x48d': {'fp32': 360.5432891845703, 'top1': 89.12},\n",
       " 'ig_resnext101_32x32d': {'fp32': 241.9998860359192, 'top1': 89.111},\n",
       " 'resmlp_big_24_224_in22ft1k': {'fp32': 36.22174024581909,\n",
       "  'top1': 89.01100000000001},\n",
       " 'vit_base_patch16_224': {'fp32': 8.107953071594238, 'top1': 88.866},\n",
       " 'ig_resnext101_32x16d': {'fp32': 119.11271810531616, 'top1': 88.834},\n",
       " 'swsl_resnext101_32x8d': {'fp32': 63.61705303192139, 'top1': 88.77},\n",
       " 'vit_base_patch16_224_miil': {'fp32': 7.891795635223389,\n",
       "  'top1': 88.73700000000001},\n",
       " 'pit_b_distilled_224': {'fp32': 23.16471815109253, 'top1': 88.676},\n",
       " 'cait_s24_224': {'fp32': 17.449767589569092, 'top1': 88.447},\n",
       " 'resmlp_big_24_distilled_224': {'fp32': 36.24388933181763, 'top1': 88.443},\n",
       " 'vit_large_r50_s32_224': {'fp32': 25.66894292831421, 'top1': 88.426},\n",
       " 'deit_base_distilled_patch16_224': {'fp32': 8.191089630126953,\n",
       "  'top1': 88.214},\n",
       " 'ig_resnext101_32x8d': {'fp32': 63.493099212646484, 'top1': 88.146},\n",
       " 'swsl_resnext101_32x4d': {'fp32': 44.973342418670654,\n",
       "  'top1': 88.09899999999999},\n",
       " 'twins_svt_large': {'fp32': 17.34797954559326, 'top1': 87.90100000000001},\n",
       " 'twins_pcpvt_large': {'fp32': 32.705254554748535, 'top1': 87.87700000000001},\n",
       " 'resnetv2_50x1_bit_distilled': {'fp32': 15.836045742034912, 'top1': 87.787},\n",
       " 'twins_pcpvt_base': {'fp32': 22.684860229492188, 'top1': 87.736},\n",
       " 'swin_small_patch4_window7_224': {'fp32': 15.812485218048096, 'top1': 87.664},\n",
       " 'twins_svt_base': {'fp32': 17.661550045013428, 'top1': 87.63799999999999},\n",
       " 'swsl_resnext101_32x16d': {'fp32': 119.64479446411133, 'top1': 87.615},\n",
       " 'swsl_resnext50_32x4d': {'fp32': 23.29725980758667, 'top1': 87.6},\n",
       " 'levit_384': {'fp32': 9.478154182434082, 'top1': 87.553},\n",
       " 'resnetv2_152x2_bit_teacher': {'fp32': 67.82337665557861, 'top1': 87.493},\n",
       " 'coat_lite_small': {'fp32': 21.04684591293335, 'top1': 87.38},\n",
       " 'ecaresnet101d': {'fp32': 30.606515407562256, 'top1': 87.288},\n",
       " 'pit_s_distilled_224': {'fp32': 16.29002809524536, 'top1': 87.277},\n",
       " 'mixer_b16_224_miil': {'fp32': 5.9320807456970215, 'top1': 87.226},\n",
       " 'convit_base': {'fp32': 12.074966430664062, 'top1': 87.2},\n",
       " 'visformer_small': {'fp32': 14.938292503356934, 'top1': 87.181},\n",
       " 'convit_small': {'fp32': 8.7324857711792, 'top1': 87.053},\n",
       " 'deit_small_distilled_patch16_224': {'fp32': 6.4098310470581055,\n",
       "  'top1': 86.993},\n",
       " 'resmlp_36_distilled_224': {'fp32': 10.808858871459961, 'top1': 86.993},\n",
       " 'tnt_s_patch16_224': {'fp32': 14.40457820892334, 'top1': 86.90299999999999},\n",
       " 'vit_small_patch16_224': {'fp32': 6.377596855163574, 'top1': 86.869},\n",
       " 'vit_small_r26_s32_224': {'fp32': 14.331820011138916, 'top1': 86.863},\n",
       " 'ssl_resnext101_32x16d': {'fp32': 119.6251392364502,\n",
       "  'top1': 86.85600000000001},\n",
       " 'rexnet_200': {'fp32': 15.437161922454834, 'top1': 86.846},\n",
       " 'deit_base_patch16_224': {'fp32': 8.144140243530273, 'top1': 86.829},\n",
       " 'ssl_resnext101_32x8d': {'fp32': 63.55698823928833, 'top1': 86.807},\n",
       " 'swsl_resnet50': {'fp32': 13.167252540588379, 'top1': 86.807},\n",
       " 'coat_mini': {'fp32': 35.6980037689209, 'top1': 86.79299999999999},\n",
       " 'twins_svt_small': {'fp32': 13.224685192108154, 'top1': 86.756},\n",
       " 'levit_256': {'fp32': 9.803543090820312, 'top1': 86.728},\n",
       " 'seresnext50_32x4d': {'fp32': 29.789512157440186, 'top1': 86.699},\n",
       " 'pit_b_224': {'fp32': 23.014636039733887, 'top1': 86.686},\n",
       " 'swin_tiny_patch4_window7_224': {'fp32': 8.665573596954346, 'top1': 86.664},\n",
       " 'wide_resnet50_2': {'fp32': 16.90601348876953, 'top1': 86.647},\n",
       " 'resmlp_24_distilled_224': {'fp32': 7.271509170532227,\n",
       "  'top1': 86.62200000000001},\n",
       " 'twins_pcpvt_small': {'fp32': 13.856451511383057, 'top1': 86.62},\n",
       " 'resnest50d_4s2x40d': {'fp32': 23.885343074798584, 'top1': 86.59200000000001},\n",
       " 'repvgg_b3': {'fp32': 28.389830589294434, 'top1': 86.566},\n",
       " 'ssl_resnext101_32x4d': {'fp32': 44.833362102508545, 'top1': 86.479},\n",
       " 'ecaresnet50d': {'fp32': 16.176774501800537, 'top1': 86.47},\n",
       " 'gluon_resnet152_v1s': {'fp32': 35.96315622329712, 'top1': 86.46799999999999},\n",
       " 'resnest50d_1s4x24d': {'fp32': 22.619028091430664, 'top1': 86.447},\n",
       " 'repvgg_b3g4': {'fp32': 27.560269832611084, 'top1': 86.361},\n",
       " 'legacy_senet154': {'fp32': 118.40935707092285, 'top1': 86.34200000000001},\n",
       " 'cait_xxs36_224': {'fp32': 25.236077308654785, 'top1': 86.34},\n",
       " 'gernet_m': {'fp32': 10.314347743988037, 'top1': 86.319},\n",
       " 'pit_s_224': {'fp32': 15.984313488006592, 'top1': 86.316},\n",
       " 'gluon_senet154': {'fp32': 118.77516746520996, 'top1': 86.27799999999999},\n",
       " 'resnest50d': {'fp32': 22.304112911224365, 'top1': 86.24},\n",
       " 'ecaresnet101d_pruned': {'fp32': 30.75754404067993, 'top1': 86.21},\n",
       " 'rexnet_150': {'fp32': 15.177664756774902, 'top1': 86.154},\n",
       " 'ssl_resnext50_32x4d': {'fp32': 23.491158485412598, 'top1': 86.086},\n",
       " 'gluon_resnet101_v1s': {'fp32': 24.85081672668457, 'top1': 86.054},\n",
       " 'ecaresnetlight': {'fp32': 15.680818557739258, 'top1': 86.052},\n",
       " 'gluon_seresnext101_32x4d': {'fp32': 58.40898513793945,\n",
       "  'top1': 86.03200000000001},\n",
       " 'resnet50d': {'fp32': 13.604111671447754, 'top1': 86.009},\n",
       " 'gluon_seresnext101_64x4d': {'fp32': 80.38221836090088, 'top1': 85.96},\n",
       " 'vit_base_patch32_224': {'fp32': 6.309616565704346, 'top1': 85.956},\n",
       " 'gluon_resnet152_v1d': {'fp32': 36.075589656829834, 'top1': 85.917},\n",
       " 'seresnet50': {'fp32': 19.72234010696411, 'top1': 85.85700000000001},\n",
       " 'repvgg_b2g4': {'fp32': 23.099920749664307, 'top1': 85.855},\n",
       " 'gluon_resnet101_v1d': {'fp32': 24.865880012512207,\n",
       "  'top1': 85.84899999999999},\n",
       " 'resnet50': {'fp32': 13.070471286773682, 'top1': 85.804},\n",
       " 'mixnet_xl': {'fp32': 30.19455909729004, 'top1': 85.79799999999999},\n",
       " 'ese_vovnet39b': {'fp32': 14.699952602386475, 'top1': 85.751},\n",
       " 'gluon_resnext101_32x4d': {'fp32': 44.82148885726929,\n",
       "  'top1': 85.74600000000001},\n",
       " 'legacy_seresnext101_32x4d': {'fp32': 58.50147008895874,\n",
       "  'top1': 85.74600000000001},\n",
       " 'cspresnext50': {'fp32': 24.12332057952881, 'top1': 85.74},\n",
       " 'regnety_320': {'fp32': 60.529518127441406, 'top1': 85.727},\n",
       " 'resmlp_big_24_224': {'fp32': 36.21501922607422, 'top1': 85.695},\n",
       " 'gluon_resnext101_64x4d': {'fp32': 72.99256563186646, 'top1': 85.693},\n",
       " 'deit_small_patch16_224': {'fp32': 6.3588714599609375, 'top1': 85.678},\n",
       " 'pit_xs_distilled_224': {'fp32': 13.260557651519775,\n",
       "  'top1': 85.65700000000001},\n",
       " 'dpn107': {'fp32': 68.58819723129272, 'top1': 85.64},\n",
       " 'resmlp_36_224': {'fp32': 10.426931381225586, 'top1': 85.62},\n",
       " 'levit_192': {'fp32': 9.473047256469727, 'top1': 85.58},\n",
       " 'gluon_resnet152_v1c': {'fp32': 36.065311431884766, 'top1': 85.58},\n",
       " 'ecaresnet50d_pruned': {'fp32': 16.34434461593628, 'top1': 85.58},\n",
       " 'resnext50d_32x4d': {'fp32': 23.9900541305542, 'top1': 85.569},\n",
       " 'regnety_120': {'fp32': 35.074260234832764, 'top1': 85.54299999999999},\n",
       " 'regnetx_320': {'fp32': 59.012954235076904, 'top1': 85.524},\n",
       " 'dpn92': {'fp32': 43.23657512664795, 'top1': 85.494},\n",
       " 'gluon_resnet152_v1b': {'fp32': 35.65824270248413, 'top1': 85.475},\n",
       " 'rexnet_130': {'fp32': 15.647735595703125, 'top1': 85.473},\n",
       " 'resnetrs50': {'fp32': 20.421524047851562, 'top1': 85.462},\n",
       " 'dpn131': {'fp32': 68.24190616607666, 'top1': 85.398},\n",
       " 'regnetx_160': {'fp32': 37.669923305511475, 'top1': 85.39},\n",
       " 'dla102x2': {'fp32': 62.16656684875488, 'top1': 85.366},\n",
       " 'gluon_seresnext50_32x4d': {'fp32': 29.890780448913574, 'top1': 85.336},\n",
       " 'skresnext50_32x4d': {'fp32': 35.31296253204346, 'top1': 85.31299999999999},\n",
       " 'dpn98': {'fp32': 51.88017129898071, 'top1': 85.311},\n",
       " 'gluon_resnet101_v1c': {'fp32': 24.825599193572998, 'top1': 85.304},\n",
       " 'dpn68b': {'fp32': 35.486135482788086, 'top1': 85.291},\n",
       " 'regnety_064': {'fp32': 33.992931842803955, 'top1': 85.28299999999999},\n",
       " 'resnetblur50': {'fp32': 13.288507461547852, 'top1': 85.28299999999999},\n",
       " 'resmlp_24_224': {'fp32': 7.358105182647705, 'top1': 85.26799999999999},\n",
       " 'coat_lite_mini': {'fp32': 11.34040117263794, 'top1': 85.251},\n",
       " 'regnety_080': {'fp32': 30.2477765083313, 'top1': 85.245},\n",
       " 'cait_xxs24_224': {'fp32': 17.572786808013916, 'top1': 85.228},\n",
       " 'resnext50_32x4d': {'fp32': 23.5636568069458, 'top1': 85.221},\n",
       " 'resnext101_32x8d': {'fp32': 63.528075218200684, 'top1': 85.18700000000001},\n",
       " 'hrnet_w48': {'fp32': 77.2935438156128, 'top1': 85.15100000000001},\n",
       " 'gluon_resnet101_v1b': {'fp32': 24.276750087738037,\n",
       "  'top1': 85.14200000000001},\n",
       " 'regnetx_120': {'fp32': 31.98323965072632, 'top1': 85.131},\n",
       " 'hrnet_w64': {'fp32': 77.98977136611938, 'top1': 85.119},\n",
       " 'ssl_resnet50': {'fp32': 13.312861919403076, 'top1': 85.09700000000001},\n",
       " 'res2net101_26w_4s': {'fp32': 42.01146602630615, 'top1': 85.09299999999999},\n",
       " 'res2net50_26w_8s': {'fp32': 37.28018045425415, 'top1': 85.029},\n",
       " 'resnest26d': {'fp32': 12.431516647338867, 'top1': 85.008},\n",
       " 'gluon_resnext50_32x4d': {'fp32': 23.481574058532715, 'top1': 84.995},\n",
       " 'tf_efficientnet_b0_ns': {'fp32': 15.606083869934082, 'top1': 84.984},\n",
       " 'coat_tiny': {'fp32': 35.102314949035645, 'top1': 84.976},\n",
       " 'regnety_040': {'fp32': 29.593660831451416, 'top1': 84.948},\n",
       " 'dla169': {'fp32': 39.44899559020996, 'top1': 84.92},\n",
       " 'legacy_seresnext50_32x4d': {'fp32': 29.708619117736816,\n",
       "  'top1': 84.90100000000001},\n",
       " 'hrnet_w44': {'fp32': 77.65289783477783, 'top1': 84.884},\n",
       " 'gluon_resnet50_v1s': {'fp32': 13.720438480377197, 'top1': 84.86200000000001},\n",
       " 'regnetx_080': {'fp32': 29.13945436477661, 'top1': 84.86200000000001},\n",
       " 'levit_128': {'fp32': 9.578113555908203, 'top1': 84.84299999999999},\n",
       " 'gluon_resnet50_v1d': {'fp32': 13.55842113494873, 'top1': 84.83200000000001},\n",
       " 'dla60_res2next': {'fp32': 30.626158714294434, 'top1': 84.83},\n",
       " 'mixnet_l': {'fp32': 24.36124563217163, 'top1': 84.822},\n",
       " 'tv_resnet152': {'fp32': 35.635008811950684, 'top1': 84.815},\n",
       " 'dla60_res2net': {'fp32': 24.18288230895996, 'top1': 84.81299999999999},\n",
       " 'dla102x': {'fp32': 42.28411912918091, 'top1': 84.81299999999999},\n",
       " 'pit_xs_224': {'fp32': 13.126370906829834, 'top1': 84.792},\n",
       " 'regnetx_064': {'fp32': 23.689093589782715, 'top1': 84.781},\n",
       " 'hrnet_w40': {'fp32': 77.58050441741943, 'top1': 84.743},\n",
       " 'res2net50_26w_6s': {'fp32': 29.149439334869385, 'top1': 84.726},\n",
       " 'repvgg_b2': {'fp32': 23.35519313812256, 'top1': 84.72399999999999},\n",
       " 'resmlp_12_distilled_224': {'fp32': 4.45798397064209, 'top1': 84.713},\n",
       " 'legacy_seresnet152': {'fp32': 56.19556903839111, 'top1': 84.704},\n",
       " 'selecsls60b': {'fp32': 15.792901515960693, 'top1': 84.65700000000001},\n",
       " 'hrnet_w32': {'fp32': 77.26882696151733, 'top1': 84.65100000000001},\n",
       " 'tf_efficientnetv2_b0': {'fp32': 17.512075901031494, 'top1': 84.625},\n",
       " 'regnetx_040': {'fp32': 24.476487636566162, 'top1': 84.6},\n",
       " 'efficientnet_es': {'fp32': 9.59014892578125, 'top1': 84.59100000000001},\n",
       " 'hrnet_w30': {'fp32': 77.46355295181274, 'top1': 84.572},\n",
       " 'tf_mixnet_l': {'fp32': 24.727728366851807, 'top1': 84.564},\n",
       " 'wide_resnet101_2': {'fp32': 31.62684440612793, 'top1': 84.557},\n",
       " 'dla60x': {'fp32': 25.395286083221436, 'top1': 84.523},\n",
       " 'legacy_seresnet101': {'fp32': 37.76135444641113, 'top1': 84.50399999999999},\n",
       " 'coat_lite_tiny': {'fp32': 11.470646858215332, 'top1': 84.45},\n",
       " 'repvgg_b1': {'fp32': 17.914841175079346, 'top1': 84.416},\n",
       " 'res2net50_26w_4s': {'fp32': 21.461904048919678, 'top1': 84.365},\n",
       " 'hardcorenas_f': {'fp32': 15.929255485534668, 'top1': 84.32600000000001},\n",
       " 'res2net50_14w_8s': {'fp32': 37.06977367401123, 'top1': 84.309},\n",
       " 'selecsls60': {'fp32': 15.906856060028076, 'top1': 84.288},\n",
       " 'regnetx_032': {'fp32': 23.281080722808838, 'top1': 84.23700000000001},\n",
       " 'res2next50': {'fp32': 27.80407190322876, 'top1': 84.226},\n",
       " 'gluon_resnet50_v1c': {'fp32': 13.52034330368042, 'top1': 84.20700000000001},\n",
       " 'dla102': {'fp32': 25.134928226470947, 'top1': 84.19},\n",
       " 'rexnet_100': {'fp32': 15.358355045318604, 'top1': 84.162},\n",
       " 'res2net50_48w_2s': {'fp32': 13.810060024261475, 'top1': 84.126},\n",
       " 'resnet34d': {'fp32': 11.96746826171875, 'top1': 84.098},\n",
       " 'efficientnet_b0': {'fp32': 15.176019668579102, 'top1': 84.038},\n",
       " 'gmixer_24_224': {'fp32': 10.632157325744629, 'top1': 83.96799999999999},\n",
       " 'hardcorenas_e': {'fp32': 16.08830213546753, 'top1': 83.96799999999999},\n",
       " 'tf_efficientnet_cc_b0_8e': {'fp32': 17.074263095855713,\n",
       "  'top1': 83.96600000000001},\n",
       " 'tv_resnext50_32x4d': {'fp32': 23.499579429626465, 'top1': 83.959},\n",
       " 'regnety_016': {'fp32': 37.729036808013916, 'top1': 83.955},\n",
       " 'gluon_resnet50_v1b': {'fp32': 13.301715850830078, 'top1': 83.94},\n",
       " 'densenet161': {'fp32': 39.50547695159912, 'top1': 83.906},\n",
       " 'mobilenetv2_120d': {'fp32': 13.552076816558838, 'top1': 83.89299999999999},\n",
       " 'seresnext26t_32x4d': {'fp32': 16.388742923736572, 'top1': 83.87799999999999},\n",
       " 'tv_resnet101': {'fp32': 24.250290393829346, 'top1': 83.848},\n",
       " 'hardcorenas_d': {'fp32': 16.87415599822998, 'top1': 83.759},\n",
       " 'seresnext26d_32x4d': {'fp32': 16.512179374694824, 'top1': 83.75399999999999},\n",
       " 'dla60': {'fp32': 15.62697172164917, 'top1': 83.729},\n",
       " 'repvgg_b1g4': {'fp32': 19.112842082977295, 'top1': 83.699},\n",
       " 'legacy_seresnet50': {'fp32': 19.561116695404053, 'top1': 83.662},\n",
       " 'tf_efficientnet_b0_ap': {'fp32': 15.479509830474854, 'top1': 83.65},\n",
       " 'skresnet34': {'fp32': 22.282590866088867, 'top1': 83.641},\n",
       " 'tf_efficientnet_cc_b0_4e': {'fp32': 17.265737056732178, 'top1': 83.639},\n",
       " 'resmlp_12_224': {'fp32': 4.0805745124816895, 'top1': 83.571},\n",
       " 'densenet201': {'fp32': 49.51512336730957, 'top1': 83.556},\n",
       " 'mobilenetv3_large_100_miil': {'fp32': 11.62226676940918, 'top1': 83.556},\n",
       " 'gernet_s': {'fp32': 10.602884292602539, 'top1': 83.522},\n",
       " 'legacy_seresnext26_32x4d': {'fp32': 16.013472080230713,\n",
       "  'top1': 83.51700000000001},\n",
       " 'mixnet_m': {'fp32': 24.340946674346924, 'top1': 83.515},\n",
       " 'tf_efficientnet_b0': {'fp32': 15.629713535308838, 'top1': 83.515},\n",
       " 'hrnet_w18': {'fp32': 77.63300657272339, 'top1': 83.5},\n",
       " 'densenetblur121d': {'fp32': 30.213792324066162, 'top1': 83.47200000000001},\n",
       " 'selecsls42b': {'fp32': 12.251818180084229, 'top1': 83.45700000000001},\n",
       " 'hardcorenas_c': {'fp32': 12.28823184967041, 'top1': 83.34200000000001},\n",
       " 'regnetx_016': {'fp32': 19.21266794204712, 'top1': 83.195},\n",
       " 'mobilenetv2_140': {'fp32': 9.146544933319092, 'top1': 83.182},\n",
       " 'dpn68': {'fp32': 32.48085021972656, 'top1': 83.178},\n",
       " 'tf_efficientnet_es': {'fp32': 9.651808738708496, 'top1': 83.178},\n",
       " 'tf_mixnet_m': {'fp32': 24.638941287994385, 'top1': 83.176},\n",
       " 'ese_vovnet19b_dw': {'fp32': 7.170546054840088, 'top1': 83.109},\n",
       " 'levit_128s': {'fp32': 7.92184591293335, 'top1': 83.069},\n",
       " 'resnet26d': {'fp32': 8.071653842926025, 'top1': 83.05},\n",
       " 'repvgg_a2': {'fp32': 12.158229351043701, 'top1': 83.001},\n",
       " 'tv_resnet50': {'fp32': 13.246650695800781, 'top1': 82.958},\n",
       " 'hardcorenas_b': {'fp32': 11.440660953521729, 'top1': 82.87299999999999},\n",
       " 'densenet121': {'fp32': 29.496641159057617, 'top1': 82.823},\n",
       " 'densenet169': {'fp32': 41.30248785018921, 'top1': 82.68299999999999},\n",
       " 'mixnet_s': {'fp32': 20.33100128173828, 'top1': 82.525},\n",
       " 'vit_small_patch32_224': {'fp32': 6.230607032775879, 'top1': 82.514},\n",
       " 'regnety_008': {'fp32': 22.214641571044922, 'top1': 82.493},\n",
       " 'efficientnet_lite0': {'fp32': 8.655755519866943, 'top1': 82.382},\n",
       " 'resnest14d': {'fp32': 7.397334575653076, 'top1': 82.34899999999999},\n",
       " 'hardcorenas_a': {'fp32': 9.995191097259521, 'top1': 82.31299999999999},\n",
       " 'efficientnet_es_pruned': {'fp32': 9.494497776031494, 'top1': 82.296},\n",
       " 'mobilenetv3_rw': {'fp32': 11.660823822021484, 'top1': 82.275},\n",
       " 'semnasnet_100': {'fp32': 12.158796787261963, 'top1': 82.251},\n",
       " 'mobilenetv3_large_100': {'fp32': 11.767716407775879, 'top1': 82.177},\n",
       " 'resnet34': {'fp32': 11.384499073028564, 'top1': 82.13799999999999},\n",
       " 'mobilenetv2_110d': {'fp32': 11.63078784942627, 'top1': 82.07},\n",
       " 'vit_tiny_patch16_224': {'fp32': 6.354000568389893, 'top1': 82.066},\n",
       " 'tf_mixnet_s': {'fp32': 20.533647537231445, 'top1': 82.038},\n",
       " 'repvgg_b0': {'fp32': 14.523680210113525, 'top1': 82.001},\n",
       " 'deit_tiny_distilled_patch16_224': {'fp32': 6.505832672119141,\n",
       "  'top1': 81.99700000000001},\n",
       " 'mixer_b16_224': {'fp32': 6.005053520202637, 'top1': 81.978},\n",
       " 'pit_ti_distilled_224': {'fp32': 11.327447891235352,\n",
       "  'top1': 81.96700000000001},\n",
       " 'hrnet_w18_small_v2': {'fp32': 39.86715793609619, 'top1': 81.961},\n",
       " 'tf_efficientnet_lite0': {'fp32': 8.792951107025146,\n",
       "  'top1': 81.95200000000001},\n",
       " 'resnet26': {'fp32': 7.5565314292907715, 'top1': 81.944},\n",
       " 'tf_mobilenetv3_large_100': {'fp32': 11.876115798950195, 'top1': 81.848},\n",
       " 'tv_densenet121': {'fp32': 29.64106559753418, 'top1': 81.726},\n",
       " 'regnety_006': {'fp32': 23.668363094329834, 'top1': 81.7},\n",
       " 'dla34': {'fp32': 10.90489149093628, 'top1': 81.658},\n",
       " 'fbnetc_100': {'fp32': 11.348040103912354, 'top1': 81.559},\n",
       " 'legacy_seresnet34': {'fp32': 16.76248788833618, 'top1': 81.53399999999999},\n",
       " 'gluon_resnet34_v1b': {'fp32': 11.525590419769287, 'top1': 81.5},\n",
       " 'regnetx_008': {'fp32': 19.472036361694336, 'top1': 81.485},\n",
       " 'mnasnet_100': {'fp32': 9.160943031311035, 'top1': 81.459},\n",
       " 'vgg19_bn': {'fp32': 21.426701545715332, 'top1': 81.444},\n",
       " 'convit_tiny': {'fp32': 8.790421485900879, 'top1': 81.126},\n",
       " 'spnasnet_100': {'fp32': 11.016905307769775, 'top1': 80.878},\n",
       " 'ghostnet_100': {'fp32': 15.661108493804932, 'top1': 80.699},\n",
       " 'regnety_004': {'fp32': 29.266657829284668, 'top1': 80.65899999999999},\n",
       " 'skresnet18': {'fp32': 12.066454887390137, 'top1': 80.637},\n",
       " 'regnetx_006': {'fp32': 16.617286205291748, 'top1': 80.62899999999999},\n",
       " 'pit_ti_224': {'fp32': 11.03642225265503, 'top1': 80.605},\n",
       " 'swsl_resnet18': {'fp32': 6.566486358642578, 'top1': 80.575},\n",
       " 'vgg16_bn': {'fp32': 18.267951011657715, 'top1': 80.556},\n",
       " 'tv_resnet34': {'fp32': 11.512017250061035, 'top1': 80.389},\n",
       " 'resnet18d': {'fp32': 6.952710151672363, 'top1': 80.387},\n",
       " 'mobilenetv2_100': {'fp32': 9.301655292510986, 'top1': 80.257},\n",
       " 'ssl_resnet18': {'fp32': 6.413772106170654, 'top1': 80.101},\n",
       " 'tf_mobilenetv3_large_075': {'fp32': 11.914403438568115, 'top1': 80.093},\n",
       " 'deit_tiny_patch16_224': {'fp32': 6.480603218078613, 'top1': 80.018},\n",
       " 'hrnet_w18_small': {'fp32': 22.388195991516113, 'top1': 79.557},\n",
       " 'vgg19': {'fp32': 20.636448860168457, 'top1': 79.48},\n",
       " 'regnetx_004': {'fp32': 23.54163646697998, 'top1': 79.435},\n",
       " 'tf_mobilenetv3_large_minimal_100': {'fp32': 8.509268760681152,\n",
       "  'top1': 79.222},\n",
       " 'legacy_seresnet18': {'fp32': 9.242548942565918, 'top1': 79.153},\n",
       " 'vgg16': {'fp32': 17.58795976638794, 'top1': 79.038},\n",
       " 'vgg13_bn': {'fp32': 15.115864276885986, 'top1': 79.006},\n",
       " 'vit_tiny_r_s16_p8_224': {'fp32': 6.765804290771484, 'top1': 78.991},\n",
       " 'gluon_resnet18_v1b': {'fp32': 6.550438404083252, 'top1': 78.372},\n",
       " 'vgg11_bn': {'fp32': 11.503260135650635, 'top1': 77.926},\n",
       " 'regnety_002': {'fp32': 23.753905296325684, 'top1': 77.405},\n",
       " 'mixer_l16_224': {'fp32': 18.644118309020996, 'top1': 77.285},\n",
       " 'resnet18': {'fp32': 6.402738094329834, 'top1': 77.27600000000001},\n",
       " 'vgg13': {'fp32': 14.562349319458008, 'top1': 77.23},\n",
       " 'vgg11': {'fp32': 11.132502555847168, 'top1': 76.384},\n",
       " 'regnetx_002': {'fp32': 18.17647933959961, 'top1': 76.124},\n",
       " 'dla60x_c': {'fp32': 24.133601188659668, 'top1': 75.637},\n",
       " 'tf_mobilenetv3_small_100': {'fp32': 10.3680419921875, 'top1': 74.717},\n",
       " 'dla46x_c': {'fp32': 18.569304943084717, 'top1': 73.64699999999999},\n",
       " 'tf_mobilenetv3_small_075': {'fp32': 10.742824077606201, 'top1': 72.812},\n",
       " 'dla46_c': {'fp32': 11.950483322143555, 'top1': 72.601},\n",
       " 'tf_mobilenetv3_small_minimal_100': {'fp32': 6.80619478225708,\n",
       "  'top1': 70.111}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark = {}\n",
    "\n",
    "# inference float precision\n",
    "for i,modelname in tqdm(enumerate((modellist))):\n",
    "    try:\n",
    "        benchmark = inference(modelname, benchmark)\n",
    "    except:\n",
    "        print(\"pass {}\".format(modelname))\n",
    "benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fp32</th>\n",
       "      <th>top1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>swin_large_patch4_window7_224</th>\n",
       "      <td>19.502795</td>\n",
       "      <td>89.796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_large_patch16_224</th>\n",
       "      <td>24.370010</td>\n",
       "      <td>89.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swin_base_patch4_window7_224</th>\n",
       "      <td>15.764215</td>\n",
       "      <td>89.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ig_resnext101_32x48d</th>\n",
       "      <td>360.543289</td>\n",
       "      <td>89.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ig_resnext101_32x32d</th>\n",
       "      <td>241.999886</td>\n",
       "      <td>89.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_mobilenetv3_small_100</th>\n",
       "      <td>10.368042</td>\n",
       "      <td>74.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dla46x_c</th>\n",
       "      <td>18.569305</td>\n",
       "      <td>73.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_mobilenetv3_small_075</th>\n",
       "      <td>10.742824</td>\n",
       "      <td>72.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dla46_c</th>\n",
       "      <td>11.950483</td>\n",
       "      <td>72.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf_mobilenetv3_small_minimal_100</th>\n",
       "      <td>6.806195</td>\n",
       "      <td>70.111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        fp32    top1\n",
       "swin_large_patch4_window7_224      19.502795  89.796\n",
       "vit_large_patch16_224              24.370010  89.314\n",
       "swin_base_patch4_window7_224       15.764215  89.145\n",
       "ig_resnext101_32x48d              360.543289  89.120\n",
       "ig_resnext101_32x32d              241.999886  89.111\n",
       "...                                      ...     ...\n",
       "tf_mobilenetv3_small_100           10.368042  74.717\n",
       "dla46x_c                           18.569305  73.647\n",
       "tf_mobilenetv3_small_075           10.742824  72.812\n",
       "dla46_c                            11.950483  72.601\n",
       "tf_mobilenetv3_small_minimal_100    6.806195  70.111\n",
       "\n",
       "[283 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.DataFrame(benchmark).T\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"results_fp32_224.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f3ea9ea8668>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lmplot(y='top1', x='fp32',  \n",
    "           data=df_results, logx=True,\n",
    "           fit_reg=False, scatter_kws={'alpha':0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
